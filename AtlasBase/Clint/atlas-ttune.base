@ROUT tune_barrier
#include "atlas_threads.h"
#include "atlas_misc.h"
#include <assert.h>
static int NTHR=0, NREP=100000;
volatile char *bchk;
static double *timearr=NULL;
#define ATL_membarrier()

#define TimePT 1
#ifdef TimePT
   #include <pthread.h>
   static pthread_barrier_t ptb;
#endif
@beginskip
static int bcnt=0, bdone=0;
static void *bmut=NULL;
   bmut = ATL_mutex_init();
void ATL_mut_barrier(ATL_CUINT P, ATL_CUINT rank)
{
   const char newv = !bchk[iam];
   if (rank)
   {
      ATL_mutex_lock(bmut);
      bchk[rank] = newv;
      ATL_mutex_unlock(bmut);
      while (*bchk != newv);
   }
   else
   {
      int i;
      for (i=1; i < P; i++)
         while(bchk[i] != newv);
      ATL_mutex_lock(bmut);
      bchk[rank] = newv;
      ATL_mutex_unlock(bmut);
   }
}
@endskip
void ATL_cbc_barrier
(
   ATL_CUINT P,    /* # of threads to barrier */
   ATL_CUINT iam   /* rank of calling thread in barrier */
)
{
   ATL_UINT d;
   const char newv = !bchk[iam];
/*
 * Any thread that did not participate in this job, simply updates
 * its entry to match what the active threads will change to, and
 * returns w/o waiting on barrier (they are not part of barrier!).
 * NOTE: all cores must call this routine to avoid having the boolean array
 *       get out of sync, or this array must be reset manually during serial
 *       execution.
 *       
 */
#if 0
   if (iam > P)
   {
      bchk[iam] = newv;
      return;
   }
#endif
   for (d=1; iam+d < P; d <<= 1)
   {
      if ((iam>>(d-1))&1) /* partner on right is done */
         break;
      while (bchk[iam+d] != newv); /* await partner signal */
   }
   bchk[iam] = newv;
   if (iam)
      while (*bchk != newv);
}

void ATL_cbc_barrlinGap
(
   ATL_CUINT P,    /* # of threads to barrier */
   ATL_CUINT iam   /* rank of calling thread in barrier */
)
{
   ATL_CUINT II = iam << 7;
   const char newv = !bchk[II];

   if (iam)
   {
      bchk[II] = newv;
      while (*bchk != newv);
   }
   else
   {
      int i;
      for (i=1; i < P; i++)
      {
         ATL_CUINT d = i<<7;
         while (bchk[d] != newv);
      }
      *bchk = newv;
   }
}

void ATL_cbc_barrlin
(
   ATL_CUINT P,    /* # of threads to barrier */
   ATL_CUINT iam   /* rank of calling thread in barrier */
)
{
   const char newv = !bchk[iam];

   if (iam)
   {
      bchk[iam] = newv;
      while (*bchk != newv);
   }
   else
   {
      int i;
      for (i=1; i < P; i++)
         while (bchk[i] != newv);
      *bchk = newv;
   }
}

void DoPTB(void *vpp, int rank, int vrank)
{
   ATL_tpool_t *pp = vpp;
   int i;
   double t0;
   t0 = ATL_walltime();
   for (i=0; i < NREP; i++)
   {
      pthread_barrier_wait(&ptb);
   }
   timearr[rank] = ATL_walltime() - t0;
}
void DoCBC(void *vpp, int rank, int vrank)
{
   ATL_tpool_t *pp = vpp;
   int i;
   double t0;
   t0 = ATL_walltime();
   for (i=0; i < NREP; i++)
   {
      ATL_cbc_barrier(pp->nthr, vrank);
   }
   timearr[rank] = ATL_walltime() - t0;
}
void DoCBC_lin(void *vpp, int rank, int vrank)
{
   ATL_tpool_t *pp = vpp;
   int i;
   double t0;
   t0 = ATL_walltime();
   for (i=0; i < NREP; i++)
   {
      ATL_cbc_barrlin(pp->nthr, vrank);
   }
   timearr[rank] = ATL_walltime() - t0;
}

void DoCBC_gap(void *vpp, int rank, int vrank)
{
   ATL_tpool_t *pp = vpp;
   int i;
   double t0;
   t0 = ATL_walltime();
   for (i=0; i < NREP; i++)
   {
      ATL_cbc_barrlinGap(pp->nthr, vrank);
   }
   timearr[rank] = ATL_walltime() - t0;
}
void DoStart(void *vpp, int rank, int vrank)
{
   ATL_tpool_t *pp = vpp;
   ATL_cbc_barrier(pp->nthr, vrank);
}

double PrintTimes()
{
   int i;
   double tmin, tmax, tsum;
   tmin = tmax = tsum = timearr[0];
   for (i=1; i < NTHR; i++)
   {
      const double t0 = timearr[i];
      tsum += t0;
      if (t0 > tmax)
         tmax = t0;
      if (t0 < tmin)
         tmin = t0;
   }
   printf("   TIMES: MAX=%e, MIN=%e, AVG=%e\n", tmax, tmin, tsum/NTHR);
   return(tsum);
}
int main(int nargs, char **args)
{
   int i, reps=100000;
   int nthr=ATL_NTHREADS;
   ATL_CUINT nthr128 = nthr<<7;
   double tlin, tlog, tpt=0, tgap;
   if (nargs > 1)
   {
      nthr = atoi(args[1]);
      if (nargs > 2)
         reps = atoi(args[2]);
   }
   NTHR = ATL_NTHREADS;
   NREP = reps;
   timearr = malloc(sizeof(double)*nthr);
   assert(timearr);
   bchk = calloc(nthr128, sizeof(char));
   assert(bchk);
/*
 * Start up ATLAS's threadpool by doing single barrier; we don't want spawn cost
 * in any of our timings.
 */
   ATL_goParallel(nthr, DoStart, NULL, NULL, NULL);
   printf("FINDING SPEED OF %s BARRIER USING %d THREADS AND %d REPS\n", 
          "log2(CBC)", nthr, reps);
   ATL_goParallel(nthr, DoCBC, NULL, NULL, NULL);
   tlog = PrintTimes();

   printf("FINDING SPEED OF %s BARRIER USING %d THREADS AND %d REPS\n", 
          "lin(CBC)", nthr, reps);
   ATL_goParallel(nthr, DoCBC_lin, NULL, NULL, NULL);
   tlin = PrintTimes();

   for (i=0; i < nthr; i++)
      bchk[i] = 0;
   printf("FINDING SPEED OF %s BARRIER USING %d THREADS AND %d REPS\n", 
          "linCL(CBC)", nthr, reps);
   ATL_goParallel(nthr, DoCBC_gap, NULL, NULL, NULL);
   tgap = PrintTimes();

   #ifdef TimePT
      assert(pthread_barrier_init(&ptb, NULL, nthr) == 0);
      printf("FINDING SPEED OF %s BARRIER USING %d THREADS AND %d REPS\n", 
             "PTHREAD", nthr, reps);
      ATL_goParallel(nthr, DoPTB, NULL, NULL, NULL);
      tpt = PrintTimes();
      assert(pthread_barrier_destroy(&ptb) == 0);
   #endif
   printf("LIN/LOG = %0.2f, LOG/LIN = %0.2f\n", tlin/tlog, tlog/tlin);
   printf("compressed/seperated = %0.2f\n", tlin/tgap);
   if (tpt != 0.0)
      printf("PTHREAD/LINCBC = %0.2f, LINCBC/PTHREAD = %0.2f\n", 
             tpt/tlin, tlin/tpt);
   return(0);
}
@ROUT test_count
#include "atlas_threads.h"
#include "atlas_misc.h"
#include "assert.h"

static volatile char *checkin;

void PrintUsage(char *name)
{
   fprintf(stderr, "USAGE: %s [-r <reps>] [-c <cnt>]\n", name);
   exit(-1);
}

int GetFlags(int nargs, char **args, int *nreps)
{
   int i, cnt=16384;

   *nreps = 20;
   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0]);
      switch(args[i][1])
      {
      case 'r':
         if (++i == nargs)
            PrintUsage(args[0]);
         *nreps = atoi(args[i]);
         break;
      case 'c':
         if (++i == nargs)
            PrintUsage(args[0]);
         cnt = atoi(args[i]);
         break;
      default:
         PrintUsage(args[0]);
      }
   }
   return(cnt);
}

void TestDoWork(ATL_LAUNCHSTRUCT_t *lp, void *vp)
{
   int i;
   ATL_thread_t *tp = vp;
   void *acnt = lp->opstruct;
   #ifdef ATL_GLOBAL
      const int iam = tp->rank;
   #endif
   do
   {
      #ifdef ATL_GLOBAL
         i = ATL_DecGlobalAtomicCount(acnt, iam);
      #else
         i = ATL_DecAtomicCount(acnt);
      #endif
      if (i < 1) 
         break;
      checkin[i-1]++;
   }
   while(1);
}

int main(int nargs, char **args)
{
   int cnt, nreps, i, k;
   void *vp;

   cnt = GetFlags(nargs, args, &nreps);

   checkin = malloc(cnt*sizeof(char));
   assert(checkin);
   for (i=0; i < nreps; i++)
   {
      #ifdef ATL_GLOBAL
         vp = ATL_SetGlobalAtomicCount(ATL_NTHREADS, cnt, 0);
      #else
         vp = ATL_SetAtomicCount(cnt);
      #endif
      for (k=0; k < cnt; k++)
         checkin[k] = 0;
      ATL_goparallel(ATL_NTHREADS, TestDoWork, vp, NULL);
@skip      ATL_thread_launch(vp, 0, NULL, TestDoWork, NULL);
      for (k=0; k < cnt; k++)
         assert(checkin[k] == 1);
      #ifdef ATL_GLOBAL
         ATL_FreeGlobalAtomicCount(vp);
      #else
         ATL_FreeAtomicCount(vp);
      #endif
   }
   printf("TEST PASSED\n");
   return(0);
}
@ROUT probe_nthr
#include "atlas_taffinity.h"
#include "atlas_misc.h"
#include "assert.h"

#if defined(__MINGW32__) || defined(__MINGW64__)
@extract -b @(topd)/Clint/atlconf.base rout=MinGWPATH

#endif


void PrintUsage(char *nam)
{
   fprintf(stderr, "\nUSAGE: %s [-o <outfile>]\n", nam);
   exit(-1);
}

FILE *GetFlags(int nargs, char **args)
{
   int i;
   FILE *fpout=stdout;

   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-') PrintUsage(args[0]);
      switch(args[i][1])
      {
      case 'o':
         #if defined(__MINGW32__) || defined(__MINGW64__)
         {
            char *wp;
            wp = malloc(sizeof(char)*(strlen(args[++i])+1));;
            strcpy(wp, args[i]);
            slashsub(wp);
            cygdrivesub(wp);
            fpout = fopen(wp, "w");
            free(wp);
         }
         #else
            fpout = fopen(args[++i], "w");
         #endif
         assert(fpout);
         break;
      default:
         PrintUsage(args[0]);
      }
   }
   return(fpout);
}

void getLaunchOrder(int P, int *lo)
{
   int i, j, k, stop, dest;

   for (i=0; (1<<i) < P; i++)
   lo[0] = 0;
   k = 1;
   for (i--; i >= 0; i--)
   {
      stop = k;
      for (j=0; j < stop; j++)
      {
         dest = lo[j] + (1<<i);
         if (dest < P)
            lo[k++] = dest;
         if (k == P)
            return;
      }
   }
}

int main(int nargs, char **args)
{
   FILE *fpout;
   int i, j, k, P;
   int *lo;
   fpout = GetFlags(nargs, args);

   fprintf(fpout, "  /* This file generated by %s */\n", __FILE__);
   fprintf(fpout, "#ifndef ATLAS_NTHREADS_H\n   #define ATLAS_NTHREADS_H\n\n");
@beginskip
/*
 * I presently build Antoine's pthread implementation even on windows for
 * comparison purposes.  Need to get rid of 00 when this is no longer the
 * case.
 */
   fprintf(fpout, "/* Get rid of 00 if you don't want to build pthreads */\n");
@endskip
   #if !defined(ATL_PAFF_WIN64) && !defined(ATL_PAFF_WIN)
      fprintf(fpout, "#include \"pthread.h\"\n");
   #endif
   #if ATL_NCPU != 0
      P = ATL_NCPU;
   #elif defined(ATL_AFF_NUMID)
      P = ATL_AFF_NUMID;
   #else
      P = 4;
   #endif
   #if defined(ATL_AFF_NUMID)
      #if ATL_NCPU > ATL_AFF_NUMID
         fprintf(fpout, 
         "/*\n * I should have tested if NTHREADS = %d(NCPU) or %d(NAFFIDs)\n");
         fprintf(fpout, " * is better.  For now, assuming %d\n */", ATL_NCPU);
      #endif
   #endif
   fprintf(fpout, "   #define ATL_NTHREADS %d\n", P);
   for (i=0; (1<<i) < P; i++);
   fprintf(fpout, "   #define ATL_NTHRPOW2 %d\n", i);
   lo = malloc(P*sizeof(int));
   getLaunchOrder(P, lo);
   fprintf(fpout, "   #ifdef ATL_LAUNCHORDER\n");
   fprintf(fpout, "       static int ATL_launchorder[%d] = {0", P);
   for (i=1; i < P; i++)
      fprintf(fpout, ",%d", lo[i]);
   fprintf(fpout, "};\n   #endif\n");
   #if defined(ATL_AFF_NUMID) && !defined(ATL_RANK_IS_PROCESSORID)
      fprintf(fpout, "   #if defined(ATL_RANK2ID)\n");
      fprintf(fpout, "       static int ATL_rank2ID[%d] = {%d", 
              P, ATL_affinityIDs[0]);
      for (i=1; i < P; i++)
         fprintf(fpout, ",%d", ATL_affinityIDs[i%ATL_AFF_NUMID]);
      fprintf(fpout, "};\n   #endif\n");
   #endif
   fprintf(fpout, "\n#endif\n");
   fclose(fpout);
   return(0);
}
@ROUT tune_count
#include "atlas_threads.h"
#include "atlas_misc.h"
void *ATL_SetAtomicCount_mut(long long);

static volatile int count=0;
static pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;
static void *acnt;
static void **acnts;
static double *timearr=NULL;

int ATL_DecAtomicCount_ser(void)
{
   int iret=0;
   if (count)
   {
      iret = count;
      count--;
   }
   return(iret);
}

@beginskip
int ATL_DecAtomicCount_mut(void)
{
   int iret=0;
   if (count)
   {
      pthread_mutex_lock(&mutex);
      if (count)
      {
         iret = count;
         count--;
      }
      pthread_mutex_unlock(&mutex);
   }
   return(iret);
}
@endskip

void TuneDoWork_ser(ATL_LAUNCHSTRUCT_t *lp, void *vp)
{
   double t0, t1;
   ATL_thread_t *tp = vp;
   ATL_CINT iam = tp->rank;
   int lcount, i;

   t0 = ATL_walltime();
#ifdef UNSAFE
   while (ATL_DecAtomicCount_ser(acnt));
#else
   lcount = ATL_GetAtomicCount(acnt);
   if (iam)
      lcount = lcount / ATL_NTHREADS;
   else
      lcount = lcount / ATL_NTHREADS + lcount % ATL_NTHREADS;
   while (lcount--)
      i = ATL_GetAtomicCount(acnt);
#endif
   timearr[iam] = ATL_walltime() - t0;
}

void TuneDoWork_mut(ATL_LAUNCHSTRUCT_t *lp, void *vp)
{
   double t0, t1;
   ATL_thread_t *tp = vp;
   ATL_CINT iam = tp->rank;

   t0 = ATL_walltime();
   while (ATL_DecAtomicCount_mut(acnt));
   timearr[iam] = ATL_walltime() - t0;
}

void TuneDoWork_loc(ATL_LAUNCHSTRUCT_t *lp, void *vp)
{
   double t0, t1;
   ATL_thread_t *tp = vp;
   ATL_CINT iam = tp->rank;
   int i;

   t0 = ATL_walltime();
   for (i=0; i < ATL_NTHREADS; i++)
   {
      void *lacnt = acnts[(iam+i)%ATL_NTHREADS];
      while (ATL_DecAtomicCount(lacnt));
   }
   t1 = ATL_walltime();
   timearr[iam] = t1 - t0;
}

void TuneDoWork(ATL_LAUNCHSTRUCT_t *lp, void *vp)
{
   double t0, t1;
   ATL_thread_t *tp = vp;
   ATL_CINT iam = tp->rank;

   t0 = ATL_walltime();
   while (ATL_DecAtomicCount(acnt));
   t1 = ATL_walltime();
   timearr[iam] = t1 - t0;
}

void TuneDoWork_gc(ATL_LAUNCHSTRUCT_t *lp, void *vp)
{
   double t0, t1;
   ATL_thread_t *tp = vp;
   ATL_CINT iam = tp->rank;

   t0 = ATL_walltime();
   while (ATL_DecGlobalAtomicCount(acnt, iam));
   t1 = ATL_walltime();
   timearr[iam] = t1 - t0;
}


void PrintRank(ATL_LAUNCHSTRUCT_t *lp, void *vp)
{
   ATL_thread_t *tp = vp;
   printf("%d: awake with vp=%p\n", tp->rank, lp->vp);
}

void PrintUsage(char *exe)
{
   fprintf(stderr, "USAGE: %s [-r <reps>] -o outfile\n", exe);
   exit(-1);
}

size_t GetFlags(int nargs, char **args, char **outfile)
{
   int i;
   size_t reps = 1000000;

   *outfile = NULL;
   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0]);
      switch(args[i][1])
      {
      case 'r':
         if (++i >= nargs)
            PrintUsage(args[0]);
         reps = atoll(args[i]);
         break;
      case 'o':
         if (++i >= nargs)
            PrintUsage(args[0]);
         *outfile = args[i];
         break;
      default:
         PrintUsage(args[0]);
      }
   }
   return(reps);
}

int main(int nargs, char **args)
{
   double t0, tmut_s, tdec_s, tser_s, tmut, tdec, tser, tldec;
   size_t nreps, i, lcnt;
   ATL_thread_t ts;
   char *outfile;

   nreps = GetFlags(nargs, args, &outfile);
   
   printf("FINDING SPEED OF SERIAL COUNTER CHANGING USING %ld REPS:\n", 
          (long int) nreps);
   ts.rank = 0;
   timearr = malloc(sizeof(double)*ATL_NTHREADS);
   ATL_assert(timearr);
   
   acnt = ATL_SetAtomicCount(nreps);
   TuneDoWork(NULL, &ts);
   tdec_s = timearr[0];
   printf("   serial AtoDec time = %e\n", tdec_s);
   ATL_FreeAtomicCount(acnt);
   acnt = NULL;

   acnt = ATL_SetAtomicCount_mut(nreps);
   TuneDoWork_mut(NULL, &ts);
   tmut_s = timearr[0];
   ATL_FreeAtomicCount_mut(acnt);
   printf("   serial mutex  time = %e\n", tmut_s);

   acnt = ATL_SetAtomicCount_mut(nreps);
   count = nreps;
   TuneDoWork_ser(NULL, &ts);
   tser_s = timearr[0];
   ATL_FreeAtomicCount_mut(acnt);
   printf("   serial/read unsafe time = %e\n", tser_s);

   #ifdef PentiumCPS
      t0 = (1000000.0/nreps)*PentiumCPS;
      printf("   CYCLES PER CALL: SER=%.1f, DEC=%.1f, MUT=%.1f\n", 
             t0*tser_s, t0*tdec_s, t0*tmut_s);
   #endif
   t0 = 1000000.0 / nreps;
   printf("   MICROSECONDS PER CALL: SER=%.2f DEC=%.2f, MUT=%.2f\n", 
          tser_s*t0, tdec_s*t0, tmut_s*t0);
   printf("DEC TIME SPEEDUP OVER MUTEX   = %.2f\n", tmut_s / tdec_s);
   printf("UNSAFE/READ SPEEDUP OVER DEC = %.2f\n\n", tdec_s / tser_s);

   printf("FINDING SPEED OF PARALLEL COUNTER CHANGING USING %ld REPS %d PROC\n",
          (long int) nreps, ATL_NTHREADS);

@beginskip
   for (i=0; i < ATL_NTHREADS-1; i++)
      timearr[i] = -1.0;
   acnts = malloc(ATL_NTHREADS*sizeof(void*));
   ATL_assert(acnts);
   lcnt = nreps / ATL_NTHREADS;
   for (i=0; i < ATL_NTHREADS-1; i++)
      acnts[i] = ATL_SetAtomicCount(lcnt);
   acnts[ATL_NTHREADS-1] = ATL_SetAtomicCount(lcnt + nreps-lcnt*ATL_NTHREADS);
   ATL_goparallel(ATL_NTHREADS, TuneDoWork_loc, NULL, NULL);
   for (tldec=0.0,i=0; i < ATL_NTHREADS; i++)
      tldec = Mmax(tldec,timearr[i]);
   printf("   parallel LocAD  time = %e (par/ser = %.2f)\n",tldec,tldec/tdec_s);
   for (i=0; i < ATL_NTHREADS; i++)
      ATL_FreeAtomicCount(acnts[i]);
   free(acnts);
@endskip

   acnt = ATL_SetGlobalAtomicCount(ATL_NTHREADS, nreps, 0);
   ATL_goparallel(ATL_NTHREADS, TuneDoWork_gc, NULL, NULL);
   for (tldec=0.0,i=0; i < ATL_NTHREADS; i++)
      tldec = Mmax(tldec,timearr[i]);
   ATL_FreeGlobalAtomicCount(acnt);
   printf("   parallel GblDec time = %e (par/ser = %.2f)\n", 
          tldec, tldec/tdec_s);

   acnt = ATL_SetAtomicCount_mut(nreps);
   acnt = ATL_SetAtomicCount(nreps);
   ATL_goparallel(ATL_NTHREADS, TuneDoWork, NULL, NULL);
   for (tdec=0.0,i=0; i < ATL_NTHREADS; i++)
      tdec = Mmax(tdec,timearr[i]);
   ATL_FreeAtomicCount(acnt);
   printf("   parallel AtoDec time = %e (par/ser = %.2f)\n", tdec, tdec/tdec_s);

   acnt = ATL_SetAtomicCount_mut(nreps);
   ATL_goparallel(ATL_NTHREADS, TuneDoWork_mut, NULL, NULL);
   for (tmut=0.0,i=0; i < ATL_NTHREADS; i++)
      tmut = Mmax(tmut,timearr[i]);
   ATL_FreeAtomicCount_mut(acnt);
   printf("   parallel mutex  time = %e (par/ser = %.2f)\n", tmut, tmut/tmut_s);

   count = nreps;
   acnt = ATL_SetAtomicCount_mut(nreps);
   ATL_goparallel(ATL_NTHREADS, TuneDoWork_ser, NULL, NULL);
   for (tser=0.0,i=0; i < ATL_NTHREADS; i++)
      tser = Mmax(tser,timearr[i]);
   ATL_FreeAtomicCount_mut(acnt);
   printf("   parallel unsafe time = %e (par/ser = %.2f)\n", tser, tser/tser_s);

   #ifdef PentiumCPS
      t0 = 1000000.0*PentiumCPS;
      printf("   CYCLES PER CALL: SER=%.1f, DEC=%.1f, GBLDEC=%.1f, MUT=%.1f\n", 
             t0*(tser/nreps), t0*(tdec/nreps), t0*(tldec/nreps), 
             t0*(tmut/nreps));
   #endif
   t0 = 1000000.0 / nreps;
   printf(
   "   MICROSECONDS PER CALL: SER=%.2f DEC=%.2f, GBLDEC=%.2f, MUT=%.2f\n", 
          tser*t0, tdec*t0, tldec*t0, tmut*t0);
   printf("DEC TIME SPEEDUP OVER MUTEX   = %.2f\n", tmut / tdec);
   printf("GBLDEC TIME SPEEDUP OVER MUTEX   = %.2f\n", tmut / tldec);
/*
 * Change nothing unless outfile is non-NULL
 */
   if (outfile)
   {
      FILE *fpout;
/*
 *    If my assembly isn't noticably faster than the mutex code, just use the
 *    the mutex code
 */
      if (tmut < tldec*1.02)
      {
         printf("\nNO REAL ADVANTAGE TO ASSEMBLY, FORCING USE OF MUTEX\n");
         ATL_assert(!system("make iForceUseMutex"));
      }
   }
   free(timearr);
   return(0);
}
@ROUT tune_aff
#include "atlas_taffinity.h"
@ROUT tune_aff tune_spawn_fp
#include "atlas_threads.h"
#define DREAL
#include "atlas_misc.h"

@ROUT tune_aff
void ATL_goparallel_noaff
   (const unsigned int P, void *DoWork, void *opstruct, void *DoComb);

@ROUT tune_spawn_fp
@whiledef suff log2 lin dyn
void goparallel_@(suff)
   (const unsigned int P, void *DoWork, void *opstruct, void *DoComb);
@endwhile
@ROUT tune_aff tune_spawn_fp
typedef struct
{
   size_t nflops;               /* number of flops to perform */
   volatile double *V;          /* 16-length array of zeros */
   int rank, nthr;
} ATL_TUNE_T;


void InCacheGemm
(
   size_t nflops,               /* how many flops to do */
   volatile double *V           /* 16-length array of zeros */
)
/*
 * This routine emulates an in-cache 4x4 GEMM, but using only 16 registers
 * V is declared volatile so compiler doesn't get rid of the loop.
 */
{
   size_t i;
   register double c0, c1, c2, c3, c4, c5, c6, c7;
   register double a0, a1, a2, a3, b0, b1, b2, b3;

   a0 = *V;   b0 = V[4];
   a1 = V[1]; a2 = V[2];
   c0 = c1 = c2 = c3 = c4 = c5 = c6 = c7 = ATL_rzero;
   for (i=(nflops>>5); i; i--)
   {
      c0 += a0*b0; a3 = V[3];
      c1 += a1*b0;
      c2 += a2*b0; b1 = V[5];
      c3 += a3*b0;
      c4 += a0*b1; b2 = V[6];
      c5 += a1*b1;
      c6 += a2*b1;
      c7 += a3*b1;
      c0 += a0*b2; b3 = V[7];
      c1 += a1*b2;
      c2 += a2*b2; b0 = V[4];
      c3 += a3*b2;
      c4 += a0*b3; a0 = *V;  
      c5 += a1*b3; a1 = V[1];
      c6 += a2*b3; a2 = V[2];
      c7 += a3*b3;
   }
   *V = c0;   V[1] = c1; V[2] = c2; V[3] = c3;
   V[4] = c4; V[5] = c5; V[6] = c6; V[7] = c7;
}

void TuneDoWork_gp(ATL_LAUNCHSTRUCT_t *lp, void *vp)
{
   ATL_TUNE_T *tp = lp->opstruct;
   int i;
   InCacheGemm(tp->nflops, tp->V);
}

void TuneDoWork(ATL_LAUNCHSTRUCT_t *lp, void *vp)
{
   ATL_TUNE_T *tp = lp->opstruct;
   int i;
   InCacheGemm(tp->nflops, tp->V);
}

@ROUT tune_aff
void PrintUsage(char *exe)
{
   fprintf(stderr, "USAGE: %s [-r <reps>] -m/k/f [m/k/flops] -o outfile\n", 
           exe);
   exit(-1);
}

int GetFlags(int nargs, char **args, size_t *nflop, char **outfile)
{
   int i, reps=50, imul;

   *outfile = NULL;
   *nflop = 2*300 * 300 * 300;  /* emulate 300x300 DGEMM */
   for (i=1; i < nargs; i++)
   {
      imul = 1;
      if (args[i][0] != '-')
         PrintUsage(args[0]);
      switch(args[i][1])
      {
      case 'r':
         if (++i >= nargs)
            PrintUsage(args[0]);
         reps = atoi(args[i]);
         break;
      case 'm':
         imul *= 1000;
      case 'k':
         imul *= 1000;
      case 'f':
         if (++i >= nargs)
            PrintUsage(args[0]);
         *nflop = atoll(args[i]) * imul;
         break;
      case 'o':
         if (++i >= nargs)
            PrintUsage(args[0]);
         *outfile = args[i];
         break;
      default:
         PrintUsage(args[0]);
      }
   }
   return(reps);
}
int main(int nargs, char **args)
{
#ifndef ATL_OMP_THREADS
   size_t nflops;
   int i, k, nreps = 200, opstride, which;
   double t0, taff, tnoa;
   ATL_TUNE_T ta[ATL_NTHREADS];
   volatile double *V;
   void *vp[ATL_NTHREADS];
   char *outfile;


   taff = tnoa = 0.0;
   nreps = GetFlags(nargs, args, &nflops, &outfile);

   for (i=0; i < ATL_NTHREADS; i++)
   {
      ta[i].rank = i;
      ta[i].nthr = ATL_NTHREADS;
      ta[i].nflops = nflops;
      vp[i] = malloc(sizeof(double)*16 + ATL_Cachelen);
      ATL_assert(vp[i]);
      ta[i].V = ATL_AlignPtr(vp[i]);
      ATL_dzero(16, (double*)ta[i].V, 1);  /* zero w/o telling compiler */
   }
   opstride = (int) ( ((char*)(ta+1)) - (char*)(ta) );

   printf("FINDING WHETHER AFFINITY IS HELPFUL USING FLOPS=%e NREPS=%d\n",
          (double)nflops, nreps);

   t0 = ATL_walltime();
   for (k=0; k < nreps; k++)
      ATL_goparallel(ATL_NTHREADS, TuneDoWork, ta, NULL);
   taff = ATL_walltime() - t0;
   printf("   Affinity    time = %e\n", (float)taff);

   t0 = ATL_walltime();
   for (k=0; k < nreps; k++)
      ATL_goparallel_noaff(ATL_NTHREADS, TuneDoWork, ta, NULL);
   tnoa = ATL_walltime() - t0;
   printf("   NO affinity time = %e\n", (float)tnoa);

   printf("Affinity speedup = %.2f\n", (float)(tnoa / taff));

   for (i=0; i < ATL_NTHREADS; i++)
      free(vp[i]);

   if (outfile)  /* if this is a real run where we want to change things */
   {
      if (tnoa*1.04 < taff)
      {
         FILE *fpout;
         printf(
       "Affinity is not helpful on your system, forcing ATLAS not to use it\n");
         fpout = fopen(outfile, "w");
         ATL_assert(fpout);
         fprintf(fpout, "#ifndef ATL_TAFFINITY_H\n   #define ATL_TAFFINITY_H\n");
         fprintf(fpout, "   #define ATL_NOAFFINITY 1\n");
         fprintf(fpout, "#endif\n");
         fclose(fpout);
         fpout = fopen("res/aff.h", "w");
         fprintf(fpout, "#define ATL_TAFFINITY 0\n");
         fclose(fpout);
      }
      else /* affinity was a win */
      {
         FILE *fpout;
         fpout = fopen("res/aff.h", "w");
         fprintf(fpout, "#define ATL_TAFFINITY 1\n");
         fclose(fpout);
      }
   }
#else
   FILE *fpout;
   char *outfile;
   size_t nflops;
   int nreps;

   nreps = GetFlags(nargs, args, &nflops, &outfile);
   if (outfile)
   {
      printf(
      "Not good idea to set affinity wt OpenMP; forcing ATLAS not to use it\n");
      fpout = fopen(outfile, "w");
      ATL_assert(fpout);
      fprintf(fpout, "#ifndef ATL_TAFFINITY_H\n   #define ATL_TAFFINITY_H\n");
      fprintf(fpout, "   #define ATL_NOAFFINITY 1\n");
      fprintf(fpout, "#endif\n");
      fclose(fpout);
      fpout = fopen("res/aff.h", "w");
      fprintf(fpout, "#define ATL_TAFFINITY 0\n");
      fclose(fpout);
   }
#endif
   return(0);
}
@ROUT tune_spawn
#include "atlas_threads.h"
#include "atlas_misc.h"

@ROUT tune_spawn
@beginskip
typedef struct
{
   volatile int *donearr;   /* starts all zero */
   int rank, nthr;
} ATL_TUNE_T;
@endskip

void TuneDoWork(ATL_LAUNCHSTRUCT_t *lp, void *vp)
/* 
 * Use volatile array to check in, and then quit (cache-speed barrier)
 */
{
   ATL_thread_t *tp = vp;
   const int nthr = tp->P, rank=tp->rank;
   int i;
   volatile int *donearr=lp->opstruct;

   donearr[rank] = 1;
   for (i=0; i < nthr; i++)
      while(!donearr[i]);
}
@ROUT tune_spawn tune_spawn_fp

void PrintUsage(char *exe)
{
@ROUT tune_spawn_fp
   fprintf(stderr, 
"USAGE: %s [-r <reps>] [-f flops] [-k <kflops>] [-m <mflops>] -W [which]\n", 
           exe);
@ROUT tune_spawn
   fprintf(stderr, "USAGE: %s [-r <reps>] -W [which]\n", exe);
@ROUT tune_spawn tune_spawn_fp
   fprintf(stderr, 
   "   which: bitfield, 1st bit is dyn, 2nd is lg2, 3rd is linear\n");
   exit(-1);
}

@ROUT tune_spawn_fp
int GetFlags(int nargs, char **args, int *which, size_t *flops)
@ROUT tune_spawn
int GetFlags(int nargs, char **args, int *which)
@ROUT tune_spawn tune_spawn_fp
{
   int i, reps=1;
@ROUT tune_spawn_fp `   int imul=1;`

@ROUT tune_spawn_fp `   *flops = 1000000;`
   *which = 7;
   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0]);
      switch(args[i][1])
      {
      case 'r':
         if (++i >= nargs)
            PrintUsage(args[0]);
         reps = atoi(args[i]);
         break;
      case 'W':
         if (++i >= nargs)
            PrintUsage(args[0]);
         *which = atoi(args[i]);
         break;
@ROUT tune_spawn_fp
      case 'm':
         imul *= 1000;
      case 'k':
         imul *= 1000;
      case 'f':
         if (++i >= nargs)
            PrintUsage(args[0]);
         *flops = imul * atoi(args[i]);
         imul = 1;
         break;
@ROUT tune_spawn tune_spawn_fp
      default:
         PrintUsage(args[0]);
      }
   }
   return(reps);
}
@ROUT tune_spawn
int main(int nargs, char **args)
{
   int i, k, nreps = 200, which;
   double t0, tlin, tlg2, tdyn, trnk;
   volatile int done[ATL_NTHREADS];

   tlg2 = tdyn = tlin = 0.0;
   nreps = GetFlags(nargs, args, &which);

   @define exp @CREATE/BARRIER/JOIN@

   printf("FINDING SPEED OF @(exp) USING %d REPITITIONS:\n", 
          nreps);
   if (which & 1)
   {
      t0 = ATL_walltime();
      for (k=0; k < nreps; k++)
      {
         for (i=0; i < ATL_NTHREADS; i++) done[i] = 0;
         ATL_goparallel_dyn(ATL_NTHREADS, TuneDoWork, done, NULL);
      }
      tdyn = ATL_walltime() - t0;
      printf("   dyn time = %e\n", (float)tdyn);
   }

   if (which & 2)
   {
      t0 = ATL_walltime();
      for (k=0; k < nreps; k++)
      {
         for (i=0; i < ATL_NTHREADS; i++) done[i] = 0;
         ATL_goparallel_log2(ATL_NTHREADS, TuneDoWork, done, NULL);
      }
      tlg2 = ATL_walltime() - t0;
      printf("   lg2 time = %e\n", (float)tlg2);
   }

   if (which & 4)
   {
      t0 = ATL_walltime();
      for (k=0; k < nreps; k++)
      {
         for (i=0; i < ATL_NTHREADS; i++) done[i] = 0;
         ATL_goparallel_lin(ATL_NTHREADS, TuneDoWork, done, NULL);
      }
      tlin = ATL_walltime() - t0;
      printf("   lin time = %e\n", (float)tlin);
   }
   #if 0
   if (which & 8)
   {
      t0 = ATL_walltime();
      for (k=0; k < nreps; k++)
      {
         for (i=0; i < ATL_NTHREADS; i++) done[i] = 0;
         ATL_goparallel_prank(ATL_NTHREADS, TuneDoWork_gp, ta, NULL);
      }
      trnk = ATL_walltime() - t0;
      printf("   rnk time = %e\n", (float)trnk);
   }
   #endif
   if ((which | 7) == which)
      printf("DYNAMIC is %.2f%% of LINEAR and %.2f%% of LOG2 SPEED.\n", 
             (tdyn/tlin)*100.0, (tdyn/tlg2)*100.0);
   if ((which & 1) && (which & 8))
      printf("rank dynamic is %.2f%% of affinity dynamic\n", (trnk/tdyn)*100.0);
   return(0);
}
@ROUT tune_spawn_fp
int main(int nargs, char **args)
{
   int i, k, nreps = 200, opstride, which;
   double t0, tlin, tlg2, tdyn, trnk;
   ATL_TUNE_T ta[ATL_NTHREADS];
   volatile double VV[16];
   tune_spawn_fp `   size_t flops;

   tlg2 = tdyn = tlin = 0.0;
   nreps = GetFlags(nargs, args, &which, &flops);

   for (i=0; i < ATL_NTHREADS; i++)
   {
      ta[i].rank = i;
      ta[i].nthr = ATL_NTHREADS;
      ta[i].nflops = flops;
      ta[i].V = VV;
   }
   for (i=0; i < 16; i++)
      VV[i] = ATL_rzero;
   @define exp @CREATE/DGEMM/JOIN@
   opstride = (int) ( ((char*)(ta+1)) - (char*)(ta) );

   printf("FINDING SPEED OF @(exp) USING %d REPITITIONS:\n", 
          nreps);
   if (which & 1)
   {
      t0 = ATL_walltime();
      for (k=0; k < nreps; k++)
      {
         ATL_goparallel_dyn(ATL_NTHREADS, TuneDoWork, ta, NULL);
      }
      tdyn = ATL_walltime() - t0;
      printf("   dyn time = %e\n", (float)tdyn);
   }

   if (which & 2)
   {
      t0 = ATL_walltime();
      for (k=0; k < nreps; k++)
      {
         ATL_goparallel_log2(ATL_NTHREADS, TuneDoWork, ta, NULL);
      }
      tlg2 = ATL_walltime() - t0;
      printf("   lg2 time = %e\n", (float)tlg2);
   }

   if (which & 4)
   {
      t0 = ATL_walltime();
      for (k=0; k < nreps; k++)
      {
         ATL_goparallel_lin(ATL_NTHREADS, TuneDoWork, ta, NULL);
      }
      tlin = ATL_walltime() - t0;
      printf("   lin time = %e\n", (float)tlin);
   }
   if (which & 8)
   {
      t0 = ATL_walltime();
      for (k=0; k < nreps; k++)
      {
         ATL_goparallel_prank(ATL_NTHREADS, TuneDoWork_gp, ta, NULL);
      }
      trnk = ATL_walltime() - t0;
      printf("   rnk time = %e\n", (float)trnk);
   }
   if ((which | 7) == which)
      printf("DYNAMIC is %.2f%% of LINEAR and %.2f%% of LOG2 SPEED.\n", 
             (tdyn/tlin)*100.0, (tdyn/tlg2)*100.0);
   if ((which & 1) && (which & 8))
      printf("rank dynamic is %.2f%% of affinity dynamic\n", (trnk/tdyn)*100.0);
   return(0);
}
@ROUT DoFlops_amd64.S
#include "atlas_asm.h"
/* 
 * function is: void DoFlops(size_t nflops);
 */
#define nflops  %rdi
#define N       %rax
#define ZR  %xmm0
#define A0  %xmm1
#define B0  %xmm2
#define B1  %xmm3
#define B2  %xmm4
#define B3  %xmm5
#define B4  %xmm6
#define C0  %xmm7
#define C1  %xmm8
#define C2  %xmm9
#define C3  %xmm10
#define C4  %xmm11
#define C5  %xmm12
#define C6  %xmm13
#define C7  %xmm14

.text
.globl ATL_asmdecor(DoFlops)
ATL_asmdecor(DoFlops):
/*
 * Zero all xmm regs
 */
   xorps %xmm0, %xmm0
   xorps %xmm1, %xmm1
   xorps %xmm2, %xmm2
   xorps %xmm3, %xmm3
   xorps %xmm4, %xmm4
   xorps %xmm5, %xmm5
   xorps %xmm6, %xmm6
   xorps %xmm7, %xmm7
   xorps %xmm8, %xmm8
   xorps %xmm9, %xmm9
   xorps %xmm10, %xmm10
   xorps %xmm11, %xmm11
   xorps %xmm12, %xmm12
   xorps %xmm13, %xmm13
   xorps %xmm14, %xmm14
   xorps %xmm15, %xmm15
/* 
 * This loop adds into 8 different accumulators, after doing a chained
 * multiplication.  The number of flops is therefore:
 *   (veclen)*(vecflops)*(naccum) = 4 * 2 * 8 = 64 flops/iteration
 */
   movq nflops, N
   shr  $6, N      /* N = nflops / 64 */
   LOOPN:
/*
 *    On Intel chips, you need to write all read registers once every loop
 *    iteration, or you cannot achieve peak.
 */
      mulps A0, B0
      addps B0, C0
      mulps A0, B1
      addps B1, C1
      mulps A0, B2
      addps B2, C2
      mulps A0, B3
      addps B3, C3
      mulps A0, B0
      addps B0, C4
      mulps A0, B1
      addps B1, C5
      mulps A0, B2
      addps B2, C6
      mulps A0, B3
      addps B3, C7
      #ifdef Intel
         xorps A0, A0
      #endif
   sub $1, N
   jnz LOOPN

ret
@ROUT ammtim
/*
 * Set quitTHR to have some threads within the 4 contexts not be actice.
 * Compile with MANAGE_NODES defined to get code that explicitly manages
 * multiple threads per core.  It will then look at NPA for the number
 * of active partners within the node (# of threads/core to explicitly
 * manage).  This number should be [2-4] (1 should just use unmanaged
 * code).
 * Set KSYNC to get threads that proceed in lockstep for k-loop as well.
 * KSYNC will have extra idle time to enforce lack of cache thrashing.
 *
 */
#define _GNU_SOURCE 1 /* what manpage says you need to get CPU_SET */
#define __USE_GNU   1 /* what you actually have to set on linuxes I've seen */
#include <sched.h>    /* must include this before pthreads */
#include <pthread.h>
#include <assert.h>
#include "atlas_misc.h"
#include "atlas_threads.h"
#include Mstr(Mjoin(Mjoin(atlas_,PRE),amm_sum.h))
#include Mstr(Mjoin(Mjoin(atlas_,UPR),amm_blk.h))
#include Mstr(Mjoin(Mjoin(atlas_,UPR),amm_kern.h))
#include Mstr(Mjoin(Mjoin(atlas_,UPR),amm_ablk2cmat.h))

#ifdef ATL_ARCH_XeonPHI
   #define ATL_tyield __asm__ __volatile__ ("delay %0" :: "r"(4) : "0" )
#else
   #define ATL_tyield pthread_yield()
#endif

static int quitTHR=0, NPA=4;
typedef struct ammjob ammjob_t;
struct ammjob
{
   int *tids;
   int P;
   int INDX;
   int mb, nb, kb;
   int nmblks, nnblks, nkblks;
   void *Cctr;   /* global counter of nblksC */
   TYPE *A, *B, *C;
};
typedef struct thrstruct thr_t;
struct thrstruct
{
   pthread_t pthr;
   int tid;
   int rank;
   void *vp;
   double tstart, tend, ts1, te1, ts2, te2;
   #ifdef MANAGE_NODES
      volatile int chk[5];
   #endif
};

void PrintUsage(char *exe, int iarg, char *arg)
{
   printf("\nERROR around arg %d (%s).\n", iarg, arg ? arg:"unknown");
   printf("\nUSAGE: %s [flags]\n", exe);
   printf("   -p # : spawn to tids 0...(#-1)\n");
   printf("   -P # <t0> .... <t#-1>: spawn # threads to given tids\n");
   printf("   -b[m,n,k]: set blocking for given dim\n");
   printf("   -B # : mb=nb=kb=#\n");
   printf("   -n[m,n,k]: set number of blks along given dim\n");
   printf("   -N # : nblks each dim = #\n");
   printf("   -I <#>: use AMM kernel index #\n");
   printf("   -Q <#>: threads rank%%4 > # quit\n");
   exit(-1);
}

ammjob_t *GetFlags(int nargs, char **args)
{
   int *tids=NULL;
   int P=4, nmblks=20, nnblks=20, nkblks=20;
   int mb=0, nb=0, kb=0;
   int i, j, I = ATL_AMM_NCASES-1;
   static ammjob_t aj;
   char ch;

   for (i=1; i < nargs; i++)
   {
      if (args[i][0] != '-')
         PrintUsage(args[0], i, args[i]);
      switch(args[i][1])
      {
      case 'Q':
         if (++i >= nargs)
            PrintUsage(args[0], i, "out of arguments");
         quitTHR = atoi(args[i]);
         break;
      case 'I':
         if (++i >= nargs)
            PrintUsage(args[0], i, "out of arguments");
         I = atoi(args[i]);
         break;
      case 'B':
         if (++i >= nargs)
            PrintUsage(args[0], i, "out of arguments");
         mb = nb = kb = atoi(args[i]);
         break;
      case 'N':
         if (++i >= nargs)
            PrintUsage(args[0], i, "out of arguments");
         nmblks = nnblks = nkblks = atoi(args[i]);
         break;
      case 'n':
         ch = args[i][2];
         if (++i >= nargs)
            PrintUsage(args[0], i, "out of arguments");
         j = atoi(args[i]);
         if (ch == 'm')
            nmblks = atoi(args[i]);
         else if (ch == 'n')
            nnblks = atoi(args[i]);
         else if (ch == 'k')
            nkblks = atoi(args[i]);
         else
            PrintUsage(args[0], i-1, "bad modifier to -n");
         break;
      case 'b':
         ch = args[i][2];
         if (++i >= nargs)
            PrintUsage(args[0], i, "out of arguments");
         j = atoi(args[i]);
         if (ch == 'm')
            mb = atoi(args[i]);
         else if (ch == 'n')
            nb = atoi(args[i]);
         else if (ch == 'k')
            kb = atoi(args[i]);
         else
            PrintUsage(args[0], i-1, "bad modifier to -b");
         break;
      case 'P':
         if (++i >= nargs)
            PrintUsage(args[0], i, "out of arguments");
         P = atoi(args[i]);
         tids = malloc(sizeof(int)*P);
         assert(tids);
         for (j=0; j < P; j++)
         {
            if (++i >= nargs)
               PrintUsage(args[0], i, "out of arguments");
            tids[j] = atoi(args[i]);
         }
         break;
      case 'p':
         if (++i >= nargs)
            PrintUsage(args[0], i, "out of arguments");
         P = atoi(args[i]);
         break;
      default :
         PrintUsage(args[0], i, args[i]);
      }
   }
   if (!mb)
      mb = ATL_AMM_MBs[I];
   if (!nb)
      nb = ATL_AMM_NBs[I];
   if (!kb)
      kb = ATL_AMM_KBs[I];
   NPA = Mmin(4,P);
   if (quitTHR)
      NPA = 4 - quitTHR;
   if (P < NPA)
      NPA = P;
   if (!tids)
   {
      tids = malloc(sizeof(int)*P);
      assert(tids);
      for (i=0; i < P; i++)
         tids[i] = i;
   }

   aj.P = P;
   aj.tids = tids;
   aj.mb = mb;
   aj.nb = nb;
   aj.kb = kb;
   aj.nmblks = nmblks;
   aj.nnblks = nnblks;
   aj.nkblks = nkblks;
   aj.INDX = I;
   return(&aj);
}


#ifndef MANAGE_NODES
void *DoAmm(void *vp)
{
   thr_t *tp = vp;
   ammjob_t *aj=tp->vp;
   const int nmblks=aj->nmblks, nnblks=aj->nnblks, nkblks=aj->nkblks;
   const int nblksC=nmblks*nnblks, rank=tp->rank;
   const int mb=aj->mb, nb=aj->nb, kb=aj->kb;
   const size_t panAsz=kb*mb*nkblks, panBsz=kb*nb*nkblks; 
   const int blkAsz=mb*kb, blkBsz=kb*nb, blkCsz=mb*nb;
   const int M=mb*nmblks, N=nb*nnblks, K=kb*nkblks;
   const int IX=aj->INDX; 
   const int mu=ATL_AMM_MUs[IX], nu=ATL_AMM_NUs[IX], ku=ATL_AMM_KUs[IX]; 
   const int nmu = mb/mu, nnu = nb/nu;
   int I;
   ammkern_t amm;
   ablk2cmat_t blk2c;
   const TYPE *A=aj->A, *B=aj->B;
   TYPE *C = aj->C, *w;
   double t0;

   #ifdef PRINT_COREID
      printf("core=%d\n", sched_getcpu());
   #endif
   tp->tstart = ATL_walltime();
   if (quitTHR)
   {
      if (tp->rank - (((tp->rank)>>2)<<2) >= quitTHR)
      {
         tp->tend = ATL_walltime();
         pthread_exit(NULL);
      }
   }
   vp = malloc(2*ATL_MulBySize(blkCsz)+ATL_Cachelen);
   assert(vp);
   w = ATL_AlignPtr(vp);
   amm = ATL_AMM_KERN_b1[IX];
   blk2c = ATL_AMM_BLK2C_an_b1[IX];
   while (I = ATL_DecGlobalAtomicCount(aj->Cctr, rank))
   {
      size_t i, j;
      int k;
      TYPE *c;
      const TYPE *a, *b;

      I = nblksC-I;
      j = I / nmblks;
      i = I - j*nmblks;
      c = C + j*M+i;
      a = A + i*panAsz;
      b = B + j*panBsz;
      for (k=0; k < nkblks; k++)
      {
         const TYPE *an = a+blkAsz, *bn = b+blkBsz;
         amm(nmu, nnu, kb, a, b, w, an, bn, w);
         a = an;
         b = bn;
      }
      blk2c(mb, nb, -1.0, w, 1.0, c, M);
   }
   free(vp);
   tp->tend = ATL_walltime();
   return(NULL);
}
#else
void *DoAmm(void *vp)
{
   thr_t *tp = vp;
   ammjob_t *aj=tp->vp;
   const int nmblks=aj->nmblks, nnblks=aj->nnblks, nkblks=aj->nkblks;
   const int nblksC=nmblks*nnblks, rank=tp->rank;
   const int mb=aj->mb, nb=aj->nb, kb=aj->kb;
   const size_t panAsz=kb*mb*nkblks, panBsz=kb*nb*nkblks; 
   const int blkAsz=mb*kb, blkBsz=kb*nb, blkCsz=mb*nb;
   const int M=mb*nmblks, N=nb*nnblks, K=kb*nkblks;
   const int IX=aj->INDX; 
   const int mu=ATL_AMM_MUs[IX], nu=ATL_AMM_NUs[IX], ku=ATL_AMM_KUs[IX]; 
   const int nmu = mb/mu, nnu = nb/nu;
   const int myd = rank%NPA;
   int I;
   volatile int *chk;
   ammkern_t amm;
   ablk2cmat_t blk2c;
   const TYPE *A=aj->A, *B=aj->B;
   TYPE *C = aj->C, *w;
   double t0;

   #ifdef PRINT_COREID
      printf("core=%d\n", sched_getcpu());
   #endif
   tp->tstart = ATL_walltime();
   if (quitTHR)
   {
      if (tp->rank - (((tp->rank)>>2)<<2) >= quitTHR)
      {
         tp->tend = ATL_walltime();
         pthread_exit(NULL);
      }
   }
   vp = malloc(2*ATL_MulBySize(blkCsz)+ATL_Cachelen);
   assert(vp);
   w = ATL_AlignPtr(vp);
   amm = ATL_AMM_KERN_b1[IX];
   blk2c = ATL_AMM_BLK2C_an_b1[IX];
/*
 * Active partner awaits for everyone else to check in
 */
   if (!myd)
   {
      int p;
      chk = tp->chk;
   }
   else
   {
      thr_t *ta = tp - myd;
      chk = ta->chk;
   }
   while (1)
   {
      size_t i, j;
      int k;
      TYPE *c;
      const TYPE *a, *b;

      if (!myd)
      {
         int p;
         const int ov=chk[0];
         I = ATL_DecGlobalAtomicCount(aj->Cctr, rank);
         if (!I)
         {
            chk[4] = -4;
            (*chk)++;
            break;
         }
         chk[4] = I = nblksC-I*NPA;
         for (p=1; p < NPA; p++)
              while(chk[p] <= ov)
                 ATL_tyield;
         (*chk)++;
      }
      else
      {
         const int ov=chk[myd]++;
         while (*chk <= ov)
            ATL_tyield;
         I = chk[4];
         if (I == -4)
            break;
      }
      j = I / nmblks;
      i = I - j*nmblks + myd;
      c = C + j*M+i;
      a = A + i*panAsz;
      b = B + j*panBsz;
      for (k=0; k < nkblks; k++)
      {
         const TYPE *an = a+blkAsz, *bn = b+blkBsz;
         amm(nmu, nnu, kb, a, b, w, an, bn, w);
         #ifdef KSYNC
@skip         if (k != nkblks-1)
@skip         {
            if (!myd)
            {
               int p;
               const int ov = *chk;
               for (p=1; p < NPA; p++)
                  while (chk[p] <= ov)
                     ATL_tyield;
               (*chk)++;
            }
            else
            {
               const int ov = chk[myd]++;
               while (*chk <= ov)
                  ATL_tyield;
            }
@skip         }
         #endif
         a = an;
         b = bn;
      }
      blk2c(mb, nb, -1.0, w, 1.0, c, M);
/*
 *    If we aren't doing K-sync, then master thread must await workers
 */
      #ifndef KSYNC
      if (!myd)
      {
         const int ov = *chk;
         int p;
         for (p=1; p < NPA; p++)
            while(chk[p] < ov)
               ATL_tyield;
      }
      #endif
   }
   DONE:
   free(vp);
   tp->tend = ATL_walltime();
   return(NULL);
}
#endif

void *DoSpawn(void *vp)
{
   ammjob_t *aj=vp;
   cpu_set_t cpuset;
   pthread_attr_t attr;
   thr_t *tp;
   const int P=aj->P;
   int i;
   double t0;

   t0 = ATL_walltime();
   assert(!pthread_attr_init(&attr));
   tp = malloc(P*sizeof(thr_t));
   tp->ts1 = t0;
   assert(tp);
   for (i=1; i < P; i++)
   {
      tp[i].rank = i;
      tp[i].vp = aj;
      tp[i].tid = aj->tids[i];
      #ifdef MANAGE_NODES
         tp[i].chk[0] = tp[i].chk[1] = tp[i].chk[2] = tp[i].chk[3] = -2;
      #endif
      CPU_ZERO(&cpuset);
      CPU_SET(aj->tids[i], &cpuset);
      assert(!pthread_attr_setaffinity_np(&attr, sizeof(cpuset), &cpuset));
      pthread_create(&(tp[i].pthr), &attr, DoAmm, tp+i);
   }
   tp[0].rank = 0;
   tp[0].vp = aj;
   tp[0].tid = aj->tids[0];
   DoAmm(tp);
   for (i=1; i < P; i++)
      pthread_join(tp[i].pthr, NULL);
   tp->te1 = ATL_walltime();
   return(tp);
}

void TimeOnCores(ammjob_t *aj)
{
   const int P=aj->P; 
   const int mb=aj->mb, nb=aj->nb, kb=aj->kb;
   const int nmblks=aj->nmblks, nnblks=aj->nnblks, nkblks=aj->nkblks;
   const int nblksA=nmblks*nkblks, nblksB=nkblks*nnblks, nblksC=nmblks*nnblks;
   size_t szA=nblksA*kb*mb, szB=nblksB*kb*nb, szC=nblksC*mb*nb;
   int i, nctrs;
   TYPE *A, *B, *C;
   void *vp;
   thr_t *tp;
   pthread_attr_t attr;
   pthread_t pthr0;
   cpu_set_t cpuset;
   double beg, end, mf;

   beg = ATL_walltime();
/*
 * Get space, init to 0 so we can just use
 */
   vp = calloc(ATL_MulBySize(szA+szB+szC+mb*nb)+3*ATL_Cachelen, 
               ATL_MulBySize(1));
   assert(vp);
   aj->A = A = ATL_AlignPtr(vp);
   B = A + szA;
   aj->B = B = ATL_AlignPtr(B);
   C = B + szB;
   aj->C = C = ATL_AlignPtr(C);
/*
 * Compute # of global ctrs to use, get global atomic counter
 */
   #ifdef MANAGE_NODES
      assert(nmblks%NPA == 0);
      i = (nmblks/NPA)*nnblks;
   #else
      i = nmblks*nnblks;
   #endif
   if (P > 16)
      nctrs = 8;
   else if (P > 3)
      nctrs = 2;
   else
      nctrs = 1;
   if (nctrs > (i>>5))
      nctrs = (i > 32) ? (i>>5) : 1;
   aj->Cctr = ATL_SetGlobalAtomicCount(nctrs, i, 0);
/*
 * Create thr0, which will then spawn everything else and then do problem
 */
   CPU_ZERO(&cpuset);
   CPU_SET(aj->tids[0], &cpuset);
   assert(!pthread_attr_init(&attr));
   if (i=pthread_attr_setaffinity_np(&attr, sizeof(cpuset), &cpuset))
   {
      fprintf(stderr, "CANNOT SET AFFINITY TO %d, error=%d\n", aj->tids[0], i);
      exit(-1);
   }
   pthread_create(&pthr0, &attr, DoSpawn, (void*)aj);
   pthread_join(pthr0, (void**)&tp);
   end = ATL_walltime();
   mf = (2.0*nmblks)*nnblks*nkblks*mb*nb*kb;
   mf /= (end-beg) * 1000000.0;
   printf("Special thread-0 timings:\n");
   printf("   startup    = %e\n", tp->ts1-beg);
   printf("   spawn time = %e\n", tp->tstart-tp->ts1);
   printf("   compute    = %e\n", tp->tend-tp->tstart);
   printf("   join  time = %e\n", tp->te1-tp->tend);
   printf("\nMFLOP = %.2f, TOTAL TIME=%e\n", mf, end-beg);

   free(vp);
}
int main(int nargs, char **args)
{
   ammjob_t *aj;
   aj = GetFlags(nargs, args);
   TimeOnCores(aj);
}
