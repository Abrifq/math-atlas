@ROUT ATL_dammm2x4x1_sse2.S ATL_dammm2x4x256_sse2.S
   @define mu @4@
   @define nu @4@
@ROUT ATL_dammm3x3x256_sse2.S
   @define mu @6@
   @define nu @3@
@ROUT ATL_dammm2x4x1_sse2.S ATL_dammm2x4x256_sse2.S ATL_dammm3x3x256_sse2.S
@extract -b @(topd)/gen.inc what=crsetup
@extract -b @(topd)/cw.inc lang=c -define cwdate 2012
#include "atlas_asm.h"
#define movapd movaps
#define nmu     %rdi
#define nnu     %rsi
#define nnu0    %r10
@ROUT ATL_dammm2x4x1_sse2.S
#define KK      %rdx
#define KK0     %r11
#define pA      %rcx
#define pB      %rax
#define pC      %r9
#define pf      %rbp
#define pB0     %r12
#define incPF   %rbx
#define pA0     %r13
#define incAm   %r14
#define pfB     %r15
#define FSIZE 6*8
@ROUT ATL_dammm2x4x256_sse2.S ATL_dammm3x3x256_sse2.S
#define pA      %rcx
#define pB      %rax
#define pC      %r9
#define pf      %rbp
#define pB0     %r12
#define incPF   %rbx
#define pfB     %rdx
#define incAm   %r11 
@ROUT ATL_dammm2x4x256_sse2.S
#define pfC     %r13
@ROUT ATL_dammm3x3x256_sse2.S

#define rA0     %xmm0
#define rA1     %xmm1
#define rA2     %xmm2
#define rB0     %xmm3
#define rB1     %xmm4
#define rB2     %xmm5
#define rC00    %xmm6
#define rC10    %xmm7
#define rC20    %xmm8
#define rC01    %xmm9
#define rC11    %xmm10
#define rC21    %xmm11
#define rC02    %xmm12
#define rC12    %xmm13
#define rC22    %xmm14
#define rm0     %xmm15
#define FSIZE 4*8
@ROUT ATL_dammm2x4x1_sse2.S
#define FSIZE 6*8
@ROUT ATL_dammm2x4x256_sse2.S
#define FSIZE 4*8
@ROUT ATL_dammm2x4x1_sse2.S ATL_dammm2x4x256_sse2.S

#define rA0     %xmm0
#define rA1     %xmm1
#define rB0     %xmm2
#define rB1     %xmm3
#define rB2     %xmm4
#define rB3     %xmm5
#define rC00    %xmm6
#define rC10    %xmm7
#define rC01    %xmm8
#define rC11    %xmm9
#define rC02    %xmm10
#define rC12    %xmm11
#define rC03    %xmm12
#define rC13    %xmm13
#define rm0     %xmm14
@ROUT ATL_dammm2x4x1_sse2.S ATL_dammm2x4x256_sse2.S 
#define unpckhpd movhlps
@ROUT ATL_dammm2x4x1_sse2.S ATL_dammm2x4x256_sse2.S ATL_dammm3x3x256_sse2.S
/* #define movddup pshufd $0x44, */
#ifndef pref
   #define pref prefetcht1
#endif
#ifndef prefB
   #define prefB prefetcht1
#endif
#ifndef prefC
   #ifdef ATL_3DNow
      #define prefC prefetchw
   #else
      #define prefC prefetcht0
   #endif
#endif
#ifdef BETAN1
   #define BETCOP subpd
#else
   #define BETCOP addpd
#endif
/*
                    rdi      rsi    rdx        rcx         r8        r9  
void ATL_USERMM(SZT nmu, SZT nnu, SZT K, CTYPE *pA, CTYPE *pB, TYPE *pC, 
                  8(%rsp)    16(%rsp)     24(%rsp)   
                CTYPE *pAn, CTYPE *pBn, CTYPE *pCn);
 */
.text
.global ATL_asmdecor(ATL_USERMM)
ALIGN16
ATL_asmdecor(ATL_USERMM):
/*
 * Save callee-saved iregs
 */
   sub $FSIZE, %rsp
   movq    %rbp, 0(%rsp)
   movq    %rbx, 8(%rsp)
   movq    %r12, 16(%rsp)
@ROUT ATL_dammm2x4x1_sse2.S ATL_dammm2x4x256_sse2.S
   movq    %r13, 24(%rsp)
@ROUT ATL_dammm2x4x1_sse2.S 
   movq    %r14, 32(%rsp)
   movq    %r15, 40(%rsp)
@ROUT ATL_dammm2x4x1_sse2.S ATL_dammm2x4x256_sse2.S ATL_dammm3x3x256_sse2.S
/*
 * Load paramaters
 */
   movq %r8, pB
   mov nnu, nnu0
   movq FSIZE+16(%rsp), pf      /* pf = pBn */
   movq FSIZE+8(%rsp), pfB      /* pfB = pAn */
@ROUT ATL_dammm2x4x1_sse2.S ATL_dammm3x3x256_sse2.S
   cmp pf, pB                   /* if (pBn == pB) */
   CMOVE pfB, pf                /* if (pBn == pB) pfB = pAn */
   CMOVEq FSIZE+24(%rsp), pfB   /* if (pbN == pB) pfB = pCn */
@ROUT ATL_dammm2x4x256_sse2.S
   movq FSIZE+24(%rsp), pfC    /* pfC = pCn */
@ROUT ATL_dammm2x4x1_sse2.S ATL_dammm2x4x256_sse2.S ATL_dammm3x3x256_sse2.S
@beginskip
   cmp $0, pf
   je BADPFB
   cmp pf, pB
   je BADPFB
.local PFSETUP
PFSETUP:
   movq FSIZE+8(%rsp), pfB
   cmp $0, pfB
   je BADPF_2
   cmp pf, pA
   je BADPF_2
PFSETUP_2:
@endskip
   mov $8*@(mu)*@(nu), incPF
@ROUT ATL_dammm2x4x256_sse2.S ATL_dammm3x3x256_sse2.S
/*
 * Extend range of small operands by starting at -128
 */
@ROUT ATL_dammm3x3x256_sse2.S `         movddup (pB), rC00`
   sub $-128, pA
   sub $-128, pB
   mov $KB*@(mu)*8, incAm           /* incAm = KB*MU*size */
@ROUT ATL_dammm3x3x256_sse2.S
   sub $-128, pf
   sub $-128, pC
   sub $-128, pfB
@ROUT ATL_dammm2x4x1_sse2.S
   mov KK, incAm                /* incAm = K */
   shl $5, incAm                /* incAm = K*MU*size = K*4*8 = K*32 = K << 5 */
   mov KK, KK0
   mov pA, pA0
@ROUT ATL_dammm2x4x1_sse2.S ATL_dammm2x4x256_sse2.S ATL_dammm3x3x256_sse2.S
   movq pB, pB0

   ALIGN8
   .local MNLOOP
   MNLOOP:
/*
 *       Peel first iteration of K-loop to handle init of C to 0
 */
@ROUT ATL_dammm3x3x256_sse2.S
         movapd  -128(pA), rA0
         movapd rC00, rC10
         mulpd rA0, rC00
         movapd rC10, rC20
         movapd  -112(pA), rA1
         mulpd rA1, rC10
         movapd  -96(pA), rA2
         mulpd rA2, rC20
         movddup -120(pB), rC01
         movapd rC01, rC11
         mulpd rA0, rC01
         movapd rC11, rC21
         mulpd rA1, rC11
         mulpd rA2, rC21
         movddup -112(pB), rC02
         movapd rC02, rC12
         mulpd rA0, rC02
         #if KB > 1
            movddup -104(pB), rB0
         #endif
         movapd rC12, rC22
         mulpd rA1, rC12
            prefC -128(pC)
         mulpd rA2, rC22

ALIGN8
@iexp ao -80 0 +
@iexp bo -96 0 +
@iexp k 1 0 +
@iwhile k < 256
         #if KB > @(k)
   @iexp k @(k) 1 +
            movapd @(ao)(pA), rA0
   @iexp ao @(ao) 16 +
            movapd rA0, rm0
            mulpd rB0, rm0
            addpd rm0, rC00
            movapd @(ao)(pA), rA1
   @iexp ao @(ao) 16 +
            movapd rA1, rm0
            mulpd rB0, rm0
            addpd rm0, rC10
            movapd @(ao)(pA), rA2
   @iexp ao @(ao) 16 +
            movapd rA2, rm0
            mulpd rA2, rB0
            addpd rB0, rC20
   
            movddup @(bo)(pB), rB1
   @iexp bo @(bo) 8 +
            movapd rA0, rm0
            mulpd rB1, rm0
            addpd rm0, rC01
            movddup @(bo)(pB), rB2
   @iexp bo @(bo) 8 +
            movapd rA1, rm0
            mulpd rB1, rm0
            addpd rm0, rC11
            #if KB > @(k)
               movddup @(bo)(pB), rB0
   @iexp bo @(bo) 8 +
            #endif
            mulpd rA2, rB1
            addpd rB1, rC21
   
   @iif k = 2
            prefC -64(pC)
   @endiif
   @iif k = 3
               #if KB < 78
                  pref -128(pf)
               #endif
   @endiif
   @iif k = 4
               #if KB < 72
               prefB -128(pfB)
               #endif
   @endiif
            mulpd rB2, rA0
            addpd rA0, rC02
   @iif k = 3
@skip               pref 64-128(pf)
   @endiif
            mulpd rB2, rA1
            addpd rA1, rC12
   @iif k = 4
               #if KB < 72
               prefB (pfB)
               #endif
   @endiif
   @iif k = 3
               #if KB < 78
               pref 128(pf)
               #endif
   @endiif
            mulpd rB2, rA2
            addpd rA2, rC22
   @iif k = 2
            prefC (pC)
   @endiif
   @iif k = 3
               #if KB < 78
                  add incPF, pf
               #endif
   @endiif
   @iif k = 4
               #if KB < 72
                  add incPF, pfB
               #endif
   @endiif
         #endif
@endiwhile
/*
 *       Bring in C if necessary, and store out final answer
 */
         add $KB*@(nu)*8, pB
         #if defined(BETA1) || defined(BETAN1)
            BETCOP -128(pC), rC00
            movapd rC00, -128(pC)
               movddup -128(pB), rC00
            BETCOP 16-128(pC), rC10
            movapd rC10, 16-128(pC)
            BETCOP 32-128(pC), rC20
            movapd rC20, 32-128(pC)
            BETCOP 48-128(pC), rC01
            movapd rC01, 48-128(pC)
            BETCOP 64-128(pC), rC11
            movapd rC11, 64-128(pC)
            BETCOP 80-128(pC), rC21
            movapd rC21, 80-128(pC)
            BETCOP 96-128(pC), rC02
            movapd rC02, 96-128(pC)
            BETCOP 112-128(pC), rC12
            movapd rC12, 112-128(pC)
            BETCOP (pC), rC22
            movapd rC22, (pC)
         #else
            movapd rC00, -128(pC)
               movddup -128(pB), rC00
            movapd rC10, 16-128(pC)
            movapd rC20, 32-128(pC)
            movapd rC01, 48-128(pC)
            movapd rC11, 64-128(pC)
            movapd rC21, 80-128(pC)
            movapd rC02, 96-128(pC)
            movapd rC12, 112-128(pC)
            movapd rC22, (pC)
         #endif
         add $144, pC
      sub $1, nnu
      jnz MNLOOP
               movddup -128(pB0), rC00
      mov nnu0, nnu
      mov pB0, pB
      add incAm, pA
   sub $1, nmu
   jnz MNLOOP
@ROUT ATL_dammm2x4x256_sse2.S
         movapd -128(pB), rB1
         movddup rB1, rB0
         movapd -128(pA), rC00

         movapd rC00, rC01
         mulpd rB0, rC00
         unpckhpd rB1, rB1
         movapd -112(pA), rC10
         movapd rC10, rC11
         mulpd rB0, rC10

         movapd -112(pB), rB3
         movddup rB3, rB2
         movapd rC01, rC02
         mulpd rB1, rC01
         unpckhpd rB3, rB3
         movapd rC11, rC12
         mulpd rB1, rC11
         #if KB > 1
            movapd -96(pB), rB1
         #else
            pref (pf)
         #endif

         #if KB > 1
            movapd -96(pA), rA0
         #else
            pref 64(pf)
         #endif
         movapd rC02, rC03
         mulpd rB2, rC02
         movapd rC12, rC13
         mulpd rB2, rC12
         #if KB > 1
            movddup rB1, rB0
         #else
            add incPF, pf
         #endif

         mulpd rB3, rC03
         prefC (pC)
         mulpd rB3, rC13
         prefC 64(pC)
/*
 *       ==========================
 *       Completely unrolled K-loop
 *       ==========================
 */
@iexp ao -80 0 +
@iexp bo -80 0 +
@iexp k 1 0 +
@iwhile k < 256
         #if KB > @(k)
   @iexp k @(k) 1 +
            movapd rB0, rm0
            mulpd rA0, rm0
            addpd rm0, rC00
            movapd @(ao)(pA), rA1
   @iexp ao @(ao) 16 +
            mulpd rA1, rB0
            addpd rB0, rC10
            unpckhpd rB1, rB1

            movapd rB1, rm0
            mulpd rA0, rm0
            addpd rm0, rC01
            movapd @(bo)(pB), rB3
   @iexp bo @(bo) 16 +
            mulpd rA1, rB1
            addpd rB1, rC11
            movddup rB3, rB2

            movapd rB2, rm0
            mulpd rA0, rm0
            addpd rm0, rC02
            unpckhpd rB3, rB3
            mulpd rA1, rB2
            addpd rB2, rC12

            #if KB > @(k)
               movapd @(bo)(pB), rB1
   @iexp bo @(bo) 16 +
            #elif KB == @(k)
               pref (pf)
            #endif
            mulpd rB3, rA0
            addpd rA0, rC03
            #if KB > @(k)
               movapd @(ao)(pA), rA0
   @iexp ao @(ao) 16 +
            #elif KB == @(k)
               pref (pfC)
               add incPF, pfC
            #endif
            mulpd rA1, rB3
            addpd rB3, rC13
            #if KB > @(k)
               movddup rB1, rB0
            #elif KB == @(k)
               prefetcht1 64(pfB)
               add incPF, pfB
               add incPF, pf
            #endif
         #endif   
@endiwhile
@ROUT ATL_dammm2x4x1_sse2.S
         movapd (pB), rB1
         movddup rB1, rB0
         movapd (pA), rC00

         movapd rC00, rC01
         mulpd rB0, rC00
         unpckhpd rB1, rB1
         movapd 16(pA), rC10
         movapd rC10, rC11
         mulpd rB0, rC10

         movapd 16(pB), rB3
         movddup rB3, rB2
         movapd rC01, rC02
         mulpd rB1, rC01
         pref (pf)
         movapd rC11, rC12
         mulpd rB1, rC11
         unpckhpd rB3, rB3

         pref 64(pf)
         movapd rC02, rC03
         mulpd rB2, rC02
         movapd rC12, rC13
         mulpd rB2, rC12

         prefC (pC)
         mulpd rB3, rC03
         add $32, pB
         prefC 64(pC)
         mulpd rB3, rC13
         add incPF, pf
         add $32, pA
         sub $1, KK
         jz DONEK

         KLOOP:
            movapd (pB), rB1
            movddup rB1, rB0
            movapd (pA), rA0
            movapd rB0, rm0
            mulpd rA0, rm0
            addpd rm0, rC00
            movapd 16(pA), rA1
            movapd rB0, rm0
            mulpd rA1, rm0
            addpd rm0, rC10
            unpckhpd rB1, rB1

            movapd 16(pB), rB3
            movapd rB1, rm0
            mulpd rA0, rm0
            addpd rm0, rC01
            movddup rB3, rB2
            movapd rB1, rm0
            mulpd rA1, rm0
            addpd rm0, rC11
            unpckhpd rB3, rB3

            movapd rB2, rm0
            mulpd rA0, rm0
            addpd rm0, rC02
            add $32, pA
            movapd rB2, rm0
            mulpd rA1, rm0
            addpd rm0, rC12
            add $32, pB

            movapd rB3, rm0
            mulpd rA0, rm0
            addpd rm0, rC03
            movapd rB3, rm0
            mulpd rA1, rm0
            addpd rm0, rC13
         sub $1, KK
         jnz KLOOP
         DONEK:
@ROUT ATL_dammm2x4x1_sse2.S ATL_dammm2x4x256_sse2.S
         #if defined(BETA1) || defined(BETAN1)
            BETCOP (pC), rC00
            movapd rC00, (pC)
            BETCOP 16(pC), rC10
            movapd rC10, 16(pC)
            BETCOP 32(pC), rC01
            movapd rC01, 32(pC)
            BETCOP 48(pC), rC11
            movapd rC11, 48(pC)
            BETCOP 64(pC), rC02
            movapd rC02, 64(pC)
            BETCOP 80(pC), rC12
            movapd rC12, 80(pC)
            BETCOP 96(pC), rC03
            movapd rC03, 96(pC)
            BETCOP 112(pC), rC13
            movapd rC13, 112(pC)
         #else
            movapd rC00, (pC)
            movapd rC10, 16(pC)
            movapd rC01, 32(pC)
            movapd rC11, 48(pC)
            movapd rC02, 64(pC)
            movapd rC12, 80(pC)
            movapd rC03, 96(pC)
            movapd rC13, 112(pC)
         #endif
         sub $-128, pC
@ROUT ATL_dammm2x4x1_sse2.S 
         mov KK0, KK
         mov pA0, pA
@ROUT ATL_dammm2x4x256_sse2.S
         add $KB*4*8, pB
@ROUT ATL_dammm2x4x1_sse2.S ATL_dammm2x4x256_sse2.S
      sub $1, nnu
      jnz MNLOOP
      mov nnu0, nnu
      mov pB0, pB
@ROUT ATL_dammm2x4x1_sse2.S
      add incAm, pA0
      mov pA0, pA
@ROUT ATL_dammm2x4x256_sse2.S
      add incAm, pA
@ROUT ATL_dammm2x4x1_sse2.S ATL_dammm2x4x256_sse2.S
   sub $1, nmu
   jnz MNLOOP

@ROUT ATL_dammm2x4x1_sse2.S ATL_dammm2x4x256_sse2.S ATL_dammm3x3x256_sse2.S
/* DONE: */
   movq    (%rsp), %rbp
   movq    8(%rsp), %rbx
   movq    16(%rsp), %r12
@ROUT ATL_dammm2x4x1_sse2.S ATL_dammm2x4x256_sse2.S
   movq    24(%rsp), %r13
@ROUT ATL_dammm2x4x1_sse2.S
   movq    32(%rsp), %r14
   movq    40(%rsp), %r15
@ROUT ATL_dammm2x4x1_sse2.S ATL_dammm2x4x256_sse2.S ATL_dammm3x3x256_sse2.S
   add $FSIZE, %rsp
   ret
@beginskip
/*
 * Can't use next B as pointer as usual, see if we can use next A
 */
.local BADPFB
BADPFB:
   movq 16(%rsp), pf
   cmp $0, pf
   je BADPFAB
   cmp pf, pA
   jne PFSETUP
/*
 * Can't use A or B as ptr, try C
 */
.local BADPFAB
BADPFAB:
   movq 24(%rsp), pf
   cmp $0, pf
   je BADPFABC
   cmp pf, pA
   jne PFSETUP
/*
 * No next block, so just fetch this time's A ahead
 */
.local BADPFABC
BADPFABC:
#ifndef KB
   #define KB 40
#endif
#ifndef MB
   #define MB KB
#endif
   lea KB*MB*4(pA), pf
   jmp PFSETUP
BADPF_2:
   movq 24(%rsp), pfB
   jmp PFSETUP_2
@endskip
@ROUT ATL_dammm_nb8_avx.S
@extract -b @(topd)/gen.inc what=crsetup
@extract -b @(topd)/cw.inc lang=c -define cwdate 2012
#include "atlas_asm.h"

#define pA %rcx
#define pB %r8
#define pC %r9
#define rA00    %ymm0
#define rA10    %ymm1
#define rA01    %ymm2
#define rA11    %ymm3
#define rA02    %ymm4
#define rA12    %ymm5
#define rA03    %ymm6
#define rA13    %ymm7
#define rB0     %ymm8
#define rB1     %ymm9
#define rC00    %ymm10
#define rC10    %ymm11
#define rC01    %ymm12
#define rC11    %ymm13
#define rb0     %ymm14
#define rb0_x   %xmm14
#define rb1     %ymm15
#define rb1_x   %xmm15
/*
                    rdi      rsi    rdx        rcx         r8        r9
void ATL_USERMM(SZT nmu, SZT nnu, SZT K, CTYPE *pA, CTYPE *pB, TYPE *pC,
                  8(%rsp)    16(%rsp)     24(%rsp)
                CTYPE *pAn, CTYPE *pBn, CTYPE *pCn);
 */
.text
ALIGN16
.global ATL_asmdecor(ATL_USERMM)
ATL_asmdecor(ATL_USERMM):
   vmovapd (pA), rA00
   movapd 16(pA), rA10
   movapd 32(pA), rA01
   movapd 48(pA), rA11
   movapd 64(pA), rA02
   movapd 80(pA), rA12
   movapd 96(pA), rA03
   movapd 112(pA), rA13

/*
 * ======================================================
 * rC00 = rA00 * rB00 + rA01*rB10 + rA02*rB20 + rA03*rB30
 * rC10 = rA10 * rB00 + rA11*rB10 + rA12*rB20 + rA13*rB30
 * rC01 = rA00 * rB01 + rA01*rB11 + rA02*rB21 + rA03*rB31
 * rC11 = rA10 * rB01 + rA11*rB11 + rA12*rB21 + rA13*rB31
 * ======================================================
 */
/*
 * rC00 = rA00 * rB0
 * rC10 = rA10 * rB0
 * rC01 = rA00 * rB1
 * rC11 = rA10 * rB1
 */
   #if defined(BETA0) || defined(BETAN1)
      movddup (pB), rC10
      movapd rC10, rC00
      mulpd rA00, rC00
      movddup 32(pB), rC11
      mulpd rA10, rC10
      movapd rC11, rC01
      mulpd rA00, rC01
      mulpd rA10, rC11
   #else
      movddup (pB), rB0
      movddup 32(pB), rB1
      movapd rB0, m0
      mulpd rA00, m0
      movapd (pC), rC00
      addpd m0, rC00
      mulpd rA10, rB0
      movapd 16(pC), rC10
      addpd rB0, rC10
      movapd rB1, m0
      mulpd rA00, m0
      movapd 32(pC), rC01
      addpd m0, rC01
      mulpd rA10, rB1
      movapd 48(pC), rC11
      addpd rB1, rC11
   #endif
/*
 * rC00 = rA01*rB10 
 * rC10 = rA11*rB10 
 * rC01 = rA01*rB11 
 * rC11 = rA11*rB11 
 */
   movddup 8(pB), rB0
   movapd rB0, m0
   mulpd rA01, m0
   addpd m0, rC00
   mulpd rA11, rB0
   addpd rB0, rC10
   movddup 40(pB), rB1
   movapd rB1, m0
   mulpd rA01, m0
   addpd m0, rC01
   mulpd rA11, rB1
   addpd rB1, rC11
/*
 * rC00 = rA02*rB20
 * rC10 = rA12*rB20
 * rC01 = rA02*rB21
 * rC11 = rA12*rB21
 */
   movddup 16(pB), rB0
   movapd rA02, m0
   mulpd rB0, m0
   addpd m0, rC00
   mulpd rA12, rB0
   addpd rB0, rC10
   movapd rA02, m0
   movddup 48(pB), rB1
   mulpd rB1, m0
   addpd m0, rC01
   mulpd rA12, rB1
   addpd rB1, rC11
/*
 * rC00 = rA03*rB30
 * rC10 = rA13*rB30
 * rC01 = rA03*rB31
 * rC11 = rA13*rB31
 */
   movddup 24(pB), rB0
   movapd rA03, m0
   mulpd rB0, m0
   addpd m0, rC00
   #ifdef BETAN1
      subpd (pC), rC00
   #endif
   movapd rC00, (pC)
   mulpd rA13, rB0
   addpd rB0, rC10
   #ifdef BETAN1
      subpd 16(pC), rC10
   #endif
   movapd rC10, 16(pC)
   movapd rA03, m0
   movddup 56(pB), rB1
   mulpd rB1, m0
   addpd m0, rC01
   #ifdef BETAN1
      subpd 32(pC), rC01
   #endif
   movapd rC01, 32(pC)
   mulpd rA13, rB1
   addpd rB1, rC11
   #ifdef BETAN1
      subpd 48(pC), rC11
   #endif
   movapd rC11, 48(pC)

/*
 * rC00 = rA00 * rB0
 * rC10 = rA10 * rB0
 * rC01 = rA00 * rB1
 * rC11 = rA10 * rB1
 */
   #if defined(BETA0) || defined(BETAN1)
      movddup 64(pB), rC10
      movapd rC10, rC00
      mulpd rA00, rC00
      movddup 96(pB), rC11
      mulpd rA10, rC10
      movapd rC11, rC01
      mulpd rA00, rC01
      mulpd rA10, rC11
   #else
      movddup 64(pB), rB0
      movddup 96(pB), rB1
      movapd rB0, m0
      mulpd rA00, m0
      movapd 64(pC), rC00
      addpd m0, rC00
      mulpd rA10, rB0
      movapd 80(pC), rC10
      addpd rB0, rC10
      movapd rB1, m0
      mulpd rA00, m0
      movapd 96(pC), rC01
      addpd m0, rC01
      mulpd rA10, rB1
      movapd 112(pC), rC11
      addpd rB1, rC11
   #endif
/*
 * rC00 = rA01*rB10 
 * rC10 = rA11*rB10 
 * rC01 = rA01*rB11 
 * rC11 = rA11*rB11 
 */
   movddup 72(pB), rB0
   movapd rB0, m0
   mulpd rA01, m0
   addpd m0, rC00
   mulpd rA11, rB0
   addpd rB0, rC10
   movddup 104(pB), rB1
   movapd rB1, m0
   mulpd rB1, rA01
   addpd rA01, rC01
   mulpd rA11, rB1
   addpd rB1, rC11
/*
 * rC00 = rA02*rB20
 * rC10 = rA12*rB20
 * rC01 = rA02*rB21
 * rC11 = rA12*rB21
 */
   movddup 80(pB), rB0
   movapd rA02, m0
   mulpd rB0, m0
   addpd m0, rC00
   mulpd rA12, rB0
   addpd rB0, rC10
   movddup 112(pB), rB1
   mulpd rB1, rA02
   addpd rA02, rC01
   mulpd rA12, rB1
   addpd rB1, rC11
/*
 * rC00 = rA03*rB30
 * rC10 = rA13*rB30
 * rC01 = rA03*rB31
 * rC11 = rA13*rB31
 */
   movddup 88(pB), rB0
   movapd rA03, m0
   mulpd rB0, m0
   addpd m0, rC00
   #ifdef BETAN1
      subpd 64(pC), rC00
   #endif
   movapd rC00, 64(pC)
   mulpd rA13, rB0
   addpd rB0, rC10
   #ifdef BETAN1
      subpd 80(pC), rC10
   #endif
   movapd rC10, 80(pC)
   movddup 120(pB), rB1
   mulpd rB1, rA03
   addpd rA03, rC01
   #ifdef BETAN1
      subpd 96(pC), rC01
   #endif
   movapd rC01, 96(pC)
   mulpd rA13, rB1
   addpd rB1, rC11
   #ifdef BETAN1
      subpd 112(pC), rC11
   #endif
   movapd rC11, 112(pC)
   ret

@ROUT ATL_dammm_nb4_sse2.S
@extract -b @(topd)/gen.inc what=crsetup
@extract -b @(topd)/cw.inc lang=c -define cwdate 2012
#include "atlas_asm.h"

#define pA %rcx
#define pB %r8
#define pC %r9
#define m0      %xmm0
#define rA00    %xmm1
#define rA10    %xmm2
#define rA01    %xmm3
#define rA11    %xmm4
#define rA02    %xmm5
#define rA12    %xmm6
#define rA03    %xmm7
#define rA13    %xmm8
#define rB0     %xmm9
#define rB1     %xmm10
#define rC00    %xmm11
#define rC10    %xmm12
#define rC01    %xmm13
#define rC11    %xmm14
/*
                    rdi      rsi    rdx        rcx         r8        r9
void ATL_USERMM(SZT nmu, SZT nnu, SZT K, CTYPE *pA, CTYPE *pB, TYPE *pC,
                  8(%rsp)    16(%rsp)     24(%rsp)
                CTYPE *pAn, CTYPE *pBn, CTYPE *pCn);
 */
.text
ALIGN16
.global ATL_asmdecor(ATL_USERMM)
ATL_asmdecor(ATL_USERMM):
   movapd (pA), rA00
   movapd 16(pA), rA10
   movapd 32(pA), rA01
   movapd 48(pA), rA11
   movapd 64(pA), rA02
   movapd 80(pA), rA12
   movapd 96(pA), rA03
   movapd 112(pA), rA13

/*
 * ======================================================
 * rC00 = rA00 * rB00 + rA01*rB10 + rA02*rB20 + rA03*rB30
 * rC10 = rA10 * rB00 + rA11*rB10 + rA12*rB20 + rA13*rB30
 * rC01 = rA00 * rB01 + rA01*rB11 + rA02*rB21 + rA03*rB31
 * rC11 = rA10 * rB01 + rA11*rB11 + rA12*rB21 + rA13*rB31
 * ======================================================
 */
/*
 * rC00 = rA00 * rB0
 * rC10 = rA10 * rB0
 * rC01 = rA00 * rB1
 * rC11 = rA10 * rB1
 */
   #if defined(BETA0) || defined(BETAN1)
      movddup (pB), rC10
      movapd rC10, rC00
      mulpd rA00, rC00
      movddup 32(pB), rC11
      mulpd rA10, rC10
      movapd rC11, rC01
      mulpd rA00, rC01
      mulpd rA10, rC11
   #else
      movddup (pB), rB0
      movddup 32(pB), rB1
      movapd rB0, m0
      mulpd rA00, m0
      movapd (pC), rC00
      addpd m0, rC00
      mulpd rA10, rB0
      movapd 16(pC), rC10
      addpd rB0, rC10
      movapd rB1, m0
      mulpd rA00, m0
      movapd 32(pC), rC01
      addpd m0, rC01
      mulpd rA10, rB1
      movapd 48(pC), rC11
      addpd rB1, rC11
   #endif
/*
 * rC00 = rA01*rB10 
 * rC10 = rA11*rB10 
 * rC01 = rA01*rB11 
 * rC11 = rA11*rB11 
 */
   movddup 8(pB), rB0
   movapd rB0, m0
   mulpd rA01, m0
   addpd m0, rC00
   mulpd rA11, rB0
   addpd rB0, rC10
   movddup 40(pB), rB1
   movapd rB1, m0
   mulpd rA01, m0
   addpd m0, rC01
   mulpd rA11, rB1
   addpd rB1, rC11
/*
 * rC00 = rA02*rB20
 * rC10 = rA12*rB20
 * rC01 = rA02*rB21
 * rC11 = rA12*rB21
 */
   movddup 16(pB), rB0
   movapd rA02, m0
   mulpd rB0, m0
   addpd m0, rC00
   mulpd rA12, rB0
   addpd rB0, rC10
   movapd rA02, m0
   movddup 48(pB), rB1
   mulpd rB1, m0
   addpd m0, rC01
   mulpd rA12, rB1
   addpd rB1, rC11
/*
 * rC00 = rA03*rB30
 * rC10 = rA13*rB30
 * rC01 = rA03*rB31
 * rC11 = rA13*rB31
 */
   movddup 24(pB), rB0
   movapd rA03, m0
   mulpd rB0, m0
   addpd m0, rC00
   #ifdef BETAN1
      subpd (pC), rC00
   #endif
   movapd rC00, (pC)
   mulpd rA13, rB0
   addpd rB0, rC10
   #ifdef BETAN1
      subpd 16(pC), rC10
   #endif
   movapd rC10, 16(pC)
   movapd rA03, m0
   movddup 56(pB), rB1
   mulpd rB1, m0
   addpd m0, rC01
   #ifdef BETAN1
      subpd 32(pC), rC01
   #endif
   movapd rC01, 32(pC)
   mulpd rA13, rB1
   addpd rB1, rC11
   #ifdef BETAN1
      subpd 48(pC), rC11
   #endif
   movapd rC11, 48(pC)

/*
 * rC00 = rA00 * rB0
 * rC10 = rA10 * rB0
 * rC01 = rA00 * rB1
 * rC11 = rA10 * rB1
 */
   #if defined(BETA0) || defined(BETAN1)
      movddup 64(pB), rC10
      movapd rC10, rC00
      mulpd rA00, rC00
      movddup 96(pB), rC11
      mulpd rA10, rC10
      movapd rC11, rC01
      mulpd rA00, rC01
      mulpd rA10, rC11
   #else
      movddup 64(pB), rB0
      movddup 96(pB), rB1
      movapd rB0, m0
      mulpd rA00, m0
      movapd 64(pC), rC00
      addpd m0, rC00
      mulpd rA10, rB0
      movapd 80(pC), rC10
      addpd rB0, rC10
      movapd rB1, m0
      mulpd rA00, m0
      movapd 96(pC), rC01
      addpd m0, rC01
      mulpd rA10, rB1
      movapd 112(pC), rC11
      addpd rB1, rC11
   #endif
/*
 * rC00 = rA01*rB10 
 * rC10 = rA11*rB10 
 * rC01 = rA01*rB11 
 * rC11 = rA11*rB11 
 */
   movddup 72(pB), rB0
   movapd rB0, m0
   mulpd rA01, m0
   addpd m0, rC00
   mulpd rA11, rB0
   addpd rB0, rC10
   movddup 104(pB), rB1
   movapd rB1, m0
   mulpd rB1, rA01
   addpd rA01, rC01
   mulpd rA11, rB1
   addpd rB1, rC11
/*
 * rC00 = rA02*rB20
 * rC10 = rA12*rB20
 * rC01 = rA02*rB21
 * rC11 = rA12*rB21
 */
   movddup 80(pB), rB0
   movapd rA02, m0
   mulpd rB0, m0
   addpd m0, rC00
   mulpd rA12, rB0
   addpd rB0, rC10
   movddup 112(pB), rB1
   mulpd rB1, rA02
   addpd rA02, rC01
   mulpd rA12, rB1
   addpd rB1, rC11
/*
 * rC00 = rA03*rB30
 * rC10 = rA13*rB30
 * rC01 = rA03*rB31
 * rC11 = rA13*rB31
 */
   movddup 88(pB), rB0
   movapd rA03, m0
   mulpd rB0, m0
   addpd m0, rC00
   #ifdef BETAN1
      subpd 64(pC), rC00
   #endif
   movapd rC00, 64(pC)
   mulpd rA13, rB0
   addpd rB0, rC10
   #ifdef BETAN1
      subpd 80(pC), rC10
   #endif
   movapd rC10, 80(pC)
   movddup 120(pB), rB1
   mulpd rB1, rA03
   addpd rA03, rC01
   #ifdef BETAN1
      subpd 96(pC), rC01
   #endif
   movapd rC01, 96(pC)
   mulpd rA13, rB1
   addpd rB1, rC11
   #ifdef BETAN1
      subpd 112(pC), rC11
   #endif
   movapd rC11, 112(pC)
   ret
@ROUT ATL_damm2x12x2_sse2.S ATL_damm2x12x256_sse2.S
@extract -b @(topd)/gen.inc what=crsetup
@extract -b @(topd)/cw.inc lang=c -define cwdate 2012
#include "atlas_asm.h"
#ifndef KB
   #define KB 0
#endif
@ROUT ATL_damm2x12x2_sse2.S
/*
 * innermost (K-) loop items get priority on 1st 7 regs
 */
#define pA      %rcx
#define pB      %rdi
#define incB    %rax
#define KK      %rdx
/*
 * Second (N-) loop items get next level of priority on good regs
 */
#define pC      %rbp
#define pfA     %rsi
#define pfB     %rbx
#define K1      %r8
#define incPF   %r9
#define nnu     %r10
#define incAm   %r11
#define KK0     %r15
/*
 * Outer- (M-) loop variables assigned to any regs
 */
#define nmu     %r12
#define pB0     %r13
#define nnu0    %r14
@ROUT ATL_damm2x12x256_sse2.S
/*
 * innermost (K-) loop items get priority on 1st 7 regs
 */
#define pA      %rcx
#define pB      %rdi
#define i256    %rax
#define i768    %rdx   /* 3 * 256 */
#define i1280   %rsi   /* 5 * 256 */
#define i1792   %rbx   /* 7 * 256 */
/*
 * Second (N-) loop items get next level of priority on good regs
 */
#define pC      %rbp
#define pfA     %r12
#define pfB     %r8
#define incPF   %r9
#define nnu     %r10
@skip #define incAm   %r11
/*
 * Outer- (M-) loop variables assigned to any regs
 */
#define nmu     %r13
#define pB0     %r14
#define nnu0    %r15
@ROUT ATL_damm2x12x2_sse2.S ATL_damm2x12x256_sse2.S
/*
 * floating point registers
 */
#define a0      %xmm0
#define b0      %xmm1
#define rC0     %xmm2
#define rC1     %xmm3
#define rC2     %xmm4
#define rC3     %xmm5
#define rC4     %xmm6
#define rC5     %xmm7
#define rC6     %xmm8
#define rC7     %xmm9
#define rC8     %xmm10
#define rC9     %xmm11
#define rC10    %xmm12
#define rC11    %xmm13
/*
                    rdi      rsi    rdx        rcx         r8        r9
void ATL_USERMM(SZT nmu, SZT nnu, SZT K, CTYPE *pA, CTYPE *pB, TYPE *pC,
                  8(%rsp)    16(%rsp)     24(%rsp)
                CTYPE *pAn, CTYPE *pBn, CTYPE *pCn);
 */

#define FSIZE 6*8
#ifndef prefA
   #define prefA prefetcht0
#endif
#ifndef prefB
   #define prefB prefetcht0
#endif
#ifndef prefC
   #ifdef ATL_3DNow
      #define prefC prefetchw
   #else
      #define prefC prefetcht0
   #endif
#endif
#ifdef BETAN1
   #define BETCOP subpd
#else
   #define BETCOP addpd
#endif
/*
                    rdi      rsi    rdx        rcx         r8        r9
void ATL_USERMM(SZT nmu, SZT nnu, SZT K, CTYPE *pA, CTYPE *pB, TYPE *pC,
                  8(%rsp)    16(%rsp)     24(%rsp)
                CTYPE *pAn, CTYPE *pBn, CTYPE *pCn);
 */
.text
.global ATL_asmdecor(ATL_USERMM)
ALIGN16
ATL_asmdecor(ATL_USERMM):
/*
 * Save callee-saved iregs
 */
   sub $FSIZE, %rsp
   movq    %rbp, 0(%rsp)
   movq    %rbx, 8(%rsp)
   movq    %r12, 16(%rsp)
   movq    %r13, 24(%rsp)
   movq    %r14, 32(%rsp)
   movq    %r15, 40(%rsp)
/*
 * Load paramaters
 */
   mov %rdi, nmu
   mov %rsi, nnu
   mov %r8, pB
   mov %r9, pC
   mov nnu, nnu0
   movq FSIZE+8(%rsp), pfB      /* pfB = pAn */
   movq FSIZE+16(%rsp), pfA     /* pf = pBn */
   cmp pfA, pB
   CMOVE pfB, pfA
   CMOVEq FSIZE+24(%rsp), pfB
   mov $2*12*8, incPF           /* incPF = mu*nu*sizeof */
/*
 * Extend range of 1-byte offsets  by starting at -128
 */
@ROUT ATL_damm2x12x256_sse2.S `   sub $-128, pA`
   sub $-128, pB
   sub $-128, pC
   sub $-128, pfA
   sub $-128, pfB
   movq pB, pB0
@ROUT ATL_damm2x12x2_sse2.S
#if KB == 0
/*
 * Make KK even, and store if we have an extra iteration in K1
 */
   mov $2, KK0  /* KK0 sets 2nd bit, used only when K==3 */
   mov $1, K1
   and KK, K1   /* K1 1 for odd K, else 0 */
   add K1, KK0  /* KK0 has both bits set appropriately for K==3 case */
   cmp $3, KK   /* is K == 3? */
   CMOVE KK0, K1/* bit 0: even/odd, bit1: set only if K == 3 */
   sub K1, KK   /* KK now guaranteed even */
#elif KB%2
      sub $1, KK  /* make loop variable even */
#endif
/*
 * incAm = KB*MU*sizeof = K*2*8 = K*16
 */
   shl $4, KK                   /* KK = K*MU*sizeof = K*2*8 = K*16 */
   mov KK, incAm                /* incAm = K*16 */
   mov $192, incB
@ROUT ATL_damm2x12x256_sse2.S
@beginskip
@BEGINPROC decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
@ENDPROC
@endskip
@BEGINPROC doref p io r
   @define io0 @@(io)@
   @mif "pB = p
      @define mv @   movddup@
   @endmif
   @mif "pB ! p
      @define mv @   movapd@
   @endmif
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io < 128
         @(mv) @(of)(@(p)), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 384
         @(mv) @(of)(@(p),i256), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 640
         @(mv) @(of)(@(p),i256,2), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 896
         @(mv) @(of)(@(p),i768), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 1152
         @(mv) @(of)(@(p),i256,4), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 1408
         @(mv) @(of)(@(p),i1280), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 1664
         @(mv) @(of)(@(p),i768,2), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 1920
         @(mv) @(of)(@(p),i1792), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 2176
         @(mv) @(of)(@(p),i256,8), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 2432
         @(mv) @(io0)(@(p)), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 2688
         @(mv) @(of)(@(p),i1280,2), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 2944
         @(mv) @(io0)(@(p)), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 3200
         @(mv) @(of)(@(p),i768,4), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 3456
         @(mv) @(io0)(@(p)), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 3712
         @(mv) @(of)(@(p),i1792,2), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io < 4992
         @(mv) @(io0)(@(p)), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 5248
         @(mv) @(of)(@(p),i1280,4), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io < 6016
         @(mv) @(io0)(@(p)), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 6272
         @(mv) @(of)(@(p),i768,8), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io < 7040
         @(mv) @(io0)(@(p)), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 7296
         @(mv) @(of)(@(p),i1792,4), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io < 10112
         @(mv) @(io0)(@(p)), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 7296
         @(mv) @(of)(@(p),i1280,8), @(r)
      @endextract
   @endiif
@SKIP default case just indexes ptr
         @(mv) @(io0)(@(p)), @(r)
   @undef io0
   @undef of
   @undef mv
@ENDPROC
   mov $256, i256
   lea (i256, i256,2), i768
   lea (i256, i256,4), i1280
   lea (i256, i768,2), i1792
   ALIGN8
   .local MNLOOP
   MNLOOP:
/*
      .local NLOOP
      NLOOP:
*/
/*
 *       Peel first iteration of K loop to initialize rCx
 */
         movapd -128(pA), a0
         movddup -128(pB), rC0
         mulpd a0, rC0
            prefC -128(pC)
         movddup -120(pB), rC1
         mulpd a0, rC1
         movddup -112(pB), rC2
         mulpd a0, rC2
         movddup -104(pB), rC3
         mulpd a0, rC3
         movddup -96(pB), rC4
         mulpd a0, rC4
         movddup -88(pB), rC5
         mulpd a0, rC5
         movddup -80(pB), rC6
         mulpd a0, rC6
         movddup -72(pB), rC7
         mulpd a0, rC7
         movddup -64(pB), rC8
         mulpd a0, rC8
         movddup -56(pB), rC9
         mulpd a0, rC9
         movddup -48(pB), rC10
         mulpd a0, rC10
         movddup -40(pB), rC11
         mulpd a0, rC11
/*
 *       Fully unrolled K-loop
 */
@iexp ao -112 0 +
@iexp bo -32 0 +
@iexp k 1 0 +
@iwhile k < 256
         #if KB > @(k)
   @iexp k @(k) 1 +
            @callproc doref pA @(ao) a0
            @iexp ao @(ao) 16 +
            @callproc doref pB @(bo) b0
            @iexp bo @(bo) 8 +
            mulpd a0, b0
            addpd b0, rC0
            @callproc doref pB @(bo) b0
            @iexp bo @(bo) 8 +
            @iif @(k) = 1
               prefC -64(pC)
            @endiif
            @iif @(k) = 2
               prefC (pC)
            @endiif
            @iif @(k) = 3
            prefA -128(pfA)
            @endiif
            @iif @(k) = 4
            prefA -64(pfA)
            @endiif
            @iif @(k) = 5
            prefA (pfA)
            @endiif
            @iif @(k) = 6
            prefB -128(pfB)
            @endiif
            @iif @(k) = 7
            prefB -64(pfB)
            @endiif
            @iif @(k) = 8
            prefB (pfB)
            @endiif
            mulpd a0, b0
            addpd b0, rC1
            @callproc doref pB @(bo) b0
            @iexp bo @(bo) 8 +
            mulpd a0, b0
            addpd b0, rC2
            @callproc doref pB @(bo) b0
            @iexp bo @(bo) 8 +
            mulpd a0, b0
            addpd b0, rC3
            @callproc doref pB @(bo) b0
            @iexp bo @(bo) 8 +
            mulpd a0, b0
            addpd b0, rC4
            @callproc doref pB @(bo) b0
            @iexp bo @(bo) 8 +
            mulpd a0, b0
            addpd b0, rC5
            @callproc doref pB @(bo) b0
            @iexp bo @(bo) 8 +
            mulpd a0, b0
            addpd b0, rC6
            @callproc doref pB @(bo) b0
            @iexp bo @(bo) 8 +
            mulpd a0, b0
            addpd b0, rC7
            @callproc doref pB @(bo) b0
            @iexp bo @(bo) 8 +
            mulpd a0, b0
            addpd b0, rC8
            @callproc doref pB @(bo) b0
            @iexp bo @(bo) 8 +
            mulpd a0, b0
            addpd b0, rC9
            @callproc doref pB @(bo) b0
            @iexp bo @(bo) 8 +
            mulpd a0, b0
            addpd b0, rC10
            @callproc doref pB @(bo) b0
            @iexp bo @(bo) 8 +
            mulpd a0, b0
            addpd b0, rC11
         #endif
@endiwhile
         add incPF, pfA
         add incPF, pfB
/*
 *       Write answer back out to C
 */
         #ifdef BETA0
            movapd rC0, -128(pC)
            movapd rC1, -112(pC)
            movapd rC2, -96(pC)
            movapd rC3, -80(pC)
            movapd rC4, -64(pC)
            movapd rC5, -48(pC)
            movapd rC6, -32(pC)
            movapd rC7, -16(pC)
            movapd rC8, (pC)
            movapd rC9, 16(pC)
            movapd rC10, 32(pC)
            movapd rC11, 48(pC)
/*
 *          Add running sum in rCx with original C, then store back out
 */
         #else
            BETCOP -128(pC), rC0
            movapd rC0, -128(pC)
            BETCOP -112(pC), rC1
            movapd rC1, -112(pC)
            BETCOP -96(pC), rC2
            movapd rC2, -96(pC)
            BETCOP -80(pC), rC3
            movapd rC3, -80(pC)
            BETCOP -64(pC), rC4
            movapd rC4, -64(pC)
            BETCOP -48(pC), rC5
            movapd rC5, -48(pC)
            BETCOP -32(pC), rC6
            movapd rC6, -32(pC)
            BETCOP -16(pC), rC7
            movapd rC7, -16(pC)
            BETCOP (pC), rC8
            movapd rC8, (pC)
            BETCOP 16(pC), rC9
            movapd rC9, 16(pC)
            BETCOP 32(pC), rC10
            movapd rC10, 32(pC)
            BETCOP 48(pC), rC11
            movapd rC11, 48(pC)
         #endif
         add $12*2*8, pC   /* pC += NU*VECLEN*sizeof */
         add $KB*12*8, pB     /* pB += K*NU*sizeof */
      sub $1, nnu
      jnz MNLOOP

      mov nnu0, nnu
      mov pB0, pB
      add $KB*2*8, pA    /* pA += KB*MU*size */
   sub $1, nmu
   jnz MNLOOP
@ROUT ATL_damm2x12x2_sse2.S
   add KK, pA                   /* pA += K*MU (ptr starts 1 past last loc */
   neg KK
   mov KK, KK0

   nop ; nop ; nop ; nop ; nop
   .local MNLOOP
   MNLOOP:
/*
      .local NLOOP
      NLOOP:
*/
         #if KB == 0
            bt $1, K1   /* If K==3, use special-case code that avoids loop */
            jc KISTHREE
         #endif
/*
 *       Peel first iteration of K loop to initialize rCx
 */
         movapd (pA,KK), a0
         movddup -128(pB), rC0
         mulpd a0, rC0
            prefC -128(pC)
         movddup -120(pB), rC1
         mulpd a0, rC1
            prefC -64(pC)
         movddup -112(pB), rC2
         mulpd a0, rC2
            prefC (pC)
         movddup -104(pB), rC3
         mulpd a0, rC3
            prefA -128(pfA)
         movddup -96(pB), rC4
         mulpd a0, rC4
            prefA -64(pfA)
         movddup -88(pB), rC5
         mulpd a0, rC5
            prefA (pfA)
         movddup -80(pB), rC6
         mulpd a0, rC6
            prefB -128(pfB)
         movddup -72(pB), rC7
         mulpd a0, rC7
            prefB -64(pfB)
         movddup -64(pB), rC8
         mulpd a0, rC8
            prefB (pfB)
         movddup -56(pB), rC9
         mulpd a0, rC9
@skip            prefC -128(pfC)
         movddup -48(pB), rC10
         mulpd a0, rC10
         movddup -40(pB), rC11
         mulpd a0, rC11
      #if KB == 0
         cmp $0, KK
         jz KLOOPDONE
      #endif

         #if KB > 1 || KB == 0
            movapd 16(pA,KK), a0
            movddup -32(pB), b0
            mulpd a0, b0
            addpd b0, rC0
            movddup -24(pB), b0
            mulpd a0, b0
            addpd b0, rC1
               #if KB > 2
                  add $32, KK
               #endif
            movddup -16(pB), b0
            mulpd a0, b0
            addpd b0, rC2
               add incPF, pfA
            movddup -8(pB), b0
            mulpd a0, b0
            addpd b0, rC3
               add incPF, pfB
            movddup (pB), b0
            mulpd a0, b0
            addpd b0, rC4
            movddup 8(pB), b0
            mulpd a0, b0
            addpd b0, rC5
            movddup 16(pB), b0
            mulpd a0, b0
            addpd b0, rC6
            movddup 24(pB), b0
            mulpd a0, b0
            addpd b0, rC7
            movddup 32(pB), b0
            mulpd a0, b0
            addpd b0, rC8
            movddup 40(pB), b0
            mulpd a0, b0
            addpd b0, rC9
            movddup 48(pB), b0
            mulpd a0, b0
            addpd b0, rC10
            movddup 56(pB), b0
            add incB, pB
            mulpd a0, b0
            addpd b0, rC11
            #if KB == 0
               add $32, KK
               jz KLOOPDONE
            #endif
         #endif

         #if KB >= 4 || KB == 0
         .local KLOOP
         KLOOP:
            movapd (pA,KK), a0
            movddup -128(pB), b0
            mulpd a0, b0
            addpd b0, rC0
            movddup -120(pB), b0
            mulpd a0, b0
            addpd b0, rC1
            movddup -112(pB), b0
            mulpd a0, b0
            addpd b0, rC2
            movddup -104(pB), b0
            mulpd a0, b0
            addpd b0, rC3
            movddup -96(pB), b0
            mulpd a0, b0
            addpd b0, rC4
            movddup -88(pB), b0
            mulpd a0, b0
            addpd b0, rC5
            movddup -80(pB), b0
            mulpd a0, b0
            addpd b0, rC6
            movddup -72(pB), b0
            mulpd a0, b0
            addpd b0, rC7
            movddup -64(pB), b0
            mulpd a0, b0
            addpd b0, rC8
            movddup -56(pB), b0
            mulpd a0, b0
            addpd b0, rC9
            movddup -48(pB), b0
            mulpd a0, b0
            addpd b0, rC10
            movddup -40(pB), b0
            mulpd a0, b0
            addpd b0, rC11

            movapd 16(pA,KK), a0
            movddup -32(pB), b0
            mulpd a0, b0
            addpd b0, rC0
            movddup -24(pB), b0
            mulpd a0, b0
            addpd b0, rC1
            movddup -16(pB), b0
            mulpd a0, b0
            addpd b0, rC2
            movddup -8(pB), b0
            mulpd a0, b0
            addpd b0, rC3
            movddup (pB), b0
            mulpd a0, b0
            addpd b0, rC4
            movddup 8(pB), b0
            mulpd a0, b0
            addpd b0, rC5
            movddup 16(pB), b0
            mulpd a0, b0
            addpd b0, rC6
            movddup 24(pB), b0
            mulpd a0, b0
            addpd b0, rC7
            movddup 32(pB), b0
            mulpd a0, b0
            addpd b0, rC8
            movddup 40(pB), b0
            mulpd a0, b0
            addpd b0, rC9
            movddup 48(pB), b0
            mulpd a0, b0
            addpd b0, rC10
            movddup 56(pB), b0
            mulpd a0, b0
            addpd b0, rC11
            add incB, pB
         add $32, KK
         jnz KLOOP
         #endif
         #if KB == 0
            bt $0, K1    /* set CF if odd # of K */
            jc ONEEXTRAKIT
            .local KLOOPDONE
            KLOOPDONE:
         #elif KB%2 && KB != 1
            movapd (pA,KK), a0
            movddup -128(pB), b0
            mulpd a0, b0
            addpd b0, rC0
            movddup -120(pB), b0
            mulpd a0, b0
            addpd b0, rC1
            movddup -112(pB), b0
            mulpd a0, b0
            addpd b0, rC2
            movddup -104(pB), b0
            mulpd a0, b0
            addpd b0, rC3
            movddup -96(pB), b0
            mulpd a0, b0
            addpd b0, rC4
            movddup -88(pB), b0
            mulpd a0, b0
            addpd b0, rC5
            movddup -80(pB), b0
            mulpd a0, b0
            addpd b0, rC6
            movddup -72(pB), b0
            mulpd a0, b0
            addpd b0, rC7
            movddup -64(pB), b0
            mulpd a0, b0
            addpd b0, rC8
            movddup -56(pB), b0
            mulpd a0, b0
            addpd b0, rC9
            movddup -48(pB), b0
            mulpd a0, b0
            addpd b0, rC10
            movddup -40(pB), b0
            mulpd a0, b0
            addpd b0, rC11
         #endif
/*
 *       Write answer back out to C
 */
         #ifdef BETA0
            movapd rC0, -128(pC)
            movapd rC1, -112(pC)
            movapd rC2, -96(pC)
            movapd rC3, -80(pC)
            movapd rC4, -64(pC)
            movapd rC5, -48(pC)
            movapd rC6, -32(pC)
            movapd rC7, -16(pC)
            movapd rC8, (pC)
            movapd rC9, 16(pC)
            movapd rC10, 32(pC)
            movapd rC11, 48(pC)
/*
 *          Add running sum in rCx with original C, then store back out
 */
         #else
            BETCOP -128(pC), rC0
            movapd rC0, -128(pC)
            BETCOP -112(pC), rC1
            movapd rC1, -112(pC)
            BETCOP -96(pC), rC2
            movapd rC2, -96(pC)
            BETCOP -80(pC), rC3
            movapd rC3, -80(pC)
            BETCOP -64(pC), rC4
            movapd rC4, -64(pC)
            BETCOP -48(pC), rC5
            movapd rC5, -48(pC)
            BETCOP -32(pC), rC6
            movapd rC6, -32(pC)
            BETCOP -16(pC), rC7
            movapd rC7, -16(pC)
            BETCOP (pC), rC8
            movapd rC8, (pC)
            BETCOP 16(pC), rC9
            movapd rC9, 16(pC)
            BETCOP 32(pC), rC10
            movapd rC10, 32(pC)
            BETCOP 48(pC), rC11
            movapd rC11, 48(pC)
         #endif
         mov KK0, KK
         add incB, pC   /* pC += 12*8*2 = 192 */
      sub $1, nnu
      jnz MNLOOP

      mov nnu0, nnu
      mov pB0, pB
      add incAm, pA    /* pA += KB*KU*MU*size */
   sub $1, nmu
   jnz MNLOOP
@ROUT ATL_damm2x12x2_sse2.S ATL_damm2x12x256_sse2.S
/* DONE: */
   movq    (%rsp), %rbp
   movq    8(%rsp), %rbx
   movq    16(%rsp), %r12
   movq    24(%rsp), %r13
   movq    32(%rsp), %r14
   movq    40(%rsp), %r15
   add $FSIZE, %rsp
   ret
@ROUT ATL_damm2x12x2_sse2.S
/*
 * This code executed only for odd K
 */
#if KB == 0
KISTHREE:
/*
 *       Peel first 2 iteration of K to initialize rCx
 */
         movapd (pA,KK), a0
         movddup -128(pB), rC0
         mulpd a0, rC0
            prefC -128(pC)
         movddup -120(pB), rC1
         mulpd a0, rC1
            prefC -64(pC)
         movddup -112(pB), rC2
         mulpd a0, rC2
            prefC (pC)
         movddup -104(pB), rC3
         mulpd a0, rC3
            prefA -128(pfA)
         movddup -96(pB), rC4
         mulpd a0, rC4
            prefA -64(pfA)
         movddup -88(pB), rC5
         mulpd a0, rC5
            prefA (pfA)
         movddup -80(pB), rC6
         mulpd a0, rC6
            prefB -128(pfB)
         movddup -72(pB), rC7
         mulpd a0, rC7
            prefB -64(pfB)
         movddup -64(pB), rC8
         mulpd a0, rC8
            prefB (pfB)
         movddup -56(pB), rC9
         mulpd a0, rC9
         movddup -48(pB), rC10
         mulpd a0, rC10
         movddup -40(pB), rC11
         mulpd a0, rC11

         movapd 16(pA,KK), a0
         movddup -32(pB), b0
         mulpd a0, b0
         addpd b0, rC0
         movddup -24(pB), b0
         mulpd a0, b0
         addpd b0, rC1
         movddup -16(pB), b0
         mulpd a0, b0
         addpd b0, rC2
            add incPF, pfA
         movddup -8(pB), b0
         mulpd a0, b0
         addpd b0, rC3
            add incPF, pfB
         movddup (pB), b0
         mulpd a0, b0
         addpd b0, rC4
         movddup 8(pB), b0
         mulpd a0, b0
         addpd b0, rC5
         movddup 16(pB), b0
         mulpd a0, b0
         addpd b0, rC6
         movddup 24(pB), b0
         mulpd a0, b0
         addpd b0, rC7
         movddup 32(pB), b0
         mulpd a0, b0
         addpd b0, rC8
         movddup 40(pB), b0
         mulpd a0, b0
         addpd b0, rC9
         movddup 48(pB), b0
         add $32, KK
         mulpd a0, b0
         addpd b0, rC10
         movddup 56(pB), b0
         add incB, pB
         mulpd a0, b0
         addpd b0, rC11
/*
 *       Then fall thru into last K iteration to finish K==3
 */
.local ONEEXTRAKIT
ONEEXTRAKIT:
            movapd (pA,KK), a0
            movddup -128(pB), b0
            mulpd a0, b0
            addpd b0, rC0
            movddup -120(pB), b0
            mulpd a0, b0
            addpd b0, rC1
            movddup -112(pB), b0
            mulpd a0, b0
            addpd b0, rC2
            movddup -104(pB), b0
            mulpd a0, b0
            addpd b0, rC3
            movddup -96(pB), b0
            mulpd a0, b0
            addpd b0, rC4
            movddup -88(pB), b0
            mulpd a0, b0
            addpd b0, rC5
            movddup -80(pB), b0
            mulpd a0, b0
            addpd b0, rC6
            movddup -72(pB), b0
            mulpd a0, b0
            addpd b0, rC7
            movddup -64(pB), b0
            mulpd a0, b0
            addpd b0, rC8
            movddup -56(pB), b0
            mulpd a0, b0
            addpd b0, rC9
            movddup -48(pB), b0
            mulpd a0, b0
            addpd b0, rC10
            movddup -40(pB), b0
            mulpd a0, b0
            addpd b0, rC11
            jmp KLOOPDONE
#endif
@ROUT ATL_damm12x3x256_avx.S ATL_samm24x3x256_avx.S
@extract -b @(topd)/gen.inc what=crsetup
@extract -b @(topd)/cw.inc lang=c -define cwdate 2012
#include "atlas_asm.h"
#ifndef KB
   #define KB 0
#endif
/*
 * innermost (K-) loop items get priority on 1st 7 regs
 */
#define pA      %rcx
#define pB      %rdi
#define i256    %rax
#define i768    %rdx   /* 3 * 256 */
#define i1280   %rsi   /* 5 * 256 */
#define i1792   %rbx   /* 7 * 256 */
#define i2304   %r11
/*
 * Second (N-) loop items get next level of priority on good regs
 */
#define pC      %rbp
#define pfA     %r8
#define pfB     %r9
#define incPF   %r10
#define nnu     %r12
/*
 * Outer- (M-) loop variables assigned to any regs
 */
#define nmu     %r13
#define pB0     %r14
#define nnu0    %r15
/*
 * floating point registers
 */
#define m0   %ymm0
#define rA0  %ymm1
#define rA1  %ymm2
#define rA2  %ymm3
#define rB0  %ymm4
#define rB1  %ymm5
#define rB2  %ymm6
#define rC00 %ymm7
#define rC10 %ymm8
#define rC20 %ymm9
#define rC01 %ymm10
#define rC11 %ymm11
#define rC21 %ymm12
#define rC02 %ymm13
#define rC12 %ymm14
#define rC22 %ymm15
/*
                    rdi      rsi    rdx        rcx         r8        r9
void ATL_USERMM(SZT nmu, SZT nnu, SZT K, CTYPE *pA, CTYPE *pB, TYPE *pC,
                  8(%rsp)    16(%rsp)     24(%rsp)
                CTYPE *pAn, CTYPE *pBn, CTYPE *pCn);
 */

#define FSIZE 6*8
#ifndef prefA
   #define prefA prefetcht0
#endif
#ifndef prefB
   #define prefB prefetcht0
#endif
#ifndef prefC
   #ifdef ATL_3DNow
      #define prefC prefetchw
   #else
      #define prefC prefetcht0
   #endif
#endif
@ROUT ATL_samm24x3x256_avx.S
#ifdef BETAN1
   #define BETCOP vsubps
#else
   #define BETCOP vaddps
#endif
#define vmovapd vmovaps
#define vmulpd vmulps
#define vaddpd vaddps
#define vbroadcastsd vbroadcastss
@define sz @4@
@ROUT ATL_damm12x3x256_avx.S
#ifdef BETAN1
   #define BETCOP vsubpd
#else
   #define BETCOP vaddpd
#endif
#define vmovapd vmovaps
@define sz @8@
@ROUT ATL_damm12x3x256_avx.S ATL_samm24x3x256_avx.S
/*
                    rdi      rsi    rdx        rcx         r8        r9
void ATL_USERMM(SZT nmu, SZT nnu, SZT K, CTYPE *pA, CTYPE *pB, TYPE *pC,
                  8(%rsp)    16(%rsp)     24(%rsp)
                CTYPE *pAn, CTYPE *pBn, CTYPE *pCn);
 */
.text
.global ATL_asmdecor(ATL_USERMM)
ALIGN16
ATL_asmdecor(ATL_USERMM):
/*
 * Save callee-saved iregs
 */
   sub $FSIZE, %rsp
   movq    %rbp, 0(%rsp)
   movq    %rbx, 8(%rsp)
   movq    %r12, 16(%rsp)
   movq    %r13, 24(%rsp)
   movq    %r14, 32(%rsp)
   movq    %r15, 40(%rsp)
/*
 * Load paramaters
 */
   mov %rdi, nmu
   mov %rsi, nnu
   mov %r8, pB
   mov %r9, pC
   mov nnu, nnu0
   movq FSIZE+8(%rsp), pfB      /* pfB = pAn */
   movq FSIZE+16(%rsp), pfA     /* pf = pBn */
   cmp pfA, pB
   CMOVE pfB, pfA
   CMOVEq FSIZE+24(%rsp), pfB
   mov $2*12*@(sz), incPF           /* incPF = mu*nu*sizeof */
/*
 * Extend range of 1-byte offsets  by starting at -128
 */
   sub $-128, pA
   sub $-128, pB
   sub $-128, pC
   sub $-128, pfA
   sub $-128, pfB
   movq pB, pB0
@BEGINPROC doref p io r
   @define io0 @@(io)@
   @mif "pB = p
      @ROUT ATL_damm12x3x256_avx.S `@define mv @   vbroadcastsd@`
      @ROUT ATL_samm24x3x256_avx.S `@define mv @   vbroadcastss@`
   @endmif
   @mif "pB ! p
      @ROUT ATL_damm12x3x256_avx.S `@define mv @   vmovapd@`
      @ROUT ATL_samm24x3x256_avx.S `@define mv @   vmovaps@`
   @endmif
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io < 128
         @(mv) @(of)(@(p)), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 384
         @(mv) @(of)(@(p),i256), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 640
         @(mv) @(of)(@(p),i256,2), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 896
         @(mv) @(of)(@(p),i768), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 1152
         @(mv) @(of)(@(p),i256,4), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 1408
         @(mv) @(of)(@(p),i1280), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 1664
         @(mv) @(of)(@(p),i768,2), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 1920
         @(mv) @(of)(@(p),i1792), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 2176
         @(mv) @(of)(@(p),i256,8), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 2432
         @(mv) @(of)(@(p),i2304), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 2688
         @(mv) @(of)(@(p),i1280,2), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 2944
         @(mv) @(io0)(@(p)), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 3200
         @(mv) @(of)(@(p),i768,4), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 3456
         @(mv) @(io0)(@(p)), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 3712
         @(mv) @(of)(@(p),i1792,2), @(r)
      @endextract
   @endiif
   @iif io0 < 4736
      @iif io0 > 4479
         @iexp io @(io0) -4480 +
         @iexp io @(io) -128 +
         @iif io = 0
         @(mv) (@(p),i2304,2), @(r)
         @endiif
         @iif io ! 0
         @(mv) @(io)(@(p),i2304,2), @(r)
         @endiif
         @endextract
      @endiif
   @endiif
   @iif io0 < 5248
      @iif io0 > 4991
         @iexp io @(io0) -4992 +
         @iexp io @(io) -128 +
         @iif io = 0
         @(mv) (@(p),i1280,4), @(r)
         @endiif
         @iif io ! 0
         @(mv) @(io)(@(p),i1280,4), @(r)
         @endiif
         @endextract
      @endiif
   @endiif
   @iif io0 < 6272
      @iif io0 > 6015
         @iexp io @(io0) -6016 +
         @iexp io @(io) -128 +
         @iif io = 0
         @(mv) (@(p),i768,8), @(r)
         @endiif
         @iif io ! 0
         @(mv) @(io)(@(p),i768,8), @(r)
         @endiif
         @endextract
      @endiif
   @endiif
   @iif io0 < 7296
      @iif io0 > 7039
         @iexp io @(io0) -7040 +
         @iexp io @(io) -128 +
         @iif io = 0
         @(mv) (@(p),i1792,4), @(r)
         @endiif
         @iif io ! 0
         @(mv) @(io)(@(p),i1792,4), @(r)
         @endiif
         @endextract
      @endiif
   @endiif
   @iif io0 < 7296
      @iif io0 > 7039
         @iexp io @(io0) -7040 +
         @iexp io @(io) -128 +
         @iif io = 0
         @(mv) (@(p),i1792,4), @(r)
         @endiif
         @iif io ! 0
         @(mv) @(io)(@(p),i1792,4), @(r)
         @endiif
         @endextract
      @endiif
   @endiif
   @iif io0 < 9344
      @iif io0 > 9087
         @iexp io @(io0) -9088 +
         @iexp io @(io) -128 +
         @iif io = 0
         @(mv) (@(p),i2304,4), @(r)
         @endiif
         @iif io ! 0
         @(mv) @(io)(@(p),i2304,4), @(r)
         @endiif
         @endextract
      @endiif
   @endiif
   @iif io0 < 10368
      @iif io0 > 10111
         @iexp io @(io0) -10112 +
         @iexp io @(io) -128 +
         @iif io = 0
         @(mv) (@(p),i1280,8), @(r)
         @endiif
         @iif io ! 0
         @(mv) @(io)(@(p),i1280,8), @(r)
         @endiif
         @endextract
      @endiif
   @endiif
@SKIP default case just indexes ptr
         @(mv) @(io0)(@(p)), @(r)
   @undef io0
   @undef of
   @undef mv
@ENDPROC
   mov $256, i256
   lea (i256, i256,2), i768
   lea (i256, i256,4), i1280
   lea (i256, i768,2), i1792
   lea (i256, i256,8), i2304
   ALIGN8
   .local MNLOOP
   MNLOOP:
/*
      .local NLOOP
      NLOOP:
*/
/*
 *       Peel first iteration of K loop to initialize rCx
 */
@iexp bo -128 0 +
         vmovapd -128(pA), rA0
         @callproc doref pB @(bo) rB0
         @iexp bo @(bo) @(sz) +
         vmulpd rA0, rB0, rC00
         vmovapd -96(pA), rA1
         vmulpd rA1, rB0, rC10
         vmovapd -64(pA), rA2
         vmulpd rA2, rB0, rC20
         @callproc doref pB @(bo) rB1
         @iexp bo @(bo) @(sz) +
         vmulpd rA0, rB1, rC01
         @callproc doref pB @(bo) rB2
         @iexp bo @(bo) @(sz) +
         vmulpd rA1, rB1, rC11
         #if KB > 1
         @callproc doref pB @(bo) rB0
         @iexp bo @(bo) @(sz) +
         #endif
         vmulpd rA2, rB1, rC21
         #if KB > 1
         @callproc doref pB @(bo) rB1
         @iexp bo @(bo) @(sz) +
         #endif
         vmulpd rA0, rB2, rC02
         #if KB > 1
            vmovapd -32(pA), rA0
         #endif
         vmulpd rA1, rB2, rC12
         #if KB > 1
            vmovapd (pA), rA1
         #endif
         vmulpd rA2, rB2, rC22
         #if KB > 1
            vmovapd 32(pA), rA2
         #endif
/*
 *       Fully unrolled K-loop
 */
@iexp ao 64 0 +
@skip @iexp bo -88 0 +
@iexp k 1 0 +
@iwhile k < 256
         #if KB > @(k)
   @iexp k @(k) 1 +
            vmulpd rB0, rA0, m0
            vaddpd rC00, m0, rC00
            @callproc doref pB @(bo) rB2
            @iexp bo @(bo) @(sz) +
            vmulpd rB0, rA1, m0
            vaddpd rC10, m0, rC10
            @iif @(k) = 1
               prefC -128(pC)
            @endiif
            @iif @(k) = 2
               prefC (pC)
            @endiif
            @iif @(k) = 3
               prefC 128(pC)
            @endiif
            @iif @(k) = 4
            prefA -128(pfA)
            @endiif
            @iif @(k) = 5
            prefA -64(pfA)
            @endiif
            @iif @(k) = 6
            prefA (pfA)
            @endiif
            @iif @(k) = 7
            prefB -128(pfB)
            @endiif
            @iif @(k) = 8
            prefB -64(pfB)
            @endiif
            @iif @(k) = 9
            prefB (pfB)
            @endiif
            vmulpd rB0, rA2, m0
            vaddpd rC20, m0, rC20
            #if KB > @(k)
               @callproc doref pB @(bo) rB0
               @iexp bo @(bo) @(sz) +
            #endif

            vmulpd rB1, rA0, m0
            vaddpd rC01, m0, rC01
            @iif @(k) = 1
               prefC -64(pC)
            @endiif
            @iif @(k) = 2
               prefC 64(pC)
            @endiif
            vmulpd rB1, rA1, m0
            vaddpd rC11, m0, rC11
            vmulpd rB1, rA2, m0
            vaddpd rC21, m0, rC21
            #if KB > @(k)
               @callproc doref pB @(bo) rB1
               @iexp bo @(bo) @(sz) +
            #endif
      
            vmulpd rB2, rA0, m0
            vaddpd rC02, m0, rC02
            #if KB > @(k)
               @callproc doref pA @(ao) rA0
               @iexp ao @(ao) 32 +
            #endif
            vmulpd rB2, rA1, m0
            vaddpd rC12, m0, rC12
            #if KB > @(k)
               @callproc doref pA @(ao) rA1
               @iexp ao @(ao) 32 +
            #endif
            vmulpd rB2, rA2, m0
            vaddpd rC22, m0, rC22
            #if KB > @(k)
               @callproc doref pA @(ao) rA2
               @iexp ao @(ao) 32 +
            #endif

         #endif
@endiwhile
         add incPF, pfA
         add incPF, pfB
/*
 *       Write answer back out to C
 */
         #ifdef BETA0
            vmovapd rC00, -128(pC)
            vmovapd rC10, -96(pC)
            vmovapd rC20, -64(pC)
            vmovapd rC01, -32(pC)
            vmovapd rC11, (pC)
            vmovapd rC21, 32(pC)
            vmovapd rC02, 64(pC)
            vmovapd rC12, 96(pC)
            vmovapd rC22, 128(pC)
/*
 *          Add running sum in rCx with original C, then store back out
 */
         #else
            BETCOP -128(pC), rC00, rC00
            vmovapd rC00, -128(pC)
            BETCOP -96(pC), rC10, rC10
            vmovapd rC10, -96(pC)
            BETCOP -64(pC), rC20, rC20
            vmovapd rC20, -64(pC)
            BETCOP -32(pC), rC01, rC01
            vmovapd rC01, -32(pC)
            BETCOP (pC), rC11, rC11
            vmovapd rC11, (pC)
            BETCOP 32(pC), rC21, rC21
            vmovapd rC21, 32(pC)
            BETCOP 64(pC), rC02, rC02
            vmovapd rC02, 64(pC)
            BETCOP 96(pC), rC12, rC12
            vmovapd rC12, 96(pC)
            BETCOP 128(pC), rC22, rC22
            vmovapd rC22, 128(pC)
         #endif
         add $12*3*8, pC        /* pC += MU*NU*sizeof */
         add $KB*3*@(sz), pB        /* pB += K*NU*sizeof */
      sub $1, nnu
      jnz MNLOOP

      mov nnu0, nnu
      mov pB0, pB
      add $KB*12*8, pA          /* pA += KB*MU*size */
   sub $1, nmu
   jnz MNLOOP
/* DONE: */
   movq    (%rsp), %rbp
   movq    8(%rsp), %rbx
   movq    16(%rsp), %r12
   movq    24(%rsp), %r13
   movq    32(%rsp), %r14
   movq    40(%rsp), %r15
   add $FSIZE, %rsp
   ret
@ROUT ATL_damm6x3x256_sse3.S ATL_damm6x3x4_sse3.S
@extract -b @(topd)/gen.inc what=crsetup
@extract -b @(topd)/cw.inc lang=c -define cwdate 2012
#include "atlas_asm.h"
#ifndef KB
   #define KB 0
#endif
/*
 * innermost (K-) loop items get priority on 1st 7 regs
 */
#define pA      %rcx
#define pB      %rdi
@ROUT ATL_damm6x3x256_sse3.S ATL_damm6x3x4_sse3.S
#define KK0     %rax
#define KK      %rdx
#define incA    %rsi
#define incB    %rbx
#define pA0     %r11
@ROUT ATL_damm6x3x256_sse3.S
#define i256    %rax
#define i768    %rdx   /* 3 * 256 */
#define i1280   %rsi   /* 5 * 256 */
#define i1792   %rbx   /* 7 * 256 */
#define i2304   %r11
@ROUT ATL_damm6x3x256_sse3.S ATL_damm6x3x4_sse3.S
/*
 * Second (N-) loop items get next level of priority on good regs
 */
#define pC      %rbp
#define pfA     %r8
#define pfB     %r9
#define incPF   %r10
#define nnu     %r12
/*
 * Outer- (M-) loop variables assigned to any regs
 */
#define nmu     %r13
#define pB0     %r14
#define nnu0    %r15
/*
 * floating point registers
 */
#define m0   %xmm0
#define rA0  %xmm1
#define rA1  %xmm2
#define rA2  %xmm3
#define rB0  %xmm4
#define rB1  %xmm5
#define rB2  %xmm6
#define rC00 %xmm7
#define rC10 %xmm8
#define rC20 %xmm9
#define rC01 %xmm10
#define rC11 %xmm11
#define rC21 %xmm12
#define rC02 %xmm13
#define rC12 %xmm14
#define rC22 %xmm15
/*
                    rdi      rsi    rdx        rcx         r8        r9
void ATL_USERMM(SZT nmu, SZT nnu, SZT K, CTYPE *pA, CTYPE *pB, TYPE *pC,
                  8(%rsp)    16(%rsp)     24(%rsp)
                CTYPE *pAn, CTYPE *pBn, CTYPE *pCn);
 */

#define FSIZE 6*8
#ifndef prefA
   #define prefA prefetcht0
#endif
#ifndef prefB
   #define prefB prefetcht2
#endif
#ifndef prefC
   #ifdef ATL_3DNow
      #define prefC prefetchw
   #else
      #define prefC prefetcht0
   #endif
#endif
#ifdef BETAN1
   #define BETCOP subpd
#else
   #define BETCOP addpd
#endif
#define movapd movaps
@define sz @8@
/*
                    rdi      rsi    rdx        rcx         r8        r9
void ATL_USERMM(SZT nmu, SZT nnu, SZT K, CTYPE *pA, CTYPE *pB, TYPE *pC,
                  8(%rsp)    16(%rsp)     24(%rsp)
                CTYPE *pAn, CTYPE *pBn, CTYPE *pCn);
 */
.text
.global ATL_asmdecor(ATL_USERMM)
ALIGN16
ATL_asmdecor(ATL_USERMM):
/*
 * Save callee-saved iregs
 */
   sub $FSIZE, %rsp
   movq    %rbp, 0(%rsp)
   movq    %rbx, 8(%rsp)
   movq    %r12, 16(%rsp)
   movq    %r13, 24(%rsp)
   movq    %r14, 32(%rsp)
   movq    %r15, 40(%rsp)
/*
 * Load paramaters
 */
   mov %rdi, nmu
   mov %rsi, nnu
   mov %r8, pB
   mov %r9, pC
   mov nnu, nnu0
   movq FSIZE+8(%rsp), pfB      /* pfB = pAn */
   movq FSIZE+16(%rsp), pfA     /* pf = pBn */
   cmp pfA, pB
   CMOVE pfB, pfA
   CMOVEq FSIZE+24(%rsp), pfB
   mov $6*3*@(sz), incPF           /* incPF = mu*nu*sizeof */
/*
 * Extend range of 1-byte offsets  by starting at -128
 */
   sub $-128, pA
   sub $-128, pB
   sub $-128, pC
   sub $-128, pfA
   sub $-128, pfB
   movq pB, pB0
@BEGINPROC doref p io r
   @define io0 @@(io)@
   @mif "pB = p
      @define mv @   movddup@
   @endmif
   @mif "pB ! p
      @define mv @   movapd@
   @endmif
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io < 128
         @(mv) @(of)(@(p)), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 384
         @(mv) @(of)(@(p),i256), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 640
         @(mv) @(of)(@(p),i256,2), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 896
         @(mv) @(of)(@(p),i768), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 1152
         @(mv) @(of)(@(p),i256,4), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 1408
         @(mv) @(of)(@(p),i1280), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 1664
         @(mv) @(of)(@(p),i768,2), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 1920
         @(mv) @(of)(@(p),i1792), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 2176
         @(mv) @(of)(@(p),i256,8), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 2432
         @(mv) @(of)(@(p),i2304), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 2688
         @(mv) @(of)(@(p),i1280,2), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 2944
         @(mv) @(io0)(@(p)), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 3200
         @(mv) @(of)(@(p),i768,4), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 3456
         @(mv) @(io0)(@(p)), @(r)
      @endextract
   @endiif
@skip   @callproc decio
   @iexp io @(io) -256 +
   @undef of
   @iif io = 0
      @define of @@
   @endiif
   @iif io ! 0
      @define of @@(io)@
   @endiif
   @iif io0 < 3712
         @(mv) @(of)(@(p),i1792,2), @(r)
      @endextract
   @endiif
   @iif io0 < 4736
      @iif io0 > 4479
         @iexp io @(io0) -4480 +
         @iexp io @(io) -128 +
         @iif io = 0
         @(mv) (@(p),i2304,2), @(r)
         @endiif
         @iif io ! 0
         @(mv) @(io)(@(p),i2304,2), @(r)
         @endiif
         @endextract
      @endiif
   @endiif
   @iif io0 < 5248
      @iif io0 > 4991
         @iexp io @(io0) -4992 +
         @iexp io @(io) -128 +
         @iif io = 0
         @(mv) (@(p),i1280,4), @(r)
         @endiif
         @iif io ! 0
         @(mv) @(io)(@(p),i1280,4), @(r)
         @endiif
         @endextract
      @endiif
   @endiif
   @iif io0 < 6272
      @iif io0 > 6015
         @iexp io @(io0) -6016 +
         @iexp io @(io) -128 +
         @iif io = 0
         @(mv) (@(p),i768,8), @(r)
         @endiif
         @iif io ! 0
         @(mv) @(io)(@(p),i768,8), @(r)
         @endiif
         @endextract
      @endiif
   @endiif
   @iif io0 < 7296
      @iif io0 > 7039
         @iexp io @(io0) -7040 +
         @iexp io @(io) -128 +
         @iif io = 0
         @(mv) (@(p),i1792,4), @(r)
         @endiif
         @iif io ! 0
         @(mv) @(io)(@(p),i1792,4), @(r)
         @endiif
         @endextract
      @endiif
   @endiif
   @iif io0 < 7296
      @iif io0 > 7039
         @iexp io @(io0) -7040 +
         @iexp io @(io) -128 +
         @iif io = 0
         @(mv) (@(p),i1792,4), @(r)
         @endiif
         @iif io ! 0
         @(mv) @(io)(@(p),i1792,4), @(r)
         @endiif
         @endextract
      @endiif
   @endiif
   @iif io0 < 9344
      @iif io0 > 9087
         @iexp io @(io0) -9088 +
         @iexp io @(io) -128 +
         @iif io = 0
         @(mv) (@(p),i2304,4), @(r)
         @endiif
         @iif io ! 0
         @(mv) @(io)(@(p),i2304,4), @(r)
         @endiif
         @endextract
      @endiif
   @endiif
   @iif io0 < 10368
      @iif io0 > 10111
         @iexp io @(io0) -10112 +
         @iexp io @(io) -128 +
         @iif io = 0
         @(mv) (@(p),i1280,8), @(r)
         @endiif
         @iif io ! 0
         @(mv) @(io)(@(p),i1280,8), @(r)
         @endiif
         @endextract
      @endiif
   @endiif
@SKIP default case just indexes ptr
         @(mv) @(io0)(@(p)), @(r)
   @undef io0
   @undef of
   @undef mv
@ENDPROC
@ROUT ATL_damm6x3x4_sse3.S
   mov pA, pA0
   mov KK, KK0
   mov $192, incA
   mov $96, incB
@ROUT ATL_damm6x3x256_sse3.S
   mov $256, i256
   lea (i256, i256,2), i768
   lea (i256, i256,4), i1280
   lea (i256, i768,2), i1792
   lea (i256, i256,8), i2304
@iexp bo -128 0 +
   @callproc doref pB @(bo) rB0
   @iexp bo @(bo) @(sz) +
   @callproc doref pB @(bo) rB1
   @iexp bo @(bo) @(sz) +
   ALIGN8
@ROUT ATL_damm6x3x4_sse3.S
@iexp bo -128 0 +
   @callproc doref pB @(bo) rB0
   @iexp bo @(bo) @(sz) +
   @callproc doref pB @(bo) rB1
   @iexp bo @(bo) @(sz) +
   nop ; nop ; nop ; nop ; nop
@ROUT ATL_damm6x3x256_sse3.S ATL_damm6x3x4_sse3.S
   .local MNLOOP
   MNLOOP:
/*
      .local NLOOP
      NLOOP:
*/
/*
 *       Peel first iteration of K loop to initialize rCx
 */
         movapd -128(pA), rC02
         movapd rC02, rC00
         mulpd rB0, rC00
         movapd -112(pA), rC12
         movapd rC12, rC10
         mulpd rB0, rC10
         movapd -96(pA), rC22
         movapd rC22, rC20
         mulpd rB0, rC20

         movapd rC02, rC01
         mulpd rB1, rC01
         @callproc doref pB @(bo) rB2
         @iexp bo @(bo) @(sz) +
         movapd rC12, rC11
         mulpd rB1, rC11
            prefC -128(pC)
         movapd rC22, rC21
         mulpd rB1, rC21

         mulpd rB2, rC02
         #if KB > 1
         @callproc doref pB @(bo) rB0
         @iexp bo @(bo) @(sz) +
         #endif
         mulpd rB2, rC12
         #if KB > 1
         @callproc doref pB @(bo) rB1
         @iexp bo @(bo) @(sz) +
         #endif
         mulpd rB2, rC22

@ROUT ATL_damm6x3x4_sse3.S
         movapd -80(pA), rA0
         movapd rA0, m0
         mulpd rB0, m0
         addpd m0, rC00
         movapd -64(pA), rA1
         movapd rA1, m0
         mulpd rB0, m0
         addpd m0, rC10
         movapd -48(pA), rA2
         mulpd rA2, rB0
         addpd rB0, rC20

            prefC 64(pC)
         movapd rA0, m0
         mulpd rB1, m0
         addpd m0, rC01
            prefA -128(pfA)
         movapd rA1, m0
         mulpd rB1, m0
         addpd m0, rC11
         mulpd rA2, rB1
         addpd rB1, rC21

         movddup -88(pB), rB2
         mulpd rB2, rA0
         addpd rA0, rC02
            movddup -80(pB), rB0
         mulpd rB2, rA1
         addpd rA1, rC12
            movddup -72(pB), rB1
         mulpd rB2, rA2
         addpd rA2, rC22

         movapd -32(pA), rA0
         movapd rA0, m0
         mulpd rB0, m0
         addpd m0, rC00
         movapd -16(pA), rA1
         movapd rA1, m0
         mulpd rB0, m0
         addpd m0, rC10
         movapd (pA), rA2
         mulpd rA2, rB0
         addpd rB0, rC20

            prefA -64(pfA)
         movapd rA0, m0
         mulpd rB1, m0
         addpd m0, rC01
            prefA (pfA)
         movapd rA1, m0
         mulpd rB1, m0
         addpd m0, rC11
         mulpd rA2, rB1
         addpd rB1, rC21

         movddup -64(pB), rB2
         mulpd rB2, rA0
         addpd rA0, rC02
            movddup -56(pB), rB0
         mulpd rB2, rA1
         addpd rA1, rC12
            movddup -48(pB), rB1
         mulpd rB2, rA2
         addpd rA2, rC22

         movapd 16(pA), rA0
         movapd rA0, m0
         mulpd rB0, m0
         addpd m0, rC00
         movapd 32(pA), rA1
         movapd rA1, m0
         mulpd rB0, m0
         addpd m0, rC10
         movapd 48(pA), rA2
         mulpd rA2, rB0
         addpd rB0, rC20

            prefB -128(pfB)
         movapd rA0, m0
         mulpd rB1, m0
         addpd m0, rC01
            prefB -64(pfB)
         movapd rA1, m0
         mulpd rB1, m0
         addpd m0, rC11
            prefB (pfB)
         mulpd rA2, rB1
         addpd rB1, rC21

         movddup -40(pB), rB2
         add incB, pB
         mulpd rB2, rA0
         addpd rA0, rC02
            movddup -128(pB), rB0
         mulpd rB2, rA1
         addpd rA1, rC12
            movddup -120(pB), rB1
         mulpd rB2, rA2
            add incA, pA
         addpd rA2, rC22
         sub $4, KK
         jz KLOOPDONE

         KLOOP:
            movapd -128(pA), rA0
            movapd rA0, m0
            mulpd rB0, m0
            addpd m0, rC00
            movapd -112(pA), rA1
            movapd rA1, m0
            mulpd rB0, m0
            addpd m0, rC10
            movapd -96(pA), rA2
            mulpd rA2, rB0
            addpd rB0, rC20

            movapd rA0, m0
            mulpd rB1, m0
            addpd m0, rC01
            movapd rA1, m0
            mulpd rB1, m0
            addpd m0, rC11
            mulpd rA2, rB1
            addpd rB1, rC21

            movddup -112(pB), rB2
            mulpd rB2, rA0
            addpd rA0, rC02
               movddup -104(pB), rB0
            mulpd rB2, rA1
            addpd rA1, rC12
               movddup -96(pB), rB1
            mulpd rB2, rA2
            addpd rA2, rC22

            movapd -80(pA), rA0
            movapd rA0, m0
            mulpd rB0, m0
            addpd m0, rC00
            movapd -64(pA), rA1
            movapd rA1, m0
            mulpd rB0, m0
            addpd m0, rC10
            movapd -48(pA), rA2
            mulpd rA2, rB0
            addpd rB0, rC20

            movapd rA0, m0
            mulpd rB1, m0
            addpd m0, rC01
            movapd rA1, m0
            mulpd rB1, m0
            addpd m0, rC11
            mulpd rA2, rB1
            addpd rB1, rC21

            movddup -88(pB), rB2
            mulpd rB2, rA0
            addpd rA0, rC02
               movddup -80(pB), rB0
            mulpd rB2, rA1
            addpd rA1, rC12
               movddup -72(pB), rB1
            mulpd rB2, rA2
            addpd rA2, rC22

            movapd -32(pA), rA0
            movapd rA0, m0
            mulpd rB0, m0
            addpd m0, rC00
            movapd -16(pA), rA1
            movapd rA1, m0
            mulpd rB0, m0
            addpd m0, rC10
            movapd (pA), rA2
            mulpd rA2, rB0
            addpd rB0, rC20

            movapd rA0, m0
            mulpd rB1, m0
            addpd m0, rC01
            movapd rA1, m0
            mulpd rB1, m0
            addpd m0, rC11
            mulpd rA2, rB1
            addpd rB1, rC21

            movddup -64(pB), rB2
            mulpd rB2, rA0
            addpd rA0, rC02
               movddup -56(pB), rB0
            mulpd rB2, rA1
            addpd rA1, rC12
               movddup -48(pB), rB1
            mulpd rB2, rA2
            addpd rA2, rC22

            movapd 16(pA), rA0
            movapd rA0, m0
            mulpd rB0, m0
            addpd m0, rC00
            movapd 32(pA), rA1
            movapd rA1, m0
            mulpd rB0, m0
            addpd m0, rC10
            movapd 48(pA), rA2
            mulpd rA2, rB0
            addpd rB0, rC20

            movapd rA0, m0
            mulpd rB1, m0
            addpd m0, rC01
            movapd rA1, m0
            mulpd rB1, m0
            addpd m0, rC11
               add incA, pA
            mulpd rA2, rB1
            addpd rB1, rC21

            movddup -40(pB), rB2
            mulpd rB2, rA0
            addpd rA0, rC02
               movddup -32(pB), rB0
            mulpd rB2, rA1
            addpd rA1, rC12
               movddup -24(pB), rB1
            mulpd rB2, rA2
            add incB, pB
            addpd rA2, rC22
         sub $4, KK
         jnz KLOOP
         KLOOPDONE:
@ROUT ATL_damm6x3x256_sse3.S
/*
 *       Fully unrolled K-loop
 */
@define vsz @16@
@iexp ao -80 0 +
@iexp k 1 0 +
@iwhile k < 256
         #if KB > @(k)
   @iexp k @(k) 1 +
            @callproc doref pA @(ao) rA0
            @iexp ao @(ao) @(vsz) +
            movapd rA0, m0
            mulpd rB0, m0
            addpd m0, rC00
            @callproc doref pA @(ao) rA1
            @iexp ao @(ao) @(vsz) +
            movapd rA1, m0
            mulpd rB0, m0
            addpd m0, rC10
            @callproc doref pA @(ao) rA2
            @iexp ao @(ao) @(vsz) +
            mulpd rA2, rB0
            addpd rB0, rC20

            @iif @(k) = 1
               prefC -64(pC)
            @endiif
            @iif @(k) = 2
               prefC (pC)
            @endiif
            @iif @(k) = 3
               prefA -128(pfA)
            @endiif
            @iif @(k) = 4
               prefA -64(pfA)
            @endiif
            @iif @(k) = 5
               prefA (pfA)
            @endiif
            @iif @(k) = 6
               prefB -128(pfB)
            @endiif
            @iif @(k) = 7
               prefB -64(pfB)
            @endiif
            @iif @(k) = 8
               prefB (pfB)
            @endiif
            movapd rA0, m0
            mulpd rB1, m0
            addpd m0, rC01
            movapd rA1, m0
            mulpd rB1, m0
            addpd m0, rC11
            mulpd rA2, rB1
            addpd rB1, rC21

            @callproc doref pB @(bo) rB2
            @iexp bo @(bo) @(sz) +
            mulpd rB2, rA0
            addpd rA0, rC02
            #if KB > @(k)
            @callproc doref pB @(bo) rB0
            @iexp bo @(bo) @(sz) +
            #endif
            mulpd rB2, rA1
            addpd rA1, rC12
            #if KB > @(k)
            @callproc doref pB @(bo) rB1
            @iexp bo @(bo) @(sz) +
            #endif
            mulpd rB2, rA2
            addpd rA2, rC22
         #endif
@endiwhile
@ROUT ATL_damm6x3x256_sse3.S ATL_damm6x3x4_sse3.S
         add incPF, pfA
         add incPF, pfB
/*
 *       Write answer back out to C
 */
         #ifdef BETA0
            movapd rC00, -128(pC)
            movapd rC10, -112(pC)
            movapd rC20, -96(pC)
            movapd rC01, -80(pC)
            movapd rC11, -64(pC)
            movapd rC21, -48(pC)
            movapd rC02, -32(pC)
            movapd rC12, -16(pC)
            movapd rC22, (pC)
/*
 *          Add running sum in rCx with original C, then store back out
 */
         #else
            BETCOP -128(pC), rC00
            movapd rC00, -128(pC)
            BETCOP -112(pC), rC10
            movapd rC10, -112(pC)
            BETCOP -96(pC), rC20
            movapd rC20, -96(pC)
            BETCOP -80(pC), rC01
            movapd rC01, -80(pC)
            BETCOP -64(pC), rC11
            movapd rC11, -64(pC)
            BETCOP -48(pC), rC21
            movapd rC21, -48(pC)
            BETCOP -32(pC), rC02
            movapd rC02, -32(pC)
            BETCOP -16(pC), rC12
            movapd rC12, -16(pC)
            BETCOP (pC), rC22
            movapd rC22, (pC)
         #endif
@ROUT ATL_damm6x3x256_sse3.S `         add $KB*3*@(sz), pB        /* pB += K*NU*sizeof */`
         add $6*3*8, pC        /* pC += MU*NU*sizeof */
         movddup -128(pB), rB0
      sub $1, nnu
         movddup -120(pB), rB1
@ROUT ATL_damm6x3x4_sse3.S `         mov KK0, KK`
@ROUT ATL_damm6x3x4_sse3.S `         mov pA0, pA`
      jnz MNLOOP

         movddup -128(pB0), rB0
      mov nnu0, nnu
         movddup -120(pB0), rB1
      mov pB0, pB
@ROUT ATL_damm6x3x4_sse3.S
      lea (KK, KK, 4), pA      /* pA = 5*K */
      add KK, pA               /* pA = 6*K = MU*K */
      shl $3, pA               /* pA = MU*K*sizeof */
      add pA0, pA              /* pA = A + MU*K*sizeof */
      mov pA, pA0
@ROUT ATL_damm6x3x256_sse3.S
      add $KB*6*8, pA          /* pA += KB*MU*size */
@ROUT ATL_damm6x3x256_sse3.S ATL_damm6x3x4_sse3.S
   sub $1, nmu
   jnz MNLOOP
/* DONE: */
   movq    (%rsp), %rbp
   movq    8(%rsp), %rbx
   movq    16(%rsp), %r12
   movq    24(%rsp), %r13
   movq    32(%rsp), %r14
   movq    40(%rsp), %r15
   add $FSIZE, %rsp
   ret
@ROUT ATL_samm16x4x1_av.c
#include "atlas_misc.h"
#define ATL_NoFakePF
#include "atlas_prefetch.h"

#ifndef ATL_CSZT
   #define ATL_CSZT const size_t
#endif
void ATL_USERMM
(
   ATL_CSZT nmus,
   ATL_CSZT nnus,
   ATL_CSZT K,
   const TYPE *pA,    /* 4*KB*nmus-length access-major array of A */
   const TYPE *pB,    /* 1*KB*nnus-length access-major array of B */
   TYPE *pC,          /* 4*1*nnus*nmus-length access-major array of C */
   const TYPE *pAn,   /* next block of A */
   const TYPE *pBn,   /* next block of B */
   const TYPE *pCn    /* next block of C */
)
/*
 * Very basic 4x4 KU=1 AltiVec kernel
 */
{
   const TYPE *pB0 = pB, *pA0 = pA;
   const TYPE *pfA, *pfB;
   size_t incPF, i, j, k;
   vector float vA0, vA1, vA2, vA3, vB0, vB1, vB2, vB3;
   vector float  vC00, vC10, vC20, vC30, vC01, vC11, vC21, vC31,
                 vC02, vC12, vC22, vC32, vC03, vC13, vC23, vC33;
   #ifndef ATL_NoIEEE /* turn on java/ieee mode */
         const vector int izero   =  VECTOR_INITI(0,0,0,0);
         vec_mtvscr(izero);
   #endif

  if (pAn != pA)
   {
      pfA = pAn;
      incPF = (nmus*4*K) / (nmus * nnus);
      pfB = (pBn != pB) ? pBn : pCn;

   }
   else if (pCn != pC)
   {
      pfA = pCn;
      incPF = (nmus*4*nnus*1) / (nmus * nnus);
      pfB = pBn;
   }
   else if (pBn != pB)
   {
      pfA = pBn;
      pfB = pBn +((nmus*4*nnus*1)>>1);
      incPF = (K*nnus*1*sizeof(TYPE)) / ((nmus * nnus)<<1);
   }
   else
   {
      pfA = pA + nmus*4*(K>>1);
      incPF = (nmus*4*K) / (nmus * nnus);
   }
   for (i=0; i < nmus; i++)
   {
      for (j=0; j < nnus; j++)
      {
/*
 *       Peel K=0 iteration to prefetch
 */
         vC33 = vec_xor(vC33, vC33);
         vB3 = vec_ld(0, pB);
         ATL_pfl1W(pC);
         ATL_pfl1W(pC+32);
         vB0 = vec_splat(vB3, 0);
         vB1 = vec_splat(vB3, 1);
         vB2 = vec_splat(vB3, 2);
         vB3 = vec_splat(vB3, 3);

         vA0 = vec_ld(0, pA);
         vA1 = vec_ld(0, pA+4);
         vA2 = vec_ld(0, pA+8);
         vA3 = vec_ld(0, pA+12);

         vC00 = vec_madd(vA0, vB0, vC33);
         ATL_pfl1R(pfA);
         vC10 = vec_madd(vA1, vB0, vC33);
         vC20 = vec_madd(vA2, vB0, vC33);
         vC30 = vec_madd(vA3, vB0, vC33);
         vC01 = vec_madd(vA0, vB1, vC33);
         vC11 = vec_madd(vA1, vB1, vC33);
         vC21 = vec_madd(vA2, vB1, vC33);
         vC31 = vec_madd(vA3, vB1, vC33);
            vB1 = vec_ld(0, pB+4);
         vC02 = vec_madd(vA0, vB2, vC33);
            vB0 = vec_splat(vB1, 0);
         vC12 = vec_madd(vA1, vB2, vC33);
         vC22 = vec_madd(vA2, vB2, vC33);
         vC32 = vec_madd(vA3, vB2, vC33);
            vB2 = vec_splat(vB1, 2);
         vC03 = vec_madd(vA0, vB3, vC33);
            vA0 = vec_ld(0, pA+16);
         vC13 = vec_madd(vA1, vB3, vC33);
            vA1 = vec_ld(0, pA+20);
         vC23 = vec_madd(vA2, vB3, vC33);
            vA2 = vec_ld(0, pA+24);
         vC33 = vec_madd(vA3, vB3, vC33);
            vB3 = vec_splat(vB1, 3);
         pA += 32;
         pB += 8;
/*
 *       Handle remaining K its with rolled loop (compiler can unroll easily)
 */
      #if KB != 0
         for (k=1; k < KB; k++)
      #else
         for (k=1; k < K; k++)
      #endif
         {
               vA3 = vec_ld(0, pA-4);
            vC00 = vec_madd(vA0, vB0, vC00);
            vC10 = vec_madd(vA1, vB0, vC10);
            vC20 = vec_madd(vA2, vB0, vC20);
            vC30 = vec_madd(vA3, vB0, vC30);
               vB1 = vec_splat(vB1, 1);
            vC01 = vec_madd(vA0, vB1, vC01);
            vC11 = vec_madd(vA1, vB1, vC11);
            vC21 = vec_madd(vA2, vB1, vC21);
            vC31 = vec_madd(vA3, vB1, vC31);
               vB1 = vec_ld(0, pB);
            vC02 = vec_madd(vA0, vB2, vC02);
               vB0 = vec_splat(vB1, 0);
            vC12 = vec_madd(vA1, vB2, vC12);
            vC22 = vec_madd(vA2, vB2, vC22);
            vC32 = vec_madd(vA3, vB2, vC32);
               vB2 = vec_splat(vB1, 2);
            vC03 = vec_madd(vA0, vB3, vC03);
            vC13 = vec_madd(vA1, vB3, vC13);
               vA0 = vec_ld(0, pA);
               vA1 = vec_ld(0, pA+4);
            vC23 = vec_madd(vA2, vB3, vC23);
            vC33 = vec_madd(vA3, vB3, vC33);
               vA2 = vec_ld(0, pA+8);
               vB3 = vec_splat(vB1, 3);
            pA += 16;
            pB += 4;
         }
         #ifdef BETA0
           vec_st(vC00, 0, pC);
           vec_st(vC10, 0, pC+4);
           vec_st(vC20, 0, pC+8);
           vec_st(vC30, 0, pC+12);
           vec_st(vC01, 0, pC+16);
           vec_st(vC11, 0, pC+20);
           vec_st(vC21, 0, pC+24);
           vec_st(vC31, 0, pC+28);
           vec_st(vC02, 0, pC+32);
           vec_st(vC12, 0, pC+36);
           vec_st(vC22, 0, pC+40);
           vec_st(vC32, 0, pC+44);
           vec_st(vC03, 0, pC+48);
           vec_st(vC13, 0, pC+52);
           vec_st(vC23, 0, pC+56);
           vec_st(vC33, 0, pC+60);
         #else
            #ifdef BETAN1
               #define VEC_ADD vec_sub
            #else
               #define VEC_ADD vec_add
            #endif
            vA0 = vec_ld(0, pC);
            vA1 = vec_ld(0, pC+4);
            vA2 = vec_ld(0, pC+8);
            vA3 = vec_ld(0, pC+12);
            vC00 = VEC_ADD(vC00, vA0);
            vC10 = VEC_ADD(vC10, vA1);
            vC20 = VEC_ADD(vC20, vA2);
            vC30 = VEC_ADD(vC30, vA3);
            vec_st(vC00, 0, pC);
            vec_st(vC10, 0, pC+4);
            vec_st(vC20, 0, pC+8);
            vec_st(vC30, 0, pC+12);
            vB0 = vec_ld(0, pC+16);
            vB1 = vec_ld(0, pC+20);
            vB2 = vec_ld(0, pC+24);
            vB3 = vec_ld(0, pC+28);
            vC01 = VEC_ADD(vC01, vB0);
            vC11 = VEC_ADD(vC11, vB1);
            vC21 = VEC_ADD(vC21, vB2);
            vC31 = VEC_ADD(vC31, vB3);
            vec_st(vC01, 0, pC+16);
            vec_st(vC11, 0, pC+20);
            vec_st(vC21, 0, pC+24);
            vec_st(vC31, 0, pC+28);
            vA0 = vec_ld(0, pC+32);
            vA1 = vec_ld(0, pC+36);
            vA2 = vec_ld(0, pC+40);
            vA3 = vec_ld(0, pC+44);
            vC02 = VEC_ADD(vC02, vA0);
            vC12 = VEC_ADD(vC12, vA1);
            vC22 = VEC_ADD(vC22, vA2);
            vC32 = VEC_ADD(vC32, vA3);
            vec_st(vC02, 0, pC+32);
            vec_st(vC12, 0, pC+36);
            vec_st(vC22, 0, pC+40);
            vec_st(vC32, 0, pC+44);
            vB0 = vec_ld(0, pC+48);
            vB1 = vec_ld(0, pC+52);
            vB2 = vec_ld(0, pC+56);
            vB3 = vec_ld(0, pC+60);
            vC03 = VEC_ADD(vC03, vB0);
            vC13 = VEC_ADD(vC13, vB1);
            vC23 = VEC_ADD(vC23, vB2);
            vC33 = VEC_ADD(vC33, vB3);
            vec_st(vC03, 0, pC+48);
            vec_st(vC13, 0, pC+52);
            vec_st(vC23, 0, pC+56);
            vec_st(vC33, 0, pC+60);
         #endif
         pA = pA0;
         pC += 16*4;  /* MU * NU */
         pB -= 4;
      }
      pA0 += 16*K;     /* MU*K */
      pA = pA0;
      pB = pB0;
   }
}
@ROUT ATL_damm12x3x1_avx.S
@extract -b @(topd)/gen.inc what=crsetup
@extract -b @(topd)/cw.inc lang=c -define cwdate 2012
#include "atlas_asm.h"
/*
                    rdi      rsi    rdx        rcx         r8        r9
void ATL_USERMM(SZT nmu, SZT nnu, SZT K, CTYPE *pA, CTYPE *pB, TYPE *pC,
                  8(%rsp)    16(%rsp)     24(%rsp)
                CTYPE *pAn, CTYPE *pBn, CTYPE *pCn);
 */

#define FSIZE 6*8
#ifndef prefA
   #define prefA prefetcht0
#endif
#ifndef prefB
   #define prefB prefetcht0
#endif
#ifndef prefC
   #ifdef ATL_3DNow
      #define prefC prefetchw
   #else
      #define prefC prefetcht0
   #endif
#endif
#ifdef BETAN1
   #define BETCOP vsubpd
#else
   #define BETCOP vaddpd
#endif
#define vmovapd vmovaps
/*
 * floating point registers
 */
#define m0   %ymm0
#define rA0  %ymm1
#define rA1  %ymm2
#define rA2  %ymm3
#define rB0  %ymm4
#define rB1  %ymm5
#define rB2  %ymm6
#define rC00 %ymm7
#define rC10 %ymm8
#define rC20 %ymm9
#define rC01 %ymm10
#define rC11 %ymm11
#define rC21 %ymm12
#define rC02 %ymm13
#define rC12 %ymm14
#define rC22 %ymm15
/*
 * Prioritize original registers for inner-loop operations, but inc regs
 * can be anything w/o changing opcode size, so use new regs for those
 */
#define KK      %rdx  /* API reg */
#define pA      %rcx  /* API reg */
#define pB      %rax  /* comes in as r9 */
#define incAk   %r9   /* set after mov r9 to pC () */
#define incBk   %r8   /* set after mov r8 to pB (rax) */
/*
 * Then N-loop variables much less important, so use any orig regs left
 */
#define pC      %rsi  /* set after mov rsi to nnu () */
#define nnu     %r10  /* comes in as rsi */
#define pfA     %rbx
#define pfB     %rbp
#define incPF   %r12
#define KK0     %rdi
/*
 * We could give a rat's ass about what registers used in outer (M-) loop
 */
#define nmu     %r11  /* comes in as rdi */
#define incAm   %r13
#define nnu0    %r14
#define pB0     %r15
/*
                    rdi      rsi    rdx        rcx         r8        r9
void ATL_USERMM(SZT nmu, SZT nnu, SZT K, CTYPE *pA, CTYPE *pB, TYPE *pC,
                  8(%rsp)    16(%rsp)     24(%rsp)
                CTYPE *pAn, CTYPE *pBn, CTYPE *pCn);
 */
.text
.global ATL_asmdecor(ATL_USERMM)
ALIGN16
ATL_asmdecor(ATL_USERMM):
/*
 * Save callee-saved iregs
 */
   sub  $FSIZE, %rsp
   movq %rbp, (%rsp)
   movq %rbx, 8(%rsp)
   movq %r12, 16(%rsp)
   movq %r13, 24(%rsp)
   movq %r14, 32(%rsp)
   movq %r15, 40(%rsp)
/*
 * Load paramaters
 */
   mov %rdi, nmu
   mov %rsi, nnu
   mov %r8, pB
   mov %r9, pC
   mov nnu, nnu0
   movq FSIZE+8(%rsp), pfB      /* pfB = pAn */
   movq FSIZE+16(%rsp), pfA     /* pf = pBn */
   cmp pfA, pB
   CMOVE pfB, pfA
   CMOVEq FSIZE+24(%rsp), pfB
   sub $-128, pfA
   sub $-128, pfB
   sub $-128, pC                 /* extend range of 1-byte offsets */
/*
 * Set constants
 */
   mov $12*3*8, incPF           /* incPF = mu*nu*sizeof */
   mov $24, incBk               /* 24 = NU*sizeof = 3*8 = 24 */
   mov $96, incAk               /* 96 = MU*sizeof = 12*8 = 96 */
   mov pB, pB0
/*
 * incAm = MU*sizeof*K = 12*8*K = 3*32*K
 */
   lea (KK, KK, 2), KK          /* KK = 3*K */
   shl $5, KK                   /* KK = 3*32*K = 12*8*K = MU*sizeof*K */
   mov KK, incAm                /* incAm = MU*sizeof*K */
   add KK, pA                   /* pA[-kk] will access A */
   neg KK                       /* KK = -NU*sizeof*K */
   mov KK, KK0
   vbroadcastsd (pB), rB0
   MLOOP:
      NLOOP:
/*
 *          First peeled iteration gets us to preloading next iter's data for
 *          loop while only doing 1 load/flop.  It does no adds to avoid
 *          having to zero the C registers.
 */

            vmovapd (pA,KK), rA0
            vmulpd rB0, rA0, rC00
            vmovapd 32(pA,KK), rA1
            vmulpd rB0, rA1, rC10
            vmovapd 64(pA,KK), rA2
            vmulpd rB0, rA2, rC20

            vbroadcastsd 8(pB), rB1
            vmulpd rB1, rA0, rC01
            vbroadcastsd 16(pB), rB2
            vmulpd rB1, rA1, rC11
               vbroadcastsd 24(pB), rB0
            vmulpd rB1, rA2, rC21
               vbroadcastsd 32(pB), rB1

            vmulpd rB2, rA0, rC02
               vmovapd 96(pA,KK), rA0
            vmulpd rB2, rA1, rC12
               vmovapd 128(pA,KK), rA1
            vmulpd rB2, rA2, rC22
               vmovapd 160(pA,KK), rA2
            add $24, pB
            add $96, KK
            jz KDONE_NOFINALPEEL
/*
 *          Stop loop on iteration early to set up for C, so 2nd peel is
 *          from end (bottom) of loop
 */
            add $24, pB
            add $96, KK
            jz KLOOPDRAIN
/*
 *          Now peel a 3rd iteration (already peeled one from top and bottom)
 *          in order to do some prefetch.  This peel is the exact code from
 *          loop, with some prefetch commands added.
 */
            vmulpd rB0, rA0, m0
            vaddpd rC00, m0, rC00
            vbroadcastsd -8(pB), rB2
            vmulpd rB0, rA1, m0
            vaddpd rC10, m0, rC10
               prefA -128(pfA)
            vmulpd rB0, rA2, m0
            vaddpd rC20, m0, rC20
               vbroadcastsd (pB), rB0

            vmulpd rB1, rA0, m0
            vaddpd rC01, m0, rC01
               prefA (pfA)
            vmulpd rB1, rA1, m0
            vaddpd rC11, m0, rC11
            vmulpd rB1, rA2, m0
            vaddpd rC21, m0, rC21
               vbroadcastsd 8(pB), rB1

            vmulpd rB2, rA0, m0
            vaddpd rC02, m0, rC02
               vmovapd (pA,KK), rA0
            vmulpd rB2, rA1, m0
            vaddpd rC12, m0, rC12
               vmovapd 32(pA,KK), rA1
            vmulpd rB2, rA2, m0
            vaddpd rC22, m0, rC22
               vmovapd 64(pA,KK), rA2
            add incPF, pfA
            add incPF, pfB
            add $24, pB
            add $96, KK
            jz KLOOPDRAIN
/*
 *        Finally, start actual loop
 */
          KLOOP:
            vmulpd rB0, rA0, m0
            vaddpd rC00, m0, rC00
            vbroadcastsd -8(pB), rB2
            vmulpd rB0, rA1, m0
            vaddpd rC10, m0, rC10
               prefetcht0 64(pB)
            vmulpd rB0, rA2, m0
            vaddpd rC20, m0, rC20
               vbroadcastsd (pB), rB0

            vmulpd rB1, rA0, m0
            vaddpd rC01, m0, rC01
               prefetcht0 128(pA)
            vmulpd rB1, rA1, m0
            vaddpd rC11, m0, rC11
            vmulpd rB1, rA2, m0
            vaddpd rC21, m0, rC21
               vbroadcastsd 8(pB), rB1

            vmulpd rB2, rA0, m0
            vaddpd rC02, m0, rC02
               vmovapd (pA,KK), rA0
            vmulpd rB2, rA1, m0
            vaddpd rC12, m0, rC12
               vmovapd 32(pA,KK), rA1
            vmulpd rB2, rA2, m0
            vaddpd rC22, m0, rC22
               vmovapd 64(pA,KK), rA2
            add $24, pB
            add $96, KK
         jnz KLOOP
/* 
 *       Last iteration peeled off bottom to allow store of C; this should
 *       strongly improve BETA=0, but may hurt BETA=1.  This kernel written
 *       primarily for K-cleanup, which is always BETA=0, so do it.
 */
.local KLOOPDRAIN
KLOOPDRAIN:
#ifdef BETAN1
   #define VCOP vsubpd
#else
   #define VCOP vaddpd
#endif
            vbroadcastsd -8(pB), rB2
            vmulpd rB0, rA0, m0
            vaddpd rC00, m0, rC00
            #ifndef BETA0
               VCOP  -128(pC), rC00, rC00
            #endif
            vmovapd rC00, -128(pC)
            vmulpd rB0, rA1, m0
            vaddpd rC10, m0, rC10
            #ifndef BETA0
               VCOP  -96(pC), rC10, rC10
            #endif
            vmovapd rC10, -96(pC)
            vmulpd rB0, rA2, m0
            vaddpd rC20, m0, rC20
            #ifndef BETA0
               VCOP  -64(pC), rC20, rC20
            #endif
            vmovapd rC20, -64(pC)

            vmulpd rB1, rA0, m0
            vaddpd rC01, m0, rC01
            #ifndef BETA0
               VCOP  -32(pC), rC01, rC01
            #endif
            vmovapd rC01, -32(pC)
            vmulpd rB1, rA1, m0
            vaddpd rC11, m0, rC11
            #ifndef BETA0
               VCOP  (pC), rC11, rC11
            #endif
            vmovapd rC11, (pC)
            vmulpd rB1, rA2, m0
            vaddpd rC21, m0, rC21
            #ifndef BETA0
               VCOP  32(pC), rC21, rC21
            #endif
            vmovapd rC21, 32(pC)

            vmulpd rB2, rA0, m0
            vaddpd rC02, m0, rC02
            #ifndef BETA0
               VCOP  64(pC), rC02, rC02
            #endif
            vmovapd rC02, 64(pC)
            vmulpd rB2, rA1, m0
            vaddpd rC12, m0, rC12
            #ifndef BETA0
               VCOP  96(pC), rC12, rC12
            #endif
            vmovapd rC12, 96(pC)
            vmulpd rB2, rA2, m0
            vaddpd rC22, m0, rC22
            #ifndef BETA0
               VCOP  128(pC), rC22, rC22
            #endif
            vmovapd rC22, 128(pC)
.local KLOOPDONE
KLOOPDONE:
         mov KK0, KK
         vbroadcastsd (pB), rB0
         add $12*3*8, pC                /* pC += MU*NU*sizeof */
      sub $1, nnu
      jnz NLOOP
      vbroadcastsd (pB0), rB0
      mov nnu0, nnu
      mov pB0, pB
      add incAm, pA                     /* pA += MU*sizeof*K */
   sub $1, nmu
   jnz MLOOP
/* DONE: */
   movq (%rsp), %rbp
   movq 8(%rsp), %rbx
   movq 16(%rsp), %r12
   movq 24(%rsp), %r13
   movq 32(%rsp), %r14
   movq 40(%rsp), %r15
   add  $FSIZE, %rsp
   ret
/*
 * got answers in rCxx, just need to apply them to memory
 */
KDONE_NOFINALPEEL:
/*
 *       Write answer back out to C
 */
         #ifdef BETA0
            vmovapd rC00, -128(pC)
            vmovapd rC10, -96(pC)
            vmovapd rC20, -64(pC)
            vmovapd rC01, -32(pC)
            vmovapd rC11, (pC)
            vmovapd rC21, 32(pC)
            vmovapd rC02, 64(pC)
            vmovapd rC12, 96(pC)
            vmovapd rC22, 128(pC)
/*
 *          Add running sum in rCx with original C, then store back out
 */
         #else
            BETCOP -128(pC), rC00, rC00
            vmovapd rC00, -128(pC)
            BETCOP -96(pC), rC10, rC10
            vmovapd rC10, -96(pC)
            BETCOP -64(pC), rC20, rC20
            vmovapd rC20, -64(pC)
            BETCOP -32(pC), rC01, rC01
            vmovapd rC01, -32(pC)
            BETCOP (pC), rC11, rC11
            vmovapd rC11, (pC)
            BETCOP 32(pC), rC21, rC21
            vmovapd rC21, 32(pC)
            BETCOP 64(pC), rC02, rC02
            vmovapd rC02, 64(pC)
            BETCOP 96(pC), rC12, rC12
            vmovapd rC12, 96(pC)
            BETCOP 128(pC), rC22, rC22
            vmovapd rC22, 128(pC)
         #endif
         jmp KLOOPDONE
@ROUT ATL_damm12x3x2_avx.S
@extract -b @(topd)/gen.inc what=crsetup
@extract -b @(topd)/cw.inc lang=c -define cwdate 2012
#include "atlas_asm.h"
#ifndef KB 
   #define KB 0
#endif
#if (KB/2)*2 != KB
   #error "KB must be a multiple of 2!"
#endif
   
/*
                    rdi      rsi    rdx        rcx         r8        r9
void ATL_USERMM(SZT nmu, SZT nnu, SZT K, CTYPE *pA, CTYPE *pB, TYPE *pC,
                  8(%rsp)    16(%rsp)     24(%rsp)
                CTYPE *pAn, CTYPE *pBn, CTYPE *pCn);
 */

#define FSIZE 6*8
#ifdef BETAN1
   #define VCOP vsubpd
#else
   #define VCOP vaddpd
#endif
#define vmovapd vmovaps
/*
 * floating point registers
 */
#define m0   %ymm0
#define rA0  %ymm1
#define rA1  %ymm2
#define rA2  %ymm3
#define rB0  %ymm4
#define rB1  %ymm5
#define rB2  %ymm6
#define rC00 %ymm7
#define rC10 %ymm8
#define rC20 %ymm9
#define rC01 %ymm10
#define rC11 %ymm11
#define rC21 %ymm12
#define rC02 %ymm13
#define rC12 %ymm14
#define rC22 %ymm15
/*
 * Prioritize original registers for inner-loop operations, but inc regs
 * can be anything w/o changing opcode size, so use new regs for those
 */
#define KK      %rdx  /* API reg */
#define pA      %rcx  /* API reg */
#define pB      %rax  /* comes in as r9 */
/*
 * Then N-loop variables much less important, so use any orig regs left
 */
#define pC      %rbx  /* set after mov rsi to nnu () */
#define nnu     %rsi  /* comes in as rsi */
#define r128    %rbp
#define KK0     %rdi
/*
 * We could give a rat's ass about what registers used in outer (M-) loop
 */
#define nmu     %r8   /* comes in as rdi */
#define incAm   %r9 
#define nnu0    %r10
#define pB0     %r11
/*
 * Prefetch definitions
 */
#define PFADIST 384
#define prefA(pA_) prefetcht0 pA_
#define prefB(pB_) prefetcht0 pB_
#define prefC(pC_) prefetcht0 pC_
/*
                    rdi      rsi    rdx        rcx         r8        r9
void ATL_USERMM(SZT nmu, SZT nnu, SZT K, CTYPE *pA, CTYPE *pB, TYPE *pC,
                  8(%rsp)    16(%rsp)     24(%rsp)
                CTYPE *pAn, CTYPE *pBn, CTYPE *pCn);
 */
.text
.global ATL_asmdecor(ATL_USERMM)
ALIGN16
ATL_asmdecor(ATL_USERMM):
/*
 * Save callee-saved iregs
 */
   sub  $FSIZE, %rsp
   movq %rbp, (%rsp)
   nop
   nop
   movq %rbx, 8(%rsp)
#if 0
   movq %r12, 16(%rsp)
   movq %r13, 24(%rsp)
   movq %r14, 32(%rsp)
   movq %r15, 40(%rsp)
#endif
/*
 * Load paramaters
 */
   mov %r8, pB
   prefA(64(pA))
   mov %rdi, nmu
   mov $128, r128
   prefA(64(pA,r128))
   mov %r9, pC
   mov nnu, nnu0
   sub $-128, pC                 /* extend range of 1-byte offsets */
/*
 * Set constants
 */
   mov pB, pB0
/*
 * incAm = MU*sizeof*K = 12*8*K = 3*32*K
 */
   lea (KK, KK, 2), KK          /* KK = 3*K */
   shl $5, KK                   /* KK = 3*32*K = 12*8*K = MU*sizeof*K */
   mov KK, incAm                /* incAm = MU*sizeof*K */
   prefA((pA,r128,2))
   sub $3*2*32, KK              /* stop 1 iteration early for final peel */
   add KK, pA                   /* pA[-kk] will access A */
   neg KK                       /* KK = -NU*sizeof*K */
   mov KK, KK0
   vbroadcastsd (pB), rB0
#if 0
   MLOOP:
      NLOOP:
#endif
   MNLOOP:
/*
 *          First peeled K=0 iteration gets to preloading next iter's data for
 *          loop while only doing 1 load/flop.  It does no adds to avoid
 *          having to zero the C registers.
 */

            vmovapd (pA,KK), rA0
            vmulpd rB0, rA0, rC00
            vmovapd 32(pA,KK), rA1
            vmulpd rB0, rA1, rC10
            vmovapd 64(pA,KK), rA2
            vmulpd rB0, rA2, rC20

            vbroadcastsd 8(pB), rB1
            vmulpd rB1, rA0, rC01
            vbroadcastsd 16(pB), rB2
            vmulpd rB1, rA1, rC11
               vbroadcastsd 24(pB), rB0
            vmulpd rB1, rA2, rC21
               vbroadcastsd 32(pB), rB1

            vmulpd rB2, rA0, rC02
               vmovapd 96(pA,KK), rA0
            vmulpd rB2, rA1, rC12
               vmovapd 128(pA,KK), rA1
            vmulpd rB2, rA2, rC22
               vmovapd 160(pA,KK), rA2
               add $96, KK
/*
 *          For K=1 iteration of peel, prefetch C
 */
            vmulpd rB0, rA0, m0
            vaddpd rC00, m0, rC00
            vbroadcastsd 40(pB), rB2
            vmulpd rB0, rA1, m0
            vaddpd rC10, m0, rC10
               prefC((pC))
            vmulpd rB0, rA2, m0
            vaddpd rC20, m0, rC20
               vbroadcastsd 48(pB), rB0

            vmulpd rB1, rA0, m0
            vaddpd rC01, m0, rC01
               prefC(64(pC))
            vmulpd rB1, rA1, m0
            vaddpd rC11, m0, rC11
            vmulpd rB1, rA2, m0
            vaddpd rC21, m0, rC21
               vbroadcastsd 56(pB), rB1
            add $48, pB
            add $96, KK

            vmulpd rB2, rA0, m0
            vaddpd rC02, m0, rC02
               vmovapd (pA,KK), rA0
            vmulpd rB2, rA1, m0
            vaddpd rC12, m0, rC12
               vmovapd 32(pA,KK), rA1
            vmulpd rB2, rA2, m0
            vaddpd rC22, m0, rC22
               vmovapd 64(pA,KK), rA2
/*
 *        Finally, start actual loop
 */
          KLOOP:
               prefB(128(pB))
            vmulpd rB0, rA0, m0
            vaddpd rC00, m0, rC00
            vbroadcastsd 16(pB), rB2
            vmulpd rB0, rA1, m0
            vaddpd rC10, m0, rC10
               prefA(PFADIST(pA,KK))
            vmulpd rB0, rA2, m0
            vaddpd rC20, m0, rC20
               vbroadcastsd 24(pB), rB0

            vmulpd rB1, rA0, m0
            vaddpd rC01, m0, rC01
               prefA(PFADIST+64(pA,KK))
            vmulpd rB1, rA1, m0
            vaddpd rC11, m0, rC11
               add $96, KK
            vmulpd rB1, rA2, m0
            vaddpd rC21, m0, rC21
               vbroadcastsd 32(pB), rB1

            vmulpd rB2, rA0, m0
            vaddpd rC02, m0, rC02
               vmovapd (pA,KK), rA0
            vmulpd rB2, rA1, m0
            vaddpd rC12, m0, rC12
               vmovapd 32(pA,KK), rA1
            vmulpd rB2, rA2, m0
            vaddpd rC22, m0, rC22
               vmovapd 64(pA,KK), rA2
/*
 *          K = 1 iteration
 */
            vmulpd rB0, rA0, m0
            vaddpd rC00, m0, rC00
            vbroadcastsd 40(pB), rB2
            vmulpd rB0, rA1, m0
            vaddpd rC10, m0, rC10
               prefA(PFADIST+128(pA,KK))
            vmulpd rB0, rA2, m0
            vaddpd rC20, m0, rC20
               vbroadcastsd 48(pB), rB0

            vmulpd rB1, rA0, m0
            vaddpd rC01, m0, rC01
               prefB(3*KB*8(pB))
            vmulpd rB1, rA1, m0
            vaddpd rC11, m0, rC11
            vmulpd rB1, rA2, m0
            vaddpd rC21, m0, rC21
               vbroadcastsd 56(pB), rB1
            add $48, pB

            vmulpd rB2, rA0, m0
            vaddpd rC02, m0, rC02
               vmovapd 96(pA,KK), rA0
            vmulpd rB2, rA1, m0
            vaddpd rC12, m0, rC12
               vmovapd 96+32(pA,KK), rA1
            vmulpd rB2, rA2, m0
            vaddpd rC22, m0, rC22
               vmovapd 96+64(pA,KK), rA2
            add $96, KK
         jnz KLOOP
/*
 *       Last iteration peeled off bottom to allow store of C; this should
 *       strongly improve BETA=0, but may hurt BETA=1.  This kernel written
 *       primarily for K-cleanup, which is always BETA=0, so do it.
 */
         vmulpd rB0, rA0, m0
         vaddpd rC00, m0, rC00
         vbroadcastsd 16(pB), rB2
         vmulpd rB0, rA1, m0
         vaddpd rC10, m0, rC10
            prefA(PFADIST(pA))
         vmulpd rB0, rA2, m0
         vaddpd rC20, m0, rC20
            vbroadcastsd 24(pB), rB0

         vmulpd rB1, rA0, m0
         vaddpd rC01, m0, rC01
            prefA(PFADIST+64(pA))
         vmulpd rB1, rA1, m0
         vaddpd rC11, m0, rC11
         vmulpd rB1, rA2, m0
         vaddpd rC21, m0, rC21
            vbroadcastsd 32(pB), rB1

         vmulpd rB2, rA0, m0
         vaddpd rC02, m0, rC02
            vmovapd 96(pA), rA0
         vmulpd rB2, rA1, m0
         vaddpd rC12, m0, rC12
            vmovapd 96+32(pA), rA1
         vmulpd rB2, rA2, m0
         vaddpd rC22, m0, rC22
            vmovapd 96+64(pA), rA2
/*
 *       K = 1 iteration
 */
         vmulpd rB0, rA0, m0
         vaddpd rC00, m0, rC00
         #ifndef BETA0
            VCOP -128(pC), rC00, rC00
         #endif
         vmovapd rC00, -128(pC)
         vbroadcastsd 40(pB), rB2
         vmulpd rB0, rA1, m0
         vaddpd rC10, m0, rC10
         #ifndef BETA0
            VCOP -96(pC), rC10, rC10
         #endif
         vmovapd rC10, -96(pC)
            prefA(PFADIST+96+128(pA))
         vmulpd rB0, rA2, m0
         vaddpd rC20, m0, rC20
         #ifndef BETA0
            VCOP -64(pC), rC20, rC20
         #endif
         vmovapd rC20, -64(pC)
            vbroadcastsd 48(pB), rB0

         vmulpd rB1, rA0, m0
         vaddpd rC01, m0, rC01
         #ifndef BETA0
            VCOP -32(pC), rC01, rC01
         #endif
         vmovapd rC01, -32(pC)
            prefB(3*KB*8(pB))
         vmulpd rB1, rA1, m0
         vaddpd rC11, m0, rC11
         #ifndef BETA0
            VCOP (pC), rC11, rC11
         #endif
         vmovapd rC11, (pC)
         vmulpd rB1, rA2, m0
         vaddpd rC21, m0, rC21
         #ifndef BETA0
            VCOP 32(pC), rC21, rC21
         #endif
         vmovapd rC21, 32(pC)
         add $48, pB

         vmulpd rB2, rA0, m0
         vaddpd rC02, m0, rC02
         #ifndef BETA0
            VCOP 64(pC), rC02, rC02
         #endif
         vmovapd rC02, 64(pC)
         vmulpd rB2, rA1, m0
         vaddpd rC12, m0, rC12
         #ifndef BETA0
            VCOP 96(pC), rC12, rC12
         #endif
         vmovapd rC12, 96(pC)
         vmulpd rB2, rA2, m0
         vaddpd rC22, m0, rC22
         #ifndef BETA0
            VCOP (pC,r128), rC22, rC22
         #endif
         vmovapd rC22, (pC,r128)

         mov KK0, KK
         vbroadcastsd (pB), rB0
         add $12*3*8, pC                /* pC += MU*NU*sizeof */
      sub $1, nnu
      jnz MNLOOP
      vbroadcastsd (pB0), rB0
      mov nnu0, nnu
      mov pB0, pB
      add incAm, pA                     /* pA += MU*sizeof*K */
   sub $1, nmu
   jnz MNLOOP
#if 0
.local DONE
DONE: 
#endif
   movq (%rsp), %rbp
   movq 8(%rsp), %rbx
#if 0
   movq 16(%rsp), %r12 
   movq 24(%rsp), %r13
   movq 32(%rsp), %r14
   movq 40(%rsp), %r15
#endif
   add  $FSIZE, %rsp
   ret
@ROUT ATL_damm16x2_kb4_avx.S
#include "atlas_asm.h"
#define m0      %ymm0
#define rA0     %ymm1
#define rA1     %ymm2
#define rA2     %ymm3
#define rA3     %ymm4
#define rB0     %ymm5
#define rB1     %ymm6
#define rb1     %ymm7
#define rC00    %ymm8
#define rC10    %ymm9
#define rC20    %ymm10
#define rC30    %ymm11
#define rC01    %ymm12
#define rC11    %ymm13
#define rC21    %ymm14
#define rC31    %ymm15
#ifdef BETA1
   #define ADDC(r, p) vaddpd p, r, r
#elif defined(BETA0)
   #define ADDC(r, p) 
#else
   #define ADDC(r, p) vsubpd p, r, r
#endif

#define NMU %rdi
#define NNU %rsi
#define pA  %rcx
#define pB  %rdx
#define pC  %r9
#define pB0 %r8
#define NNU0 %rax
/*
                    rdi      rsi    rdx        rcx         r8        r9
void ATL_USERMM(SZT nmu, SZT nnu, SZT K, CTYPE *pA, CTYPE *pB, TYPE *pC,
                  8(%rsp)    16(%rsp)     24(%rsp)
                CTYPE *pAn, CTYPE *pBn, CTYPE *pCn);
 */
.text
.global ATL_asmdecor(ATL_USERMM)
ALIGN16
ATL_asmdecor(ATL_USERMM):
   mov pB0, pB
   mov NNU, NNU0
   MLOOP:
      vbroadcastsd (pB), rB0
      vmovapd (pA), rA0
      NLOOP:
/*
 *       K == 1
*/
         vmulpd rA0, rB0, rC00
         ADDC(rC00, (pC))
         vmovapd 32(pA), rA1
         vmulpd rA1, rB0, rC10
         ADDC(rC10, 32(pC))
         vmovapd 64(pA), rA2
         vmulpd rA2, rB0, rC20
         ADDC(rC20, 64(pC))
         vmovapd 96(pA), rA3
         vmulpd rA3, rB0, rC30
         ADDC(rC30, 96(pC))
         vbroadcastsd 8(pB), rB1
         vmulpd rA0, rB1, rC01
         ADDC(rC01, 128(pC))
            vbroadcastsd 16(pB), rB0
         vmulpd rA1, rB1, rC11
         ADDC(rC11, 160(pC))
            vmovapd 128(pA), rA0
         vmulpd rA2, rB1, rC21
         ADDC(rC21, 192(pC))
            vmovapd 160(pA), rA1
         vmulpd rA3, rB1, rC31
         ADDC(rC31, 224(pC))
            vmovapd 192(pA), rA2
/*
 *       K == 2
 */
         vmulpd rA0, rB0, m0
         vaddpd m0, rC00, rC00
            vmovapd 224(pA), rA3
         vmulpd rA1, rB0, m0
         vaddpd m0, rC10, rC10
            vbroadcastsd 24(pB), rB1
         vmulpd rA2, rB0, m0
         vaddpd m0, rC20, rC20
         vmulpd rA3, rB0, m0
         vaddpd m0, rC30, rC30
            vbroadcastsd 32(pB), rB0
         vmulpd rA0, rB1, m0
         vaddpd m0, rC01, rC01
            vmovapd 256(pA), rA0
         vmulpd rA1, rB1, m0
         vaddpd m0, rC11, rC11
            vmovapd 288(pA), rA1
         vmulpd rA2, rB1, m0
         vaddpd m0, rC21, rC21
            vmovapd 320(pA), rA2
         vmulpd rA3, rB1, m0
         vaddpd m0, rC31, rC31
            vmovapd 352(pA), rA3
/*
 *       K == 3
 */
         vmulpd rA0, rB0, m0
         vaddpd m0, rC00, rC00
            vbroadcastsd 40(pB), rB1
         vmulpd rA1, rB0, m0
         vaddpd m0, rC10, rC10
            vbroadcastsd 56(pB), rb1
         vmulpd rA2, rB0, m0
         vaddpd m0, rC20, rC20
         vmulpd rA3, rB0, m0
         vaddpd m0, rC30, rC30
            vbroadcastsd 48(pB), rB0
         vmulpd rA0, rB1, m0
         vaddpd m0, rC01, rC01
            vmovapd 384(pA), rA0
         vmulpd rA1, rB1, m0
         vaddpd m0, rC11, rC11
            vmovapd 416(pA), rA1
         vmulpd rA2, rB1, m0
         vaddpd m0, rC21, rC21
            vmovapd 448(pA), rA2
         vmulpd rA3, rB1, m0
         vaddpd m0, rC31, rC31
            vmovapd 480(pA), rA3
/*
 *       K == 4
 */
         vmulpd rA0, rB0, m0
         vaddpd m0, rC00, rC00
         vmovapd rC00, (pC)
         vmulpd rA1, rB0, m0
         vaddpd m0, rC10, rC10
         vmovapd rC10, 32(pC)
         vmulpd rA2, rB0, m0
         vaddpd m0, rC20, rC20
         vmovapd rC20, 64(pC)
         vmulpd rA3, rB0, m0
         vaddpd m0, rC30, rC30
         vmovapd rC30, 96(pC)
            vbroadcastsd 64(pB), rB0
         add $64, pB
         vmulpd rA0, rb1, m0
         vaddpd m0, rC01, rC01
         vmovapd rC01, 128(pC)
            vmovapd (pA), rA0
         vmulpd rA1, rb1, m0
         vaddpd m0, rC11, rC11
         vmovapd rC11, 160(pC)
         vmulpd rA2, rb1, m0
         vaddpd m0, rC21, rC21
         vmovapd rC21, 192(pC)
         vmulpd rA3, rb1, m0
         vaddpd m0, rC31, rC31
         vmovapd rC31, 224(pC)
         add $256, pC
      sub $1, NNU
      jnz NLOOP

      add $512, pA
      mov pB0, pB
      mov NNU0, NNU
   sub $1, NMU
   jnz MLOOP
/* DONE: */
   ret
@ROUT ATL_damm6x3x2_sse3.S ATL_sammm8x4x2_sse.S
   @extract -b @(topd)/gen.inc what=crsetup
   @extract -b @(topd)/cw.inc lang=c -define cwdate 2013
@ROUT ATL_sammm8x4x2_sse.S
   @extract -b @(topd)/kernel/ClintWhaley/ATL_sammm8x4x2_sse.S
@ROUT ATL_damm6x3x2_sse3.S
   @extract -b @(topd)/kernel/ClintWhaley/ATL_damm6x3x2_sse3.S
@ROUT ATL_damm6x4x1_fma3.S
   @extract -b @(topd)/gen.inc what=crsetup
   @extract -b @(topd)/cw.inc lang=c -define cwdate 2013
   @extract -b @(topd)/kernel/ClintWhaley/ATL_damm6x4x1_fma3.S
@ROUT ATL_amm6x1x1_x87.S ATL_damm24x1x8_sse2.S ATL_damm24x1x1_sse2.S @\
      ATL_damm12x4x1_fma3.S ATL_amm4x2x4_kb4.c
   @extract -b @(topd)/gen.inc what=crsetup
   @extract -b @(topd)/cw.inc lang=c -define cwdate 2012
@ROUT ATL_amm4x2x4_kb4.c
   @extract -b @(topd)/kernel/ClintWhaley/ATL_amm4x2x4_kb4.c
@ROUT ATL_damm12x4x1_fma3.S
   @extract -b @(topd)/kernel/ClintWhaley/ATL_damm12x4x1_fma3.S
@ROUT ATL_amm6x1x1_x87.S
   @extract -b @(topd)/kernel/ClintWhaley/ATL_amm6x1x1_x87.S
@ROUT ATL_damm24x1x8_sse2.S
   @extract -b @(topd)/kernel/ClintWhaley/ATL_damm24x1x8_sse2.S
@ROUT ATL_damm24x1x1_sse2.S
   @extract -b @(topd)/kernel/ClintWhaley/ATL_damm24x1x1_sse2.S
@ROUT ATL_damm4x4x2rp_arm.S ATL_samm4x6x2_arm.S ATL_damm5x5x2_arm.S @\
      ATL_damm5x5x2_armpf.S ATL_damm5x5x1_armpf.S ATL_samm4x6x1_arm.S @\
      ATL_damm3x4x1_armpf.S
@extract -b @(topd)/gen.inc what=crsetup
@extract -b @(topd)/cw.inc lang=c -define cwdate 2012
#ifndef ATL_GAS_ARM
   #error "This routine requires GAS/ARM assembly"
#endif
@ROUT ATL_damm4x4x2rp_arm.S
@extract -b @(topd)/kernel/ClintWhaley/ATL_damm4x4x2rp_arm.S
@ROUT ATL_samm4x6x2_arm.S
@extract -b @(topd)/kernel/ClintWhaley/ATL_samm4x6x2_arm.S
@ROUT ATL_samm4x6x1_arm.S
@extract -b @(topd)/kernel/ClintWhaley/ATL_samm4x6x1_arm.S
@ROUT ATL_damm5x5x2_arm.S
@extract -b @(topd)/kernel/ClintWhaley/ATL_damm5x5x2_arm.S
@ROUT ATL_damm5x5x2_armpf.S
@extract -b @(topd)/kernel/ClintWhaley/ATL_damm5x5x2_armpf.S
@ROUT ATL_damm5x5x1_armpf.S
@extract -b @(topd)/kernel/ClintWhaley/ATL_damm5x5x1_armpf.S
@ROUT ATL_damm3x4x1_armpf.S
@extract -b @(topd)/kernel/ClintWhaley/ATL_damm3x4x1_armpf.S
@ROUT ATL_damm8x2x256_sse3.S
@extract -b @(topd)/gen.inc what=crsetup
@extract -b @(topd)/cw.inc lang=c -define cwdate 2013
#include "atlas_asm.h"
#ifndef prefA
   #define prefA prefetcht0
#endif
#ifndef prefB
   #define prefB prefetcht2
#endif
#ifndef prefC
   #ifdef ATL_3DNow
      #define prefC prefetchw
   #else
      #define prefC prefetcht0
   #endif
#endif
#ifdef BETAN1
   #define BETCOP subpd
#elif defined(BETA1)
   #define BETCOP addpd
#endif
#define MOVAPD movaps
#define UNPCKHPD movhlps

#define m0      %xmm0
#define rA0     %xmm1
#define rA1     %xmm2
#define rA2     %xmm3
#define rA3     %xmm4
#define rB0     %xmm5
#define rB1     %xmm6
#define rb1     %xmm7
#define rC00    %xmm8
#define rC10    %xmm9
#define rC20    %xmm10
#define rC30    %xmm11
#define rC01    %xmm12
#define rC11    %xmm13
#define rC21    %xmm14
#define rC31    %xmm15

#define pA      %rcx
#define pB      %rdx
#define pC      %rbp
#define pfA     %rax
#define pfB     %rbx
#define pfC     %rdi
#define nnu     %rsi

#define incPF   %r8
#define incA    %r9
#define incB    %r10
#define pA0     %r11
#define nnu0    %r12
#define r256    %r13
#define nmu     %r14
#define pB0     %r15
/*
                    rdi      rsi    rdx        rcx         r8        r9
void ATL_USERMM(SZT nmu, SZT nnu, SZT K, CTYPE *pA, CTYPE *pB, TYPE *pC,
                  8(%rsp)    16(%rsp)     24(%rsp)
                CTYPE *pAn, CTYPE *pBn, CTYPE *pCn);
 */
.text
.global ATL_asmdecor(ATL_USERMM)
ALIGN16
ATL_asmdecor(ATL_USERMM):
   #define FSIZE 6*8
/*
 * Save callee-saved iregs
 */
   sub $FSIZE, %rsp
   movq    %rbp, (%rsp)
   movq    %rbx, 8(%rsp)
   movq    %r12, 16(%rsp)
   movq    %r13, 24(%rsp)
   movq    %r14, 32(%rsp)
/*
 * Load parameters
 */
   mov  %rdi, nmu
   mov  %rsi, nnu0
   mov  %r8, pB
   mov  %r9, pC
   movq FSIZE+8(%rsp), pfA
   movq FSIZE+16(%rsp), pfB
   movq FSIZE+24(%rsp), pfC
   mov  $256, r256
   mov  $8*8*2, incPF
/*
 * Add 128 to ptrs to maximize unrolling range
 */
   add incPF, pA
   add incPF, pB
   mov pA, pA0
   mov pB, pB0
   mov nnu0, nnu
   mov $2*KB*8, incB   /* incB = nu*KB*sizeof */
   mov $8*KB*8, incA   /* incA = mu*KB*sizeof */

#if 0
   MLOOP:
      mov nnu0, nnu
      NLOOP:
#else
   ALIGN16
   .local MNLOOP
   MNLOOP:
#endif
/*
 *       Unroll first iteration to avoid zeroing rCxx
 */
         MOVAPD -128(pB), rB1
         movddup rB1, rB0
         MOVAPD -128(pA), rC00
         MOVAPD rC00, rC01
         mulpd rB0, rC00
         MOVAPD -112(pA), rC10
         MOVAPD rC10, rC11
         mulpd rB0, rC10
         MOVAPD -96(pA), rC20
         MOVAPD rC20, rC21
         mulpd rB0, rC20
         MOVAPD -80(pA), rC30
         MOVAPD rC30, rC31
         mulpd rB0, rC30


         UNPCKHPD rB1, rB1
         #if KB > 1
            MOVAPD -112(pB), rb1
         #endif
         mulpd rB1, rC01
         #if KB > 1
            movddup rb1, rB0
            MOVAPD -64(pA), rA0
         #endif
         mulpd rB1, rC11
         #if KB > 1
            MOVAPD -48(pA), rA1
         #endif
         mulpd rB1, rC21
         #if KB > 1
            MOVAPD -32(pA), rA2
         #endif
         mulpd rB1, rC31
         #if KB > 1
            UNPCKHPD rb1, rb1
         #endif

         #if KB > 1
               MOVAPD -16(pA), rA3
            MOVAPD rA0, m0
            mulpd rB0, m0
            addpd m0, rC00
            #if KB > 2
               MOVAPD -96(pB), rB1
            #endif
            MOVAPD rA1, m0
            mulpd rB0, m0
            addpd m0, rC10
            MOVAPD rA2, m0
            mulpd rB0, m0
            addpd m0, rC20
            UNPCKHPD rb1, rb1
            mulpd rA3, rB0
            addpd rB0, rC30
            #if KB > 2
               movddup rB1, rB0
            #endif
   
            mulpd rb1, rA0
            addpd rA0, rC01
            #if KB > 2
               MOVAPD (pA), rA0
            #endif
            mulpd rb1, rA1
            addpd rA1, rC11
            #if KB > 2
               MOVAPD 16(pA), rA1
            #endif
            mulpd rb1, rA2
            addpd rA2, rC21
            #if KB > 2
               MOVAPD 32(pA), rA2
            #endif
            mulpd rA3, rb1
            addpd rb1, rC31
            #if KB > 2
               MOVAPD 48(pA), rA3
               UNPCKHPD rB1, rB1
            #endif
         #endif

         #if KB > 2
            MOVAPD rA0, m0
            mulpd rB0, m0
            addpd m0, rC00
            #if KB > 3
               MOVAPD -80(pB), rb1
            #endif
            MOVAPD rA1, m0
            mulpd rB0, m0
            addpd m0, rC10
            MOVAPD rA2, m0
            mulpd rB0, m0
            addpd m0, rC20
            mulpd rA3, rB0
            addpd rB0, rC30
            #if KB > 3
               movddup rb1, rB0
            #endif
   
            mulpd rB1, rA0
            addpd rA0, rC01
            #if KB > 3
               UNPCKHPD rb1, rb1
               MOVAPD 64(pA), rA0
            #endif
            mulpd rB1, rA1
            addpd rA1, rC11
            #if KB > 3
               MOVAPD 80(pA), rA1
            #endif
            mulpd rB1, rA2
            addpd rA2, rC21
            #if KB > 3
               MOVAPD 96(pA), rA2
            #endif
            mulpd rA3, rB1
            addpd rB1, rC31
            #if KB > 3
               MOVAPD 112(pA), rA3
              add r256, pA
            #endif
         #endif

         #if KB > 3
            MOVAPD rA0, m0
            mulpd rB0, m0
            addpd m0, rC00
            #if KB > 4
               MOVAPD -64(pB), rB1
            #endif
            MOVAPD rA1, m0
            mulpd rB0, m0
            addpd m0, rC10
               prefC 64(pC)
            MOVAPD rA2, m0
            mulpd rB0, m0
            addpd m0, rC20
               prefC 64(pC)
            UNPCKHPD rb1, rb1
            mulpd rA3, rB0
            addpd rB0, rC30
            #if KB > 4
               movddup rB1, rB0
            #endif
   
            mulpd rb1, rA0
            addpd rA0, rC01
            #if KB > 4
               MOVAPD -128(pA), rA0
               UNPCKHPD rB1, rB1
            #endif
            mulpd rb1, rA1
            addpd rA1, rC11
            #if KB > 4
               MOVAPD -112(pA), rA1
            #endif
            mulpd rb1, rA2
            addpd rA2, rC21
            #if KB > 4
               MOVAPD -96(pA), rA2
            #endif
            mulpd rA3, rb1
            addpd rb1, rC31
            #if KB > 4
               MOVAPD -80(pA), rA3
            #endif
         #endif

         ALIGN16
@iexp incT 1280000 0 +
@iexp k 4 0 +
@iexp ao -80 16 +
@iexp bo -64 16 +
@iwhile k < 256
         #if KB > @(k)
   @iexp k @(k) 1 +
            MOVAPD rA0, m0
            mulpd rB0, m0
            addpd m0, rC00
            #if KB > @(k)
               MOVAPD @(bo)(pB), rb1
   @iexp bo @(bo) 16 +
   @iif @(bo) = @(incT)
               add r256, pB
      @iexp bo -128 0 +
   @endiif
            #endif
            MOVAPD rA1, m0
            mulpd rB0, m0
            addpd m0, rC10
            MOVAPD rA2, m0
            mulpd rB0, m0
            addpd m0, rC20
            mulpd rA3, rB0
            addpd rB0, rC30
            #if KB > @(k)
               movddup rb1, rB0
            #endif
   
            mulpd rB1, rA0
            addpd rA0, rC01
            #if KB > @(k)
               UNPCKHPD rb1, rb1
               MOVAPD @(ao)(pA), rA0
   @iexp ao @(ao) 16 +
   @iif @(ao) = @(incT)
               add r256, pA
      @iexp ao -128 0 +
   @endiif
            #endif
            mulpd rB1, rA1
            addpd rA1, rC11
            #if KB > @(k)
               MOVAPD @(ao)(pA), rA1
   @iexp ao @(ao) 16 +
   @iif @(ao) = @(incT)
               add r256, pA
      @iexp ao -128 0 +
   @endiif
            #endif
            mulpd rB1, rA2
            addpd rA2, rC21
            #if KB > @(k) 
               MOVAPD @(ao)(pA), rA2
   @iexp ao @(ao) 16 +
   @iif @(ao) = @(incT)
               add r256, pA
      @iexp ao -128 0 +
   @endiif
            #endif
            mulpd rA3, rB1
            addpd rB1, rC31
            #if KB > @(k)
               MOVAPD @(ao)(pA), rA3
   @iexp ao @(ao) 16 +
   @iif @(ao) = @(incT)
               add r256, pA
      @iexp ao -128 0 +
   @endiif
            #endif
         #endif

         #if KB > @(k)
   @iexp k @(k) 1 +
            MOVAPD rA0, m0
            mulpd rB0, m0
            addpd m0, rC00
            #if KB > @(k)
               MOVAPD @(bo)(pB), rB1
   @iexp bo @(bo) 16 +
   @iif @(bo) = @(incT)
               add r256, pB
      @iexp bo -128 0 +
   @endiif
            #endif
            MOVAPD rA1, m0
            mulpd rB0, m0
            addpd m0, rC10
            MOVAPD rA2, m0
            mulpd rB0, m0
            addpd m0, rC20
            UNPCKHPD rb1, rb1
            mulpd rA3, rB0
            addpd rB0, rC30
            #if KB > @(k)
               movddup rB1, rB0
            #endif
   
            mulpd rb1, rA0
            addpd rA0, rC01
            #if KB > @(k)
               MOVAPD @(ao)(pA), rA0
   @iexp ao @(ao) 16 +
   @iif @(ao) = @(incT)
               add r256, pA
      @iexp ao -128 0 +
   @endiif
               UNPCKHPD rB1, rB1
            #endif
            mulpd rb1, rA1
            addpd rA1, rC11
            #if KB > @(k)
               MOVAPD @(ao)(pA), rA1
   @iexp ao @(ao) 16 +
   @iif @(ao) = @(incT)
               add r256, pA
      @iexp ao -128 0 +
   @endiif
            #endif
            mulpd rb1, rA2
            addpd rA2, rC21
            #if KB > @(k)
               MOVAPD @(ao)(pA), rA2
   @iexp ao @(ao) 16 +
   @iif @(ao) = @(incT)
               add r256, pA
      @iexp ao -128 0 +
   @endiif
            #endif
            mulpd rA3, rb1
            addpd rb1, rC31
            #if KB > @(k)
               MOVAPD @(ao)(pA), rA3
   @iexp ao @(ao) 16 +
   @iif @(ao) = @(incT)
               add r256, pA
      @iexp ao -128 0 +
   @endiif
            #endif
         #endif
@endiwhile
/*
 *       Write answer out to C
 */
         #ifdef BETCOP
            BETCOP (pC), rC00
         #endif
         MOVAPD rC00, (pC)
         #ifdef BETCOP
            BETCOP 16(pC), rC10
         #endif
         MOVAPD rC10, 16(pC)
         #ifdef BETCOP
            BETCOP 32(pC), rC20
         #endif
         MOVAPD rC20, 32(pC)
         #ifdef BETCOP
            BETCOP 48(pC), rC30
         #endif
         MOVAPD rC30, 48(pC)
         #ifdef BETCOP
            BETCOP 64(pC), rC01
         #endif
         MOVAPD rC01, 64(pC)
         #ifdef BETCOP
            BETCOP 80(pC), rC11
         #endif
         MOVAPD rC11, 80(pC)
         #ifdef BETCOP
            BETCOP 96(pC), rC21
         #endif
         MOVAPD rC21, 96(pC)
         #ifdef BETCOP
            BETCOP 112(pC), rC31
         #endif
         MOVAPD rC31, 112(pC)
         add incPF, pC
         mov pA0, pA
@iif @(incT) = 128
         #if 2*KB*8 >= 256
            sub $((2*KB*8)/256)*256, pB
         #endif
@endiif
         add incB, pB
      dec nnu
      jnz MNLOOP

      mov nnu0, nnu
      add incA, pA0
      mov pA0, pA
      mov pB0, pB
   dec nmu
   jnz MNLOOP

/* DONE: */
   movq    (%rsp), %rbp
   movq    8(%rsp), %rbx
   movq    16(%rsp), %r12
   movq    24(%rsp), %r13
   movq    32(%rsp), %r14
   add $FSIZE, %rsp
   ret
@ROUT !
@ROUT ATL_dammm4x4x256_sse3.S
   @define mu @4@
   @define nu @4@
@extract -b @(topd)/gen.inc what=crsetup
@extract -b @(topd)/cw.inc lang=c -define cwdate 2013
#include "atlas_asm.h"
#define movapd movaps
#define nmu     %rdi
#define nnu     %rsi
#define nnu0    %r10
#define pA      %rcx
#define pB      %rax
#define pC      %r9
#define pf      %rbp
#define pB0     %r12
#define incPF   %rbx
#define pfB     %rdx
#define incAm   %r11 
#define pfC     %r13
#define r256    %r14

#define rA0     %xmm0
#define rA1     %xmm1
#define rB0     %xmm2
#define rB1     %xmm3
#define rB2     %xmm4
#define rB3     %xmm5
#define rC00    %xmm6
#define rC10    %xmm7
#define rC01    %xmm8
#define rC11    %xmm9
#define rC02    %xmm10
#define rC12    %xmm11
#define rC03    %xmm12
#define rC13    %xmm13
#define rm0     %xmm14
#define unpckhpd movhlps
/* #define movddup pshufd $0x44, */
#ifndef pref
   #define pref prefetcht1
#endif
#ifndef prefB
   #define prefB prefetcht1
#endif
#ifndef prefC
   #ifdef ATL_3DNow
      #define prefC prefetchw
   #else
      #define prefC prefetcht0
   #endif
#endif
#ifdef BETAN1
   #define BETCOP subpd
#else
   #define BETCOP addpd
#endif
#define FSIZE 6*8
/*
                    rdi      rsi    rdx        rcx         r8        r9  
void ATL_USERMM(SZT nmu, SZT nnu, SZT K, CTYPE *pA, CTYPE *pB, TYPE *pC, 
                  8(%rsp)    16(%rsp)     24(%rsp)   
                CTYPE *pAn, CTYPE *pBn, CTYPE *pCn);
 */
.text
.global ATL_asmdecor(ATL_USERMM)
ALIGN16
ATL_asmdecor(ATL_USERMM):
/*
 * Save callee-saved iregs
 */
   sub $FSIZE, %rsp
   movq    %rbp, 0(%rsp)
   movq    %rbx, 8(%rsp)
   movq    %r12, 16(%rsp)
   movq    %r13, 24(%rsp)
@skip   movq    %r14, 32(%rsp)
@skip   movq    %r15, 40(%rsp)
/*
 * Load paramaters
 */
   movq %r8, pB
   mov nnu, nnu0
   movq FSIZE+16(%rsp), pf      /* pf = pBn */
   movq FSIZE+8(%rsp), pfB      /* pfB = pAn */
   movq FSIZE+24(%rsp), pfC    /* pfC = pCn */
   mov $8*@(mu)*@(nu), incPF
/*
 * Extend range of small operands by starting at -128
 */
   sub $-128, pA
   sub $-128, pB
   mov $KB*@(mu)*8, incAm           /* incAm = KB*MU*size */
   movq pB, pB0

   ALIGN8
   .local MNLOOP
   MNLOOP:
/*
 *       Peel first iteration of K-loop to handle init of C to 0
 */
         movapd -128(pB), rB1
         movddup rB1, rB0
         movapd -128(pA), rC00

         movapd rC00, rC01
         mulpd rB0, rC00
         unpckhpd rB1, rB1
         movapd -112(pA), rC10
         movapd rC10, rC11
         mulpd rB0, rC10

         movapd -112(pB), rB3
         movddup rB3, rB2
         movapd rC01, rC02
         mulpd rB1, rC01
         unpckhpd rB3, rB3
         movapd rC11, rC12
         mulpd rB1, rC11
         #if KB > 1
            movapd -96(pB), rB1
         #else
            pref (pf)
         #endif

         #if KB > 1
            movapd -96(pA), rA0
         #else
            pref 64(pf)
         #endif
         movapd rC02, rC03
         mulpd rB2, rC02
         movapd rC12, rC13
         mulpd rB2, rC12
         #if KB > 1
            movddup rB1, rB0
         #else
            add incPF, pf
         #endif

         mulpd rB3, rC03
         prefC (pC)
         mulpd rB3, rC13
         prefC 64(pC)
/*
 *       ==========================
 *       Completely unrolled K-loop
 *       ==========================
 */
@iexp ao -80 0 +
@iexp bo -80 0 +
@iexp k 1 0 +
@iwhile k < 256
         #if KB > @(k)
   @iif k = 48
            nop
   @endiif
   @iexp k @(k) 1 +
            movapd rB0, rm0
            mulpd rA0, rm0
            addpd rm0, rC00
            movapd @(ao)(pA), rA1
   @iexp ao @(ao) 16 +
            mulpd rA1, rB0
            addpd rB0, rC10
            unpckhpd rB1, rB1

            movapd rB1, rm0
            mulpd rA0, rm0
            addpd rm0, rC01
            movapd @(bo)(pB), rB3
   @iexp bo @(bo) 16 +
            mulpd rA1, rB1
            addpd rB1, rC11
            movddup rB3, rB2

            movapd rB2, rm0
            mulpd rA0, rm0
            addpd rm0, rC02
            unpckhpd rB3, rB3
            mulpd rA1, rB2
            addpd rB2, rC12

            #if KB > @(k)
               movapd @(bo)(pB), rB1
   @iexp bo @(bo) 16 +
            #elif KB == @(k)
               pref (pf)
            #endif
            mulpd rB3, rA0
            addpd rA0, rC03
            #if KB > @(k)
               movapd @(ao)(pA), rA0
   @iexp ao @(ao) 16 +
            #elif KB == @(k)
               pref (pfC)
               add incPF, pfC
            #endif
            mulpd rA1, rB3
            addpd rB3, rC13
            #if KB > @(k)
               movddup rB1, rB0
            #elif KB == @(k)
               prefetcht1 64(pfB)
               add incPF, pfB
               add incPF, pf
            #endif
         #endif   
@endiwhile
         #if defined(BETA1) || defined(BETAN1)
            BETCOP (pC), rC00
            movapd rC00, (pC)
            BETCOP 16(pC), rC10
            movapd rC10, 16(pC)
            BETCOP 32(pC), rC01
            movapd rC01, 32(pC)
            BETCOP 48(pC), rC11
            movapd rC11, 48(pC)
            BETCOP 64(pC), rC02
            movapd rC02, 64(pC)
            BETCOP 80(pC), rC12
            movapd rC12, 80(pC)
            BETCOP 96(pC), rC03
            movapd rC03, 96(pC)
            BETCOP 112(pC), rC13
            movapd rC13, 112(pC)
         #else
            movapd rC00, (pC)
            movapd rC10, 16(pC)
            movapd rC01, 32(pC)
            movapd rC11, 48(pC)
            movapd rC02, 64(pC)
            movapd rC12, 80(pC)
            movapd rC03, 96(pC)
            movapd rC13, 112(pC)
         #endif
         sub $-128, pC
         add $KB*4*8, pB
      sub $1, nnu
      jnz MNLOOP
      mov nnu0, nnu
      mov pB0, pB
      add incAm, pA
   sub $1, nmu
   jnz MNLOOP

/* DONE: */
   movq    (%rsp), %rbp
   movq    8(%rsp), %rbx
   movq    16(%rsp), %r12
   movq    24(%rsp), %r13
@skip   movq    32(%rsp), %r14
@skip   movq    40(%rsp), %r15
   add $FSIZE, %rsp
   ret
@ROUT ATL_sammm8x4x256_sse3.S
   @define mu @4@
   @define nu @4@
@extract -b @(topd)/gen.inc what=crsetup
@extract -b @(topd)/cw.inc lang=c -define cwdate 2013
#include "atlas_asm.h"
#define movaps movaps
#define nmu     %rdi
#define nnu     %rsi
#define nnu0    %r10
#define pA      %rcx
#define pB      %rax
#define pC      %r9
#define pf      %rbp
#define pB0     %r12
#define incPF   %rbx
#define pfB     %rdx
#define incAm   %r11 
#define pfC     %r13
#define r256    %r14

#define rm0     %xmm0
#define rA0     %xmm1
#define rA1     %xmm2
#define rB0     %xmm3
#define rB1     %xmm4
#define rB2     %xmm5
#define rB3     %xmm6
#define rb3     %xmm7
#define rC00    %xmm8
#define rC10    %xmm9
#define rC01    %xmm10
#define rC11    %xmm11
#define rC02    %xmm12
#define rC12    %xmm13
#define rC03    %xmm14
#define rC13    %xmm15
#ifndef pref
   #define pref prefetcht1
#endif
#ifndef prefB
   #define prefB prefetcht1
#endif
#ifndef prefC
   #ifdef ATL_3DNow
      #define prefC prefetchw
   #else
      #define prefC prefetcht0
   #endif
#endif
#ifdef BETAN1
   #define BETCOP subps
#else
   #define BETCOP addps
#endif
#define FSIZE 6*8
/*
                    rdi      rsi    rdx        rcx         r8        r9  
void ATL_USERMM(SZT nmu, SZT nnu, SZT K, CTYPE *pA, CTYPE *pB, TYPE *pC, 
                  8(%rsp)    16(%rsp)     24(%rsp)   
                CTYPE *pAn, CTYPE *pBn, CTYPE *pCn);
 */
.text
.global ATL_asmdecor(ATL_USERMM)
ALIGN16
ATL_asmdecor(ATL_USERMM):
/*
 * Save callee-saved iregs
 */
   sub $FSIZE, %rsp
   movq    %rbp, 0(%rsp)
   movq    %rbx, 8(%rsp)
   movq    %r12, 16(%rsp)
   movq    %r13, 24(%rsp)
@skip   movq    %r14, 32(%rsp)
@skip   movq    %r15, 40(%rsp)
/*
 * Load paramaters
 */
   movq %r8, pB
   mov nnu, nnu0
   movq FSIZE+16(%rsp), pf      /* pf = pBn */
   movq FSIZE+8(%rsp), pfB      /* pfB = pAn */
   movq FSIZE+24(%rsp), pfC    /* pfC = pCn */
   mov $4*@(mu)*@(nu), incPF
/*
 * Extend range of small operands by starting at -128
 */
   sub $-128, pA
   sub $-128, pB
   mov $KB*8*4, incAm           /* incAm = KB*MU*size */
   movq pB, pB0

   ALIGN8
   .local MNLOOP
   MNLOOP:
/*
 *       Peel first iteration of K-loop to handle init of C to 0
 */
         movaps -128(pB), rB3
         pshufd $0x00, rB3, rB0
         movaps -128(pA), rC00

         movaps rC00, rC01
         mulps rB0, rC00
         pshufd $0x55, rB3, rB1
         movaps -112(pA), rC10
         movaps rC10, rC11
         mulps rB0, rC10

         #if KB > 1
            movaps -112(pB), rb3
         #else
            pref (pf)
         #endif
         movaps rC01, rC02
         mulps rB1, rC01
         #if KB > 1
            movaps -96(pA), rA0
         #else
            pref 64(pf)
         #endif
         movaps rC11, rC12
         mulps rB1, rC11

         #if KB > 1
            movaps -80(pA), rA1
         #endif
         pshufd $0xAA, rB3, rB2
         movaps rC02, rC03
         mulps rB2, rC02
         shufps $0xFF, rB3, rB3
         movaps rC12, rC13
         mulps rB2, rC12
         #if KB > 1
            pshufd $0x00, rb3, rB0
         #else
            add incPF, pf
         #endif

         mulps rB3, rC03
         prefC (pC)
         mulps rB3, rC13
         prefC 64(pC)
/*
 *       2nd peeled K iteration
 */
         #if KB > 1
            #if KB > 2
               movaps -96(pB), rB3
            #endif
            pshufd $0x55, rb3, rB1
            movaps rA0, rm0
            mulps rB0, rm0
            addps rm0, rC00
            pshufd $0xAA, rb3, rB2
            movaps rA1, rm0
            mulps rB0, rm0
            addps rm0, rC10
            shufps $0xFF, rb3, rb3
            movaps rA0, rm0
            mulps rB1, rm0
            addps rm0, rC01
            #if KB > 2
               pshufd $0x00, rB3, rB0
            #endif
            movaps rA1, rm0
            mulps rB1, rm0
            addps rm0, rC11
            #if KB > 2
               pshufd $0x55, rB3, rB1
            #endif
            movaps rA0, rm0
            mulps rB2, rm0
            addps rm0, rC02
            movaps rA1, rm0
            mulps rB2, rm0
            addps rm0, rC12
            #if KB > 2
               pshufd $0xAA, rB3, rB2
            #endif

            mulps rb3, rA0
            addps rA0, rC03
            #if KB > 2
               movaps -64(pA), rA0
            #endif
            mulps rA1, rb3
            addps rb3, rC13
            #if KB > 2
               movaps -48(pA), rA1
            #endif
         #endif
/*
 *       ==========================
 *       Completely unrolled K-loop
 *       ==========================
 */
@iexp ao -32 0 +
@iexp bo -80 0 +
@iexp k 2 0 +
@iwhile k < 256
         #if KB > @(k)
   @iexp k @(k) 1 +
            #if KB > @(k)
               movaps @(bo)(pB), rb3
   @iexp bo @(bo) 16 +
            #elif KB == @(k)
               pref (pf)
            #endif
            movaps rA0, rm0
            mulps rB0, rm0
            addps rm0, rC00
            shufps $0xFF, rB3, rB3
            #if KB == @(k)
               add incPF, pf
            #endif
            movaps rA1, rm0
            mulps rB0, rm0
            addps rm0, rC10
            #if KB > @(k)
               pshufd $0x00, rb3, rB0
            #elif KB == @(k)
               pref (pfC)
            #endif
            movaps rA0, rm0
            mulps rB1, rm0
            addps rm0, rC01
            #if KB == @(k)
               add incPF, pfC
            #endif
            movaps rA1, rm0
            mulps rB1, rm0
            addps rm0, rC11
            #if KB > @(k)
               pshufd $0x55, rb3, rB1
            #elif KB == @(k)
               pref (pfB)
            #endif
            movaps rA0, rm0
            mulps rB2, rm0
            addps rm0, rC02
            #if KB == @(k)
               add incPF, pfB
            #endif
            movaps rA1, rm0
            mulps rB2, rm0
            addps rm0, rC12
            #if KB > @(k)
               pshufd $0xAA, rb3, rB2
            #endif

            mulps rB3, rA0
            addps rA0, rC03
            #if KB > @(k)
               movaps @(ao)(pA), rA0
   @iexp ao @(ao) 16 +
            #endif
            mulps rA1, rB3
            addps rB3, rC13
            #if KB > @(k)
               movaps @(ao)(pA), rA1
   @iexp ao @(ao) 16 +
            #endif
         #endif
         #if KB > @(k)
   @iexp k @(k) 1 +
            #if KB > @(k)
               movaps @(bo)(pB), rB3
   @iexp bo @(bo) 16 +
            #endif
            movaps rA0, rm0
            mulps rB0, rm0
            addps rm0, rC00
            shufps $0xFF, rb3, rb3
            movaps rA1, rm0
            mulps rB0, rm0
            addps rm0, rC10
            #if KB > @(k)
               pshufd $0x00, rB3, rB0
            #endif
            movaps rA0, rm0
            mulps rB1, rm0
            addps rm0, rC01
            movaps rA1, rm0
            mulps rB1, rm0
            addps rm0, rC11
            #if KB > @(k)
               pshufd $0x55, rB3, rB1
            #endif
            movaps rA0, rm0
            mulps rB2, rm0
            addps rm0, rC02
            movaps rA1, rm0
            mulps rB2, rm0
            addps rm0, rC12
            #if KB > @(k)
               pshufd $0xAA, rB3, rB2
            #endif

            mulps rb3, rA0
            addps rA0, rC03
            #if KB > @(k)
               movaps @(ao)(pA), rA0
   @iexp ao @(ao) 16 +
            #endif
            mulps rA1, rb3
            addps rb3, rC13
            #if KB > @(k)
               movaps @(ao)(pA), rA1
   @iexp ao @(ao) 16 +
            #endif
         #endif
@endiwhile
         #if defined(BETA1) || defined(BETAN1)
            BETCOP (pC), rC00
            movaps rC00, (pC)
            BETCOP 16(pC), rC10
            movaps rC10, 16(pC)
            BETCOP 32(pC), rC01
            movaps rC01, 32(pC)
            BETCOP 48(pC), rC11
            movaps rC11, 48(pC)
            BETCOP 64(pC), rC02
            movaps rC02, 64(pC)
            BETCOP 80(pC), rC12
            movaps rC12, 80(pC)
            BETCOP 96(pC), rC03
            movaps rC03, 96(pC)
            BETCOP 112(pC), rC13
            movaps rC13, 112(pC)
         #else
            movaps rC00, (pC)
            movaps rC10, 16(pC)
            movaps rC01, 32(pC)
            movaps rC11, 48(pC)
            movaps rC02, 64(pC)
            movaps rC12, 80(pC)
            movaps rC03, 96(pC)
            movaps rC13, 112(pC)
         #endif
         sub $-128, pC
         add $KB*4*4, pB
      sub $1, nnu
      jnz MNLOOP
      mov nnu0, nnu
      mov pB0, pB
      add incAm, pA
   sub $1, nmu
   jnz MNLOOP

/* DONE: */
   movq    (%rsp), %rbp
   movq    8(%rsp), %rbx
   movq    16(%rsp), %r12
   movq    24(%rsp), %r13
@skip   movq    32(%rsp), %r14
@skip   movq    40(%rsp), %r15
   add $FSIZE, %rsp
   ret
